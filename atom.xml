<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jiawen and her funny friends</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2021-04-14T01:25:40.285Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jiawen Zhang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>The Basics of Computer Vision</title>
    <link href="http://yoursite.com/2021/04/14/The_basics_of_computer_vision/"/>
    <id>http://yoursite.com/2021/04/14/The_basics_of_computer_vision/</id>
    <published>2021-04-14T00:44:35.000Z</published>
    <updated>2021-04-14T01:25:40.285Z</updated>
    
    <content type="html"><![CDATA[<p>对计算机视觉的基础知识，重要工作，以及相关任务进行了梳理。</p><a id="more"></a><h1 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h1><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><h3 id="卷积神经网络的层级结构"><a href="#卷积神经网络的层级结构" class="headerlink" title="卷积神经网络的层级结构"></a>卷积神经网络的层级结构</h3><ul><li>数据输入层/ Input layer</li><li>卷积计算层/ CONV layer</li><li>ReLU激励层 / ReLU layer</li><li>池化层 / Pooling layer</li><li>全连接层 / FC layer</li></ul><h4 id="数据输入层"><a href="#数据输入层" class="headerlink" title="数据输入层"></a>数据输入层</h4><p>该层要做的处理主要是对原始图像数据进行预处理，其中包括：</p><ul><li>去均值：把输入数据各个维度都中心化为0，如下图所示，其目的就是把样本的中心拉回到坐标系原点上。</li><li>归一化：幅度归一化到同样的范围，如下所示，即减少各维度数据取值范围的差异而带来的干扰，比如，我们有两个维度的特征A和B，A范围是0到10，而B范围是0到10000，如果直接使用这两个特征是有问题的，好的做法就是归一化，即A和B的数据都变为0到1的范围。</li><li>PCA/白化：用PCA降维；白化是对数据各个特征轴上的幅度归一化</li></ul><p>去均值与归一化：</p><p><a href="https://imgchr.com/i/NMr1c4" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMr1c4.md.png" alt="NMr1c4.md.png"></a></p><p>PCA/白化：</p><p><a href="https://imgchr.com/i/NMr3jJ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMr3jJ.md.png" alt="NMr3jJ.md.png"></a></p><h3 id="卷积计算层"><a href="#卷积计算层" class="headerlink" title="卷积计算层"></a>卷积计算层</h3><p>这一层就是卷积神经网络最重要的一个层次，也是“卷积神经网络”的名字来源。<br>在这个卷积层，有两个关键操作：</p><ul><li>局部关联。每个神经元看做一个滤波器(filter)</li><li>窗口(receptive field)滑动， filter对局部数据计算</li></ul><p>先介绍卷积层遇到的几个名词：</p><ul><li>深度/depth<br>有多少个滤波器，depth就是多少</li><li>步长/stride （窗口一次滑动的长度）</li><li>填充值/zero-padding<br>当窗口无法将所有像素遍历完时，添加填充值</li></ul><p>这里的蓝色矩阵就是输入的图像，粉色矩阵就是卷积层的神经元，这里表示了有两个神经元（w0,w1）。绿色矩阵就是经过卷积运算后的输出矩阵，这里的步长设置为2。<br>蓝色的矩阵(输入图像)对粉色的矩阵（filter）进行矩阵内积计算并将三个内积运算的结果与偏置值b相加（比如上面图的计算：2+（-2+1-2）+（1-2-2） + 1= 2 - 3 - 3 + 1 = -3），计算后的值就是绿框矩阵的一个元素。</p><p><a href="https://imgchr.com/i/NMyEoq" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyEoq.md.png" alt="NMyEoq.md.png"></a></p><h5 id="参数共享机制"><a href="#参数共享机制" class="headerlink" title="参数共享机制"></a>参数共享机制</h5><ul><li>在卷积层中每个神经元连接数据窗的权重是固定的，每个神经元只关注一个特性。神经元就是图像处理中的滤波器，比如边缘检测专用的Sobel滤波器，即卷积层的每个滤波器都会有自己所关注一个图像特征，比如垂直边缘，水平边缘，颜色，纹理等等，这些所有神经元加起来就好比就是整张图像的特征提取器集合。</li><li>需要估算的权重个数减少: AlexNet 1亿 =&gt; 3.5w</li><li>一组固定的权重和不同窗口内数据做内积: 卷积</li></ul><h4 id="激励层"><a href="#激励层" class="headerlink" title="激励层"></a>激励层</h4><p>把卷积层输出结果做非线性映射。</p><p><a href="https://imgchr.com/i/NMyrTI" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyrTI.md.png" alt="NMyrTI.md.png"></a></p><p>CNN采用的激励函数一般为ReLU(The Rectified Linear Unit/修正线性单元)，它的特点是收敛快，求梯度简单，但较脆弱，图像如下。</p><p><a href="https://imgchr.com/i/NMyD0A" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyD0A.md.png" alt="NMyD0A.md.png"></a></p><p>激励层的实践经验：</p><ol><li>不要用sigmoid！不要用sigmoid！不要用sigmoid！</li><li>首先试RELU，因为快，但要小心点</li><li>如果2失效，请用Leaky ReLU或者Maxout</li><li>某些情况下tanh倒是有不错的结果，但是很少</li></ol><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>池化层夹在连续的卷积层中间， 用于压缩数据和参数的量，减小过拟合。<br>简而言之，如果输入是图像的话，那么池化层的最主要作用就是压缩图像。</p><p>这里再展开叙述池化层的具体作用。</p><ol><li>特征不变性，也就是我们在图像处理中经常提到的特征的尺度不变性，池化操作就是图像的resize，平时一张狗的图像被缩小了一倍我们还能认出这是一张狗的照片，这说明这张图像中仍保留着狗最重要的特征，我们一看就能判断图像中画的是一只狗，图像压缩时去掉的信息只是一些无关紧要的信息，而留下的信息则是具有尺度不变性的特征，是最能表达图像的特征。</li><li>特征降维，我们知道一幅图像含有的信息是很大的，特征也很多，但是有些信息对于我们做图像任务时没有太多用途或者有重复，我们可以把这类冗余信息去除，把最重要的特征抽取出来，这也是池化操作的一大作用。</li><li>在一定程度上防止过拟合，更方便优化。</li></ol><p><a href="https://imgchr.com/i/NMyL1U" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyL1U.md.png" alt="NMyL1U.md.png"></a></p><p>池化层用的方法有Max pooling 和 average pooling，而实际用的较多的是Max pooling。<br>这里就说一下Max pooling，其实思想非常简单。对于每个2 <em> 2的窗口选出最大的数作为输出矩阵的相应元素的值，比如输入矩阵第一个2 </em> 2窗口中最大的数是6，那么输出矩阵的第一个元素就是6，如此类推。</p><p><a href="https://imgchr.com/i/NMyqpT" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyqpT.md.png" alt="NMyqpT.md.png"></a></p><h4 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h4><p>两层之间所有神经元都有权重连接，通常全连接层在卷积神经网络尾部。也就是跟传统的神经网络神经元的连接方式是一样的.</p><p><a href="https://imgchr.com/i/NMyOcF" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMyOcF.md.png" alt="NMyOcF.md.png"></a></p><h3 id="一般CNN结构"><a href="#一般CNN结构" class="headerlink" title="一般CNN结构"></a>一般CNN结构</h3><ol><li>INPUT</li><li>[[CONV -&gt; RELU]N -&gt; POOL?]M</li><li>[FC -&gt; RELU]*K</li><li>FC</li></ol><h3 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h3><ol><li>同一般机器学习算法，先定义Loss function，衡量和实际结果之间差距。</li><li>找到最小化损失函数的W和b， CNN中用的算法是SGD（随机梯度下降）。</li></ol><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><ul><li>共享卷积核，对高维数据处理无压力</li><li>无需手动选取特征，训练好权重，即得特征分类效果好</li></ul><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><ul><li>物理含义不明确（也就说，我们并不知道没个卷积层到底提取到的是什么特征，而且神经网络本身就是一种难以解释的“黑箱模型”）</li></ul><h3 id="典型CNN"><a href="#典型CNN" class="headerlink" title="典型CNN"></a>典型CNN</h3><ul><li>LeNet，这是最早用于数字识别的CNN</li><li>AlexNet， 2012 ILSVRC比赛远超第2名的CNN，比LeNet更深，用多层小卷积层叠加替换单大卷积层。</li><li>ZF Net， 2013 ILSVRC比赛冠军</li><li>GoogLeNet， 2014 ILSVRC比赛冠军</li><li>VGGNet， 2014 ILSVRC比赛中的模型，图像识别略差于GoogLeNet，但是在很多图像转化学习问题(比如object detection)上效果奇好</li></ul><h3 id="Fine-tuning"><a href="#Fine-tuning" class="headerlink" title="Fine-tuning"></a>Fine-tuning</h3><p>fine-tuning就是使用已用于其他目标、预训练好模型的权重或者部分权重，作为初始值开始训练。</p><p>具体做法：</p><ul><li>复用相同层的权重，新定义层取随机权重初始值</li><li>调大新定义层的的学习率，调小复用层学习率</li></ul><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>卷积网络在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。</p><p>CNN一个非常重要的特点就是头重脚轻（越往输入权值越小，越往输出权值越多），呈现出一个倒三角的形态，这就很好地避免了BP神经网络中反向传播的时候梯度损失得太快。</p><p>卷积神经网络CNN主要用来识别位移、缩放及其他形式扭曲不变性的二维图形。由于CNN的特征检测层通过训练数据进行学习，所以在使用CNN时，避免了显式的特征抽取，而隐式地从训练数据中进行学习；再者由于同一特征映射面上的神经元权值相同，所以网络可以并行学习，这也是卷积网络相对于神经元彼此相连网络的一大优势。卷积神经网络以其局部权值共享的特殊结构在语音识别和图像处理方面有着独特的优越性，其布局更接近于实际的生物神经网络，权值共享降低了网络的复杂性，特别是多维输入向量的图像可以直接输入网络这一特点避免了特征提取和分类过程中数据重建的复杂度。</p><h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p>Very Deep Convolutional Networks for Large-Scale Image Recognition<br>intro：ICLR 2015</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>VGG16采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p><p>简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。</p><p>比如，3个步长为1的3x3卷积核的一层层叠加作用可看成一个大小为7的感受野（其实就表示3个3x3连续卷积相当于一个7x7卷积），其参数总量为 3x(9xC^2) ，如果直接使用7x7卷积核，其参数总量为 49xC^2 ，这里 C 指的是输入和输出的通道数。很明显，27xC^2小于49xC^2，即减少了参数；而且3x3卷积核有利于更好地保持图像性质。</p><p><a href="https://imgchr.com/i/NMBbss" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/19/NMBbss.md.png" alt="NMBbss.md.png"></a></p><ul><li>VGG16包含了16个隐藏层（13个卷积层和3个全连接层），如上图中的D列所示</li><li>VGG19包含了19个隐藏层（16个卷积层和3个全连接层），如上图中的E列所示</li></ul><p>VGG网络的结构非常一致，从头到尾全部使用的是3x3的卷积和2x2的max pooling。</p><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><h4 id="VGG优点"><a href="#VGG优点" class="headerlink" title="VGG优点"></a>VGG优点</h4><ul><li>VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）。</li><li>几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好</li><li>验证了通过不断加深网络结构可以提升性能。</li></ul><p>更少的参数意味着减少过拟合，而且更重要的是3个3x3卷积层拥有比1个7x7的卷积层更少的非线性变换（前者拥有3次而后者只有一次），使得CNN对特征的学习能力更强。</p><h4 id="VGG缺点"><a href="#VGG缺点" class="headerlink" title="VGG缺点"></a>VGG缺点</h4><ul><li>VGG耗费更多计算资源，并且使用了更多的参数（这里不是3x3卷积的锅），导致更多的内存占用（140M）。其中绝大多数的参数都是来自于第一个全连接层。VGG可是有3个全连接层啊！</li></ul><p>PS：有的文章称：发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量。</p><h2 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h2><h3 id="Inception-v1"><a href="#Inception-v1" class="headerlink" title="Inception v1"></a>Inception v1</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>Inception V1是来源于《Going deeper with convolutions》，论文主要介绍了，如何在有限的计算资源内，进一步提升网络的性能。</p><p>提升网络的性能的方法有很多，例如硬件的升级，更大的数据集等。但一般而言，提升网络性能最直接的方法是增加网络的深度和宽度。其中，网络的深度只的是网络的层数，宽度指的是每层的通道数。但是，这种方法会带来两个不足：</p><ol><li>容易发生过拟合。当深度和宽度不断增加的时候，需要学习到的参数也不断增加，巨大的参数容易发生过拟合。</li><li>均匀地增加网络的大小，会导致计算量的加大。</li></ol><p>因此，解决上述不足的方法是引入稀疏特性和将全连接层转换成稀疏连接。这个思路的缘由来自于两方面：</p><ol><li>生物的神经系统连接是稀疏的；</li><li>有文献指出：如果数据集的概率分布能够被大型且非常稀疏的DNN网络所描述的话，那么通过分析前面层的激活值的相关统计特性和将输出高度相关的神经元进行聚类，便可逐层构建出最优的网络拓扑结构。</li></ol><p>说明臃肿的网络可以被不失性能地简化。</p><p>但是，现在的计算框架对非均匀的稀疏数据进行计算是非常低效的，主要是因为查找和缓存的开销。因此，作者提出了一个想法，既能保持滤波器级别的稀疏特性，又能充分密集矩阵的高计算性能。有大量文献指出，将稀疏矩阵聚类成相对密集的子矩阵，能提高计算性能。根据此想法，提出了Inception结构。</p><p>inception结构的主要思路是：如何使用一个密集成分来近似或者代替最优的局部稀疏结构。inception V1的结构如下面两个图所示。</p><p><a href="https://imgchr.com/i/NQeZss" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/20/NQeZss.md.png" alt="NQeZss.md.png"></a></p><p>对于上图中的（a）做出几点解释：</p><ol><li>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； </li><li>之所以卷积核大小采用1、3和5，主要是为了方便对齐；</li><li>文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了；</li><li>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</li></ol><p>但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN，采用1x1卷积核来进行降维，如图中（b）所示。</p><p>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据的大小为100x100x256。其中，卷积层的参数为5x5x128x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据的大小仍为100x100x256，但卷积参数量已经减少为1x1x128x32 + 5x5x32x256，大约减少了4倍。</p><p>在inception结构中，大量采用了1x1的矩阵，主要是两点作用：</p><ol><li>对数据进行降维</li><li>引入更多的非线性，提高泛化能力，因为卷积后要经过ReLU激活函数</li></ol><h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p>GoogLeNet是由inception模块进行组成的，结构太大了，就不放出来了，这里做出几点说明：</p><p>　　a）GoogLeNet采用了模块化的结构，方便增添和修改；</p><p>　　b）网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune;</p><p>　　c）虽然移除了全连接，但是网络中依然使用了Dropout；</p><p>　　d）为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看源码中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</p><h4 id="note-1x1的卷积核的作用"><a href="#note-1x1的卷积核的作用" class="headerlink" title="note:1x1的卷积核的作用"></a>note:1x1的卷积核的作用</h4><h5 id="灵活的控制特征图的深度"><a href="#灵活的控制特征图的深度" class="headerlink" title="灵活的控制特征图的深度"></a>灵活的控制特征图的深度</h5><p>1x1的卷积核由于大小只有1x1，所以并不需要考虑像素跟周边像素的关系，它主要用于调节通道数，对不同的通道上的像素点进行线性组合，然后进行非线性化操作，可以完成升维和降维的功能，如下图所示，选择2个1x1大小的卷积核，那么特征图的深度将会从3变成2，如果使用4个1x1的卷积核，特征图的深度将会由3变成4。<br><a href="https://imgchr.com/i/NQeqwq" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/20/NQeqwq.md.png" alt="NQeqwq.md.png"></a></p><h5 id="减少参数"><a href="#减少参数" class="headerlink" title="减少参数"></a>减少参数</h5><p>前面所说的降维，其实也是减少了参数，因为特征图少了，参数也自然跟着就减少，相当于在特征图的通道数上进行卷积，压缩特征图，二次提取特征，使得新特征图的特征表达更佳。接着再通过两个例子来看看它是如何减少参数的。<br>在GoogleNet的3a模块，假设输入特征图的大小是28*28*192,1x1卷积通道为64,3x3卷积通道为128,5x5卷积通道为32，左边的卷积核参数计算如下：<br>192 × (1×1×64) +192 × (3×3×128) + 192 × (5×5×32) = 387072<br>而右图的3x3卷积层前加入通道数为96的1x1的卷积，5x5的特征图前加入通道数为16的1x1的卷积，参数的计算如下：<br>192 × (1×1×64) +（192×1×1×96+ 96 × 3×3×128）+（192×1×1×16+16×5×5×32）= 157184</p><p>Factorizing Convolutions with Large Filter Size，也就是分解大的卷积，用小的卷积核替换大的卷积核，因为大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。因此可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量),也就产生了Inception V2;而nxn的卷积核又可以通过1xn卷积后接nx1卷积来替代,也就是Inception V3结构,但是作者发现在网络的前期使用这种分解效果并不好，还有在中度大小的feature map上使用效果才会更好。（对于mxm大小的feature map,建议m在12到20之间）.</p><p>如下图：从左到右是Inception V1~IncVeption V3,需要指出的是将7´7卷积拆成1x7卷积和7x1卷积，比拆成3个3x3卷积更节约参数。</p><p><a href="https://imgchr.com/i/NQmNcQ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/20/NQmNcQ.md.png" alt="NQmNcQ.md.png"></a></p><h5 id="现了跨通道的信息组合，并增加了非线性特征"><a href="#现了跨通道的信息组合，并增加了非线性特征" class="headerlink" title="现了跨通道的信息组合，并增加了非线性特征"></a>现了跨通道的信息组合，并增加了非线性特征</h5><p>使用1*1卷积核，实现降维和升维的操作其实就是channel间信息的线性组合变化，3*3，64channels的卷积核前面添加一个1*1，28channels的卷积核，就变成了3*3，28channels的卷积核，原来的64个channels就可以理解为跨通道线性组合变成了28channels，这就是通道间的信息交互。因为1*1卷积核，可以在保持feature map尺度不变的（即不损失分辨率）的前提下大幅增加非线性特性（利用后接的非线性激活函数），把网络做的很deep，增加非线性特性。</p><h3 id="Inception-v2"><a href="#Inception-v2" class="headerlink" title="Inception v2"></a>Inception v2</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>Inception v2来自于论文《Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift》。</p><p>训练DNN网络的一个难点是，在训练时每层输入数据的分布会发生改变，所以需要较低的学习率和精心设置初始化参数。只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。作者把网络中间层在训练过程中，数据分布的改变称之为：“Internal  Covariate Shift”。因此，作者提出对数据做归一化的想法。</p><p>对数据进行了BN算法后，具有以下的优点：</p><ol><li>可以设置较大的初始学习率，并且减少对参数初始化的依赖，提高了训练速度；</li><li>这是个正则化模型，因此可以去除dropout和降低L2正则约束参数；</li><li>不需要局部响应归一化层；</li><li>能防止网络陷入饱和，即消除梯度消失</li></ol><h4 id="BN算法"><a href="#BN算法" class="headerlink" title="BN算法"></a>BN算法</h4><p>BN算法通过下面公式，对某一层进行归一化处理，也叫近似白化预处理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\hat&#123;x&#125;^&#123;(k)&#125; &#x3D; \frac&#123;x^&#123;(k)&#125;-E[x^&#123;(k)&#125;]&#125;&#123;\sqrt&#123;Var(x^&#123;(k)&#125;)&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>其中，由于我们是采用批量梯度下降法的，所以<code>$E[x^{(k)}]$</code>是指在一批数据中，各神经元的平均值；𝑉𝑎𝑟(𝑥(𝑘))是指在一批训练数据时各神经元输入值的标准差。</p><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>ResNet是当前应用最为广泛的CNN特征提取网络。</p><p>VGG网络试着探寻了一下深度学习网络的深度究竟可以深几许以能持续地提高分类准确率。我们的一般印象当中，深度学习愈是深（复杂，参数多）愈是有着更强的表达能力。凭着这一基本准则CNN分类网络自Alexnet的7层发展到了VGG的16乃至19层，后来更有了Googlenet的22层。可后来我们发现深度CNN网络达到一定深度后再一味地增加层数并不能带来进一步地分类性能提高，反而会招致网络收敛变得更慢，test dataset的分类准确率也变得更差。排除数据集过小带来的模型过拟合等问题后，我们发现过深的网络仍然还会使分类准确度下降（相对于较浅些的网络而言）。</p><p><a href="https://imgchr.com/i/NldRdP" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/20/NldRdP.md.png" alt="NldRdP.md.png"></a></p><h1 id="目标检测"><a href="#目标检测" class="headerlink" title="目标检测"></a>目标检测</h1><h2 id="一文读懂目标检测-（R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD）"><a href="#一文读懂目标检测-（R-CNN-Fast-R-CNN-Faster-R-CNN-YOLO-SSD）" class="headerlink" title="一文读懂目标检测 （R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD）"></a>一文读懂目标检测 （R-CNN, Fast R-CNN, Faster R-CNN, YOLO, SSD）</h2><p><a href="https://blog.csdn.net/gdfyug/article/details/84195634" target="_blank" rel="noopener">https://blog.csdn.net/gdfyug/article/details/84195634</a></p><p><strong>RCNN</strong></p><ol><li>在图像中确定约1000-2000个候选框 (使用选择性搜索Selective Search)</li><li>每个候选框内图像块缩放至相同大小，并输入到CNN内进行特征提取</li><li>对候选框中提取出的特征，使用分类器判别是否属于一个特定类</li><li>对于属于某一类别的候选框，用回归器进一步调整其位置</li></ol><p><strong>Fast R-CNN</strong></p><ol><li>在图像中确定约1000-2000个候选框 (使用选择性搜索)</li><li>对整张图片输进CNN，得到feature map</li><li>找到每个候选框在feature map上的映射patch，将此patch作为每个候选框的卷积特征输入到SPP layer和之后的层</li><li>对候选框中提取出的特征，使用分类器判别是否属于一个特定类</li><li>对于属于某一类别的候选框，用回归器进一步调整其位置</li></ol><p><strong>Faster R-CNN</strong></p><ol><li>对整张图片输进CNN，得到feature map</li><li>卷积特征输入到RPN，得到候选框的特征信息</li><li>对候选框中提取出的特征，使用分类器判别是否属于一个特定类</li><li>对于属于某一类别的候选框，用回归器进一步调整其位置</li></ol><p>简言之，即如本文开头所列</p><p>R-CNN（Selective Search + CNN + SVM）</p><p>SPP-net（ROI Pooling）</p><p>Fast R-CNN（Selective Search + CNN + ROI）</p><p>Faster R-CNN（RPN + CNN + ROI）</p><p><strong>YOLO</strong></p><ol><li>给个一个输入图像，首先将图像划分成7*7的网格</li><li>对于每个网格，我们都预测2个边框（包括每个边框是目标的置信度以及每个边框区域在多个类别上的概率）</li><li>根据上一步可以预测出7<em>7</em>2个目标窗口，然后根据阈值去除可能性比较低的目标窗口，最后NMS去除冗余窗口即可</li></ol><p>（非极大值抑制NMS：<a href="https://www.julyedu.com/question/big/kp_id/26/ques_id/2141）。" target="_blank" rel="noopener">https://www.julyedu.com/question/big/kp_id/26/ques_id/2141）。</a></p><p>可以看到整个过程非常简单，不再需要中间的region proposal找目标，直接回归便完成了位置和类别的判定。</p><p>YOLO将目标检测任务转换成一个回归问题，大大加快了检测的速度，使得YOLO可以每秒处理45张图像。而且由于每个网络预测目标窗口时使用的是全图信息，使得false positive比例大幅降低（充分的上下文信息）。</p><p>但是YOLO也存在问题：没有了Region Proposal机制，只使用7*7的网格回归会使得目标不能非常精准的定位，这也导致了YOLO的检测精度并不是很高。</p><h2 id="SSD-（Single-Shot-MultiBox-Detector）"><a href="#SSD-（Single-Shot-MultiBox-Detector）" class="headerlink" title="SSD （Single Shot MultiBox Detector）"></a>SSD （Single Shot MultiBox Detector）</h2><p><a href="https://blog.csdn.net/qianqing13579/article/details/82106664" target="_blank" rel="noopener">https://blog.csdn.net/qianqing13579/article/details/82106664</a></p><p><a href="https://www.cnblogs.com/MY0213/p/9858383.html" target="_blank" rel="noopener">https://www.cnblogs.com/MY0213/p/9858383.html</a></p><p><a href="https://imgchr.com/i/NG46jH" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NG46jH.md.png" alt="NG46jH.md.png"></a></p><p><a href="https://imgchr.com/i/NGIRtP" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NGIRtP.md.png" alt="NGIRtP.md.png"></a></p><p><a href="https://imgchr.com/i/NGIWff" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NGIWff.md.png" alt="NGIWff.md.png"></a></p><p><strong>SSD算法步骤</strong></p><ol><li><p>输入一幅图片（200x200），将其输入到预训练好的分类网络中来获得不同大小的特征映射，修改了传统的VGG16网络；</p><p> SSD将backbone中fc6改为3 <em> 3卷积层，fc7改为1 </em> 1卷积层，池化层pool5由原来的stride=2的2 <em> 2变成stride=1的3 </em> 3。为了不改变特征图的大小，同时获得更大的感受野，Conv6为空洞卷积，dilation=6。在backbone之后增加了8个卷积层(Extra Feature Layers)。</p></li></ol><p>note:下采样和扩张卷积可以增大感受野</p><ol><li><p>网络中共有6个卷积层（Conv4_3, Conv7, Conv8_2, Conv9_2, Conv10_2, Conv11_2）的特征图被用来进行检测，6个特征图分别预测不同大小(scales)和长宽比(ratios)的边界框。<br> SSD为每个检测层都预定义了不同大小的先验框(Prior boxes), Conv4_3、Conv10_2和Conv11_2分别有4种先验框，而Conv7、Conv8_2和Conv9_2分别有6种先验框，即对应于特征图上的每个像素，都会生成K（prior box种类）个prior box。prior box类似于Faster rcnn中的anchor。<br> 网络6个检测层总共预测的边界框数目为8732（38 <em> 38 </em> 4 + 19 <em> 19 </em> 6 + 10 <em> 10 </em> 6 + 5 <em> 5 </em> 6 + 3 <em> 3 </em> 4 + 1 <em> 1 </em> 4）。</p></li><li><p>将不同feature map获得的BB结合起来，经过NMS（非极大值抑制）方法来抑制掉一部分重叠或者不正确的BB，生成最终的BB集合（即检测结果）；</p></li></ol><p>SSD论文贡献：</p><ol><li>引入了一种单阶段的检测器，比以前的算法YOLO更准更快，并没有使用RPN和Pooling操作；</li><li>使用一个小的卷积滤波器应用在不同的feature map层从而预测BB的类别的BB偏差；</li><li>可以在更小的输入图片中得到更好的检测效果（相比Faster-rcnn）；</li><li>在多个数据集（PASCAL、VOC、COCO、ILSVRC）上面的测试结果表明，它可以获得更高的mAp值</li></ol><p>Detector和Classfier对每个特征图使用不同的3 <em> 3卷积核进行预测，卷积核的数目由每个特征图上定义的priors box种类决定。比如Conv4_3输出的特征图，定义了4种prior box，那么Detector得到的特征图通道数为4 </em> 4，Classifier得到的特征图通道数为4 * 21(voc类别数，包含背景)。</p><p>Detector输出每个prior box的坐标偏移，Classifier输出每个类的类别概率得分。</p><p>网络输入大小为300 * 300，数据集使用Voc数据集（20个类别）。</p><p><a href="https://imgchr.com/i/NJSmJe" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJSmJe.md.png" alt="NJSmJe.md.png"></a></p><p>如上图所示，我们可以看到左边的方法针对输入的图片获取不同尺度的特征映射，但是在预测阶段仅仅使用了最后一层的特征映射；而SSD不仅获得不同尺度的特征映射，同时在不同的特征映射上面进行预测，它在增加运算量的同时可能会提高检测的精度，因为它具有更多的可能性。</p><h3 id="Prior-Box"><a href="#Prior-Box" class="headerlink" title="Prior Box"></a>Prior Box</h3><p>缩进在SSD中引入了Prior Box，实际上与anchor非常类似，就是一些目标的预选框，后续通过softmax分类+bounding box regression获得真实目标的位置。SSD按照如下规则生成prior box：</p><ul><li>以feature map上每个点的中点为中心（offset=0.5），生成一些列同心的prior box（然后中心点的坐标会乘以step，相当于从feature map位置映射回原图位置）<ul><li>正方形prior box最小边长为<code>$min_{size}$</code>,最大边长为<code>$\sqrt{min_{size}*max_{siza}}$</code></li><li>每在prototxt设置一个aspect ratio，会生成2个长方形，长宽为：<code>$\sqrt{aspect_{ratio}}*min_{size}$</code>和<code>$1/\sqrt{aspect_{ratio}}*min_size$</code></li></ul></li></ul><p><a href="https://imgchr.com/i/NGqatA" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NGqatA.md.png" alt="NGqatA.md.png"></a></p><ul><li>而每个feature map对应prior box的min_size和max_size由以下公式决定，公式中m是使用feature map的数量（SSD 300中m=6），6个特征图的尺寸分别为(38, 19, 10, 5, 3, 1), 它们对应的先验框尺寸随着特征图的缩小线性增大：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_k &#x3D; s_&#123;min&#125; + \frac&#123;s_&#123;max&#125;-s_&#123;min&#125;&#125;&#123;m-1&#125;(k-1),\quad k \in [1,m]</span><br></pre></td></tr></table></figure></li></ul><p>第一层feature map对应的min_size=S1，max_size=S2；第二层min_size=S2，max_size=S3；其他类推。</p><p>Sk表示先验框大小和图片大小的比例，Smin表示最小比例，设为0.2，Smax表示最大比例，设为0.9 。对于第一个特征图Conv4_3，比例单独设置为Smin/2 = 0.1，其对应大小为300 * 0.1 = 30。</p><p>对于之后的特征图，先验框的大小按照上面的公式线性增加，但是需现将比例扩大100倍：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_k &#x3D; s_&#123;min&#125; + \frac&#123;s_&#123;max&#125;*100-s_&#123;min&#125;*100&#125;&#123;m-1&#125;(k-1),\quad k \in [1,m]</span><br></pre></td></tr></table></figure><br>这样计算的step = (90 - 20)/(5 - 1)=17.5，由于像素已经是最小单位，不可再分，需要对步长进行取整，step=17, 从而得到第二层及之后Sk*100 = (20，37, 54, 71, 88), 接着再除以100，就得到一组近似的缩放比(0.1, 0.2, 0.37, 0.54, 0.71, 0.88)，使用这组缩放比来计算先验框的尺寸，6个特征图对应的先验框尺寸分别为30，60，111，162，213，264。</p><div class="table-container"><table><thead><tr><th></th><th>min_size</th><th>max_size</th></tr></thead><tbody><tr><td>conv4_3</td><td>30</td><td>60</td></tr><tr><td>fc7</td><td>60</td><td>111</td></tr><tr><td>conv6_2</td><td>111</td><td>162</td></tr><tr><td>conv7_2</td><td>162</td><td>213</td></tr><tr><td>conv8_2</td><td>213</td><td>264</td></tr><tr><td>conv9_2</td><td>264</td><td>315</td></tr></tbody></table></div><p>不过依然可以看出，SSD使用低层feature map检测小目标，使用高层feature map检测大目标，这也应该是SSD的突出贡献了。</p><p>得到每个特征图对应的基础先验框尺寸（最中间小正方形的大小）后，需要根据基础尺寸来生成k个先验框。基础先验框尺寸对应特征图定义的最小正方形先验框，最外侧大正方形先验框的尺寸为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">s_k^&#39; &#x3D; \sqrt&#123;s_k * s_&#123;k+1&#125;&#125;</span><br></pre></td></tr></table></figure><br>而最后一层最大的正方形先验框尺寸直接通过300 * 1.05=315给出。</p><p>正方形的尺寸确定了，那长方形先验框的尺寸如何确定呢，网络定义了一组长宽比ar={1, 2, 3, 1/2, 1/3}, Sk为基础框尺寸。只定义了4种先验框的特征图，不会使用3和1/3两种长宽比。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w_k^a &#x3D; s_k \sqrt&#123;a_r&#125;, \quad h^a_k &#x3D; \frac&#123;s_k&#125;&#123;a_r&#125;</span><br></pre></td></tr></table></figure><br>每个单元先验框的中心处于每个单元的中心，即：<br><code>$(\frac{1+0.5}{|f_k|},\frac{j+0.5}{|f_k|}), i,j, \in [0,|f_k|]$</code>,其中<code>$f_k$</code>为特征图大小。<br>需要注意的是，以上计算的先验框的尺寸，都是根据输入图像的大小来计算的。</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>SSD网络的关键在于MultiBox detection, 多个特征图多尺度检测。之后的Yolov3中同样借鉴了这个思路。同时它还使用了更多的精心挑选的先验框（一共30种先验框，共8732个），让网络的的检测效果更好。SSD对小目标的检测效果之所以不太好，主要原因可能在于，大的特征图负责检测小物体，小的特征图负责检测大的物体，大的特征图具有更多的位置信息，但缺少足够的语义信息，而小的特征图具有更多的语义信息，却因为不断的下采样丢失了大量的位置信息。之后的Yolov3在借鉴SSD多尺度多框思路的同时，也利用了跳过连接，融合高分辨率的特征图和包含更多语义信息的特征图，从而更好的定位。</p><p>SSD效果好主要有三点原因：</p><ol><li>多尺度</li><li>设置了多种宽高比的anchor</li><li>数据增强</li></ol><h2 id="FPN-（Feature-Pyramid-Networks）"><a href="#FPN-（Feature-Pyramid-Networks）" class="headerlink" title="FPN （Feature Pyramid Networks）"></a>FPN （Feature Pyramid Networks）</h2><p>reference：<a href="https://www.jianshu.com/p/5a28ae9b365d" target="_blank" rel="noopener">https://www.jianshu.com/p/5a28ae9b365d</a></p><p>特征金字塔可以在速度和准确率之间进行权衡，可以通过它获得更加鲁棒的语义信息。图像中存在不同尺寸的目标，而不同的目标具有不同的特征，利用浅层的特征就可以将简单的目标的区分开来；利用深层的特征可以将复杂的目标区分开来。</p><p>FPN是一种利用常规CNN模型来高效提取图片中各维度特征的方法。在计算机视觉学科中，多维度的目标检测一直以来都是通过将缩小或扩大后的不同维度图片作为输入来生成出反映不同维度信息的特征组合。这种办法确实也能有效地表达出图片之上的各种维度特征，但却对硬件计算能力及内存大小有较高要求，因此只能在有限的领域内部使用。</p><p>FPN通过利用常规CNN模型内部从底至上各个层对同一scale图片不同维度的特征表达结构，提出了一种可有效在单一图片视图下生成对其的多维度特征表达的方法。它可以有效地赋能常规CNN模型，从而可以生成出表达能力更强的feature maps以供下一阶段计算机视觉任务像object detection/semantic segmentation等来使用。本质上说它是一种加强主干网络CNN特征表达的方法。</p><p>下图中描述了四种不同的得到一张图片多维度特征组合的方法。</p><p><a href="https://imgchr.com/i/NJPxgg" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJPxgg.md.png" alt="NJPxgg.md.png"></a></p><p>上图(a)中的方法即为常规的生成一张图片的多维度特征组合的经典方法。即对某一输入图片我们通过压缩或放大从而形成不同维度的图片作为模型输入，使用同一模型对这些不同维度的图片分别处理后，最终再将这些分别得到的特征（feature maps）组合起来就得到了我们想要的可反映多维度信息的特征集。此种方法缺点在于需要对同一图片在更改维度后输入处理多次，因此对计算机的算力及内存大小都有较高要求。</p><p>图(b)中的方法则只拿单一维度的图片做为输入，然后经CNN模型处理后，拿最终一层的feature maps作为最终的特征集。显然此种方法只能得到单一维度的信息。优点是计算简单，对计算机算力及内存大小都无过高需求。此方法为大多数R-CNN系列目标检测方法所用像R-CNN/Fast-RCNN/Faster-RCNN等。因此最终这些模型对小维度的目标检测性能不是很好。</p><p>图(c)中的方法同样是拿单一维度的图片做为输入，不过最终选取用于接下来分类或检测任务时的特征组合时，此方法不只选用了最后一层的high level feature maps，同样也会选用稍靠下的反映图片low level 信息的feature maps。然后将这些不同层次（反映不同level的图片信息）的特征简单合并起来（一般为concat处理），用于最终的特征组合输出。此方法可见于SSD当中。不过SSD在选取层特征时都选用了较高层次的网络。比如在它以VGG16作为主干网络的检测模型里面所选用的最低的Convolution的层为Conv4，这样一些具有更低级别信息的层特征像Conv2/Conv3就被它给漏掉了，于是它对更小维度的目标检测效果就不大好。</p><p>图(d)中的方法同图(c)中的方法有些类似，也是拿单一维度的图片作为输入，然后它会选取所有层的特征来处理然后再联合起来做为最终的特征输出组合。（作者在论文中拿Resnet为实例时并没选用Conv1层，那是为了算力及内存上的考虑，毕竟Conv1层的size还是比较大的，所包含的特征跟直接的图片像素信息也过于接近）。另外还对这些反映不同级别图片信息的各层自上向下进行了再处理以能更好地组合从而形成较好的特征表达（详细过程会在下面章节中进一步介绍）。而此方法正是我们本文中要讲的FPN CNN特征提取方法。</p><h3 id="FPN基本架构"><a href="#FPN基本架构" class="headerlink" title="FPN基本架构"></a>FPN基本架构</h3><p>FPN会使用CNN网络中每一层的信息来生成最后的表达特征组合。下图是它的基本架构。从中我们能看到FPN会模型每个CNN层的特征输出进行处理以生成反映此维度信息的特征。而自上至下处理后所生成出的特征之间也有个关联关系，即上层high level的特征会影响下一层次的low level特征表达。最终所有的特征一起用来作为下一步的目标检测或类别分析等任务的输入。</p><p><a href="https://imgchr.com/i/NJiBIP" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJiBIP.md.png" alt="NJiBIP.md.png"></a></p><h3 id="FPN详细介绍"><a href="#FPN详细介绍" class="headerlink" title="FPN详细介绍"></a>FPN详细介绍</h3><p>FPN是传统CNN网络对图片信息进行表达输出的一种增强。它目的是为了改进CNN网络的特征提取方式，从而可以使最终输出的特征更好地表示出输入图片各个维度的信息。它的基本过程有三个分别为：自下至上的通路即自下至上的不同维度特征生成；自上至下的通路即自上至下的特征补充增强；CNN网络层特征与最终输出的各维度特征之间的关联表达。</p><p><a href="https://imgchr.com/i/NJAlan" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJAlan.md.png" alt="NJAlan.md.png"></a></p><ul><li>自下至上的通路（Bottom-top pathway）：这个没啥奇怪就是指的普通CNN特征自底至上逐层浓缩表达特征的一个过程。此过程很早即被认识到了即较底的层反映较浅层次的图片信息特征像边缘等；较高的层则反映较深层次的图片特征像物体轮廓、乃至类别等；</li><li>自上至下的通路（Top-bottome pathway）：上层的特征输出一般其feature map size比较小，但却能表示更大维度（同时也是更加high level）的图片信息。此类high level信息经实验证明能够对后续的目标检测、物体分类等任务发挥关键作用。因此我们在处理每一层信息时会参考上一层的high level信息做为其输入（这里只是在将上层feature map等比例放大后再与本层的feature maps做element wise相加）;</li><li>NN层特征与每一级别输出之间的表达关联：在这里作者实验表明使用1x1的Conv即可生成较好的输出特征，它可有效地降低中间层次的channels 数目。最终这些1x1的Convs使得我们输出不同维度的各个feature maps有着相同的channels数目（本文用到的Resnet-101主干网络中，各个层次特征的最终输出channels数目为256）。</li></ul><h1 id="图像分割"><a href="#图像分割" class="headerlink" title="图像分割"></a>图像分割</h1><h2 id="FCN-（Fully-Convolutional-Networks）"><a href="#FCN-（Fully-Convolutional-Networks）" class="headerlink" title="FCN （Fully Convolutional Networks）"></a>FCN （Fully Convolutional Networks）</h2><p>《Fully Convolutional Networks for Semantic Segmentation》</p><p>reference：<a href="https://blog.csdn.net/shenxiaolu1984/article/details/51348149#fn:2" target="_blank" rel="noopener">https://blog.csdn.net/shenxiaolu1984/article/details/51348149#fn:2</a></p><h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p>该论文包含了当下CNN的三个思潮 </p><ul><li>不含全连接层(fc)的全卷积(fully conv)网络。可适应任意尺寸输入。 </li><li>增大数据尺寸的反卷积(deconv)层。能够输出精细的结果。 </li><li>结合不同深度层结果的跳级(skip)结构。同时确保鲁棒性和精确性。</li></ul><p>一些重点：</p><ul><li>损失函数是在最后一层的 spatial map上的 pixel 的 loss 和，在每一个 pixel 使用 softmax loss</li><li>使用 skip 结构融合多层（3层）输出，底层网络应该可以预测更多的位置信息，因为他的感受野小可以看到小的 pixels</li><li>上采样 lower-resolution layers 时，如果采样后的图因为 padding 等原因和前面的图大小不同，使用 crop ，当裁剪成大小相同的，spatially aligned ，使用 concat 操作融合两个层</li></ul><h4 id="CNN与FCN"><a href="#CNN与FCN" class="headerlink" title="CNN与FCN"></a>CNN与FCN</h4><p>通常cnn网络在卷积之后会接上若干个全连接层，将卷积层产生的特征图（feature map）映射成为一个固定长度的特征向量。一般的CNN结构适用于图像级别的分类和回归任务，因为它们最后都期望得到输入图像的分类的概率，如ALexNet网络最后输出一个1000维的向量表示输入图像属于每一类的概率。</p><p>FCN对图像进行像素级的分类，从而解决了语义级别的图像分割问题。与经典的CNN在卷积层使用全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷基层的特征图（feature map）进行上采样，使它恢复到输入图像相同的尺寸，从而可以对每一个像素都产生一个预测，同时保留了原始输入图像中的空间信息，最后奇偶在上采样的特征图进行像素的分类。</p><p>全卷积网络(FCN)是从抽象的特征中恢复出每个像素所属的类别。即从图像级别的分类进一步延伸到像素级别的分类。</p><p>FCN将传统CNN中的全连接层转化成一个个的卷积层。如下图所示，在传统的CNN结构中，前5层是卷积层，第6层和第7层分别是一个长度为4096的一维向量，第8层是长度为1000的一维向量，分别对应1000个类别的概率。FCN将这3层表示为卷积层，卷积核的大小(通道数，宽，高)分别为（4096,7,7）、（4096,1,1）、（1000,1,1）。所有的层都是卷积层，故称为全卷积网络。</p><p><a href="https://imgchr.com/i/NJew6K" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJew6K.md.png" alt="NJew6K.md.png"></a></p><p>简单的说，FCN与CNN的区别在于FCN把CNN最后的全连接层换成卷积层，输出一张已经label好的图。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>网络结构如下。输入可为任意尺寸图像彩色图像；输出与输入尺寸相同，深度为：20类目标+背景=21。 （在PASCAL数据集上进行的，PASCAL一共20类）</p><p><a href="https://imgchr.com/i/NJ1QZ6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJ1QZ6.md.png" alt="NJ1QZ6.md.png"></a></p><h4 id="全卷积-提取特征"><a href="#全卷积-提取特征" class="headerlink" title="全卷积-提取特征"></a>全卷积-提取特征</h4><p>虚线上半部分为全卷积网络。（蓝：卷积，绿：max pooling）。对于不同尺寸的输入图像，各层数据的尺寸（height，width）相应变化，深度（channel）不变。<br>这部分由深度学习分类问题中经典网络AlexNet1修改而来。只不过，把最后两个全连接层（fc）改成了卷积层。</p><h4 id="逐像素预测"><a href="#逐像素预测" class="headerlink" title="逐像素预测"></a>逐像素预测</h4><p>虚线下半部分中，分别从卷积网络的不同阶段，以卷积层（蓝色×3）预测深度为21的分类结果。</p><p>怎么具体逐像素点预测分类的：<a href="http://www.cnblogs.com/gujianhan/p/6030639.html" target="_blank" rel="noopener">http://www.cnblogs.com/gujianhan/p/6030639.html</a></p><p>采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。</p><p>经过多次卷积和pooling以后，得到的图像越来越小，分辨率越来越低。其中图像到 H/32∗W/32 的时候图片是最小的一层时，所产生图叫做<strong>heatmap热图</strong>，热图就是我们最重要的<strong>高维特征图</strong>。</p><p>得到高维特征的heatmap之后就是最重要的一步也是最后的一步对原图像进行upsampling，把图像进行放大、放大、放大，到原图像的大小。</p><p>（也就是将高维特征图翻译成原图时对应的分割图像！！）</p><p>最后的输出是21张heatmap经过upsampling变为原图大小的图片，为了对每个像素进行分类预测label成最后已经进行语义分割的图像，这里有一个小trick，就是最后通过逐个像素地求其在21张图像该像素位置的最大数值描述（概率）作为该像素的分类。因此产生了一张已经分类好的图片。</p><h4 id="反卷积-升采样"><a href="#反卷积-升采样" class="headerlink" title="反卷积-升采样"></a>反卷积-升采样</h4><h5 id="上采样-Upsample"><a href="#上采样-Upsample" class="headerlink" title="上采样(Upsample)"></a>上采样(Upsample)</h5><p>在应用在计算机视觉的深度学习领域，由于输入图像通过卷积神经网络(CNN)提取特征后，输出的尺寸往往会变小，而有时我们需要将图像恢复到原来的尺寸以便进行进一步的计算(e.g.:图像的语义分割)，这个采用扩大图像尺寸，实现图像由小分辨率到大分辨率的映射的操作，叫做上采样(Upsample)。</p><h5 id="反卷积-Transposed-Convolution"><a href="#反卷积-Transposed-Convolution" class="headerlink" title="反卷积(Transposed Convolution)"></a>反卷积(Transposed Convolution)</h5><p>上采样有3种常见的方法：双线性插值(bilinear)，反卷积(Transposed Convolution)，反池化(Unpooling)，我们这里只讨论反卷积。这里指的反卷积，也叫转置卷积，它并不是正向卷积的完全逆过程，用一句话来解释：反卷积是一种特殊的正向卷积，先按照一定的比例通过补  来扩大输入图像的尺寸，接着旋转卷积核，再进行正向卷积。</p><p>卷积计算公式：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">o&#x3D;\frac&#123;i+2p-k&#125;&#123;s&#125; +1</span><br></pre></td></tr></table></figure><br>i:输入图像大小<br>p:padding<br>s:strides 步长<br>k:kernel大小</p><p><a href="https://imgchr.com/i/NJcDuq" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJcDuq.md.png" alt="NJcDuq.md.png"></a></p><p>反卷积输出图片的尺寸会大于输入图片的尺寸，通过增加padding来实现这一操作，上图展示的是一个strides(步长)为1的反卷积。下面看一个strides不为1的反卷积</p><p><a href="https://imgchr.com/i/NJcRC4" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJcRC4.md.png" alt="NJcRC4.md.png"></a></p><p>上图中的反卷积的stride为2，通过间隔插入padding来实现的。同样，可以根据反卷积的o、s、k、po、s、k、po、s、k、p参数来计算反卷积的输出iii，也就是卷积的输入。公式如下：i=(o−1)∗s+k−2∗pi=(o-1)*s+k-2*p, 其实就是根据上式推导出来的。</p><p>note: 反卷积只能恢复尺寸，不能恢复数值</p><p>这里图像的反卷积与下图的full卷积原理是一样的，使用了这一种反卷积手段使得图像可以变大，FCN作者使用的方法是这里所说反卷积的一种变体，这样就可以获得相应的像素值，图像可以实现end to end。</p><p>（feature map值与权重不同，生成的上采样的二值区域也是不一样的。）</p><p><a href="https://imgchr.com/i/NJyCaF" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJyCaF.md.png" alt="NJyCaF.md.png"></a></p><p>输入：每个像素值等于filter的权重  <br>输出：步长为stride，截取的宽度为pad。</p><h4 id="跳级结构"><a href="#跳级结构" class="headerlink" title="跳级结构"></a>跳级结构</h4><p>下半部分，使用逐数据相加（黄色×2），把三个不同深度的预测结果进行融合：较浅的结果更为精细，较深的结果更为鲁棒。</p><p>在融合之前，使用裁剪层（灰色×2）统一两者大小。最后裁剪成和输入相同尺寸输出。</p><h4 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h4><ol><li>以经典的分类网络为初始化。最后两级是全连接，参数弃去不用。</li><li>从特征小图（16*16*4096）预测分割小图（16*16*21），之后直接升采样为大图。<br>反卷积（橙色）的步长为32，这个网络称为FCN-32s。<br>这一阶段使用单GPU训练约需3天。</li></ol><p><a href="https://imgchr.com/i/NJRFjs" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJRFjs.md.png" alt="NJRFjs.md.png"></a></p><ol><li>升采样分为两次完成（橙色×2）。<br>在第二次升采样前，把第4个pooling层（绿色）的预测结果（蓝色）融合进来。使用跳级结构提升精确性。<br>第二次反卷积步长为16，这个网络称为FCN-16s。<br>这一阶段使用单GPU训练约需1天。</li></ol><p><a href="https://imgchr.com/i/NJWExH" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJWExH.md.png" alt="NJWExH.md.png"></a></p><ol><li>升采样分为三次完成（橙色×3）。<br>进一步融合了第3个pooling层的预测结果。<br>第三次反卷积步长为8，记为FCN-8s。<br>这一阶段使用单GPU训练约需1天。</li></ol><p><a href="https://imgchr.com/i/NJWYss" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJWYss.md.png" alt="NJWYss.md.png"></a></p><p>较浅层的预测结果包含了更多细节信息。比较2,3,4阶段可以看出，跳级结构利用浅层信息辅助逐步升采样，有更精细的结果</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>总体来说，本文的逻辑如下：</p><ul><li>想要精确预测每个像素的分割结果</li><li>必须经历从大到小，再从小到大的两个过程</li><li>在升采样过程中，分阶段增大比一步到位效果更好</li><li>在升采样的每个阶段，使用降采样对应层的特征进行辅助</li></ul><h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h2><p>reference：<a href="https://blog.csdn.net/wangdongwei0/article/details/83110305" target="_blank" rel="noopener">https://blog.csdn.net/wangdongwei0/article/details/83110305</a></p><p>reference：<a href="https://blog.csdn.net/WZZ18191171661/article/details/79453780" target="_blank" rel="noopener">https://blog.csdn.net/WZZ18191171661/article/details/79453780</a></p><p>Mask R-CNN是一个实例分割（Instance segmentation）算法，可以用来做“目标检测”、“目标实例分割”、“目标关键点检测”。</p><p><a href="https://imgchr.com/i/NJf8k6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NJf8k6.md.png" alt="NJf8k6.md.png"></a></p><h3 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h3><ul><li>Mask RCNN可以看做是一个通用实例分割架构。</li><li>Mask RCNN以Faster RCNN原型，增加了一个分支用于分割任务。</li><li>Mask RCNN比Faster RCNN速度慢一些，达到了5fps。</li><li>可用于人的姿态估计等其他任务；</li></ul><p>高速和高准确率：作者选用了经典的目标检测算法Faster-rcnn和经典的语义分割算法FCN。Faster-rcnn可以既快又准的完成目标检测的功能；FCN可以精准的完成语义分割的功能，这两个算法都是对应领域中的经典之作。Mask R-CNN比Faster-rcnn复杂，但是最终仍然可以达到5fps的速度，这和原始的Faster-rcnn的速度相当。由于发现了ROI Pooling中所存在的像素偏差问题，提出了对应的ROIAlign策略，加上FCN精准的像素MASK，使得其可以获得高准确率。</p><p>简单直观：整个Mask R-CNN算法的思路很简单，就是在原始Faster-rcnn算法的基础上面增加了FCN来产生对应的MASK分支。即Faster-rcnn + FCN，更细致的是 RPN + ROIAlign + Fast-rcnn + FCN。</p><p>易于使用：整个Mask R-CNN算法非常的灵活，可以用来完成多种任务，包括目标分类、目标检测、语义分割、实例分割、人体姿态识别等多个任务，这将其易于使用的特点展现的淋漓尽致。我很少见到有哪个算法有这么好的扩展性和易用性，值得我们学习和借鉴。除此之外，我们可以更换不同的backbone architecture和Head Architecture来获得不同性能的结果。</p><h3 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li>实例分割不仅要正确的找到图像中的objects，还要对其精确的分割。所以Instance Segmentation可以看做object dection和semantic segmentation的结合。</li><li>Mask RCNN是Faster RCNN的扩展，对于Faster RCNN的每个Proposal Box都要使用FCN进行语义分割，分割任务与定位、分类任务是同时进行的。</li><li>引入了RoI Align代替Faster RCNN中的RoI Pooling。因为RoI Pooling并不是按照像素一一对齐的（pixel-to-pixel alignment），也许这对bbox的影响不是很大，但对于mask的精度却有很大影响。使用RoI Align后mask的精度从10%显著提高到50%，第3节将会仔细说明。</li><li>引入语义分割分支，实现了mask和class预测的关系的解耦，mask分支只做语义分割，类型预测的任务交给另一个分支。这与原本的FCN网络是不同的，原始的FCN在预测mask时还用同时预测mask所属的种类。</li><li>没有使用什么花哨的方法，Mask RCNN就超过了当时所有的state-of-the-art模型。</li><li>使用8-GPU的服务器训练了两天。</li></ul><h3 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h3><h4 id="Mask-R-CNN算法步骤"><a href="#Mask-R-CNN算法步骤" class="headerlink" title="Mask R-CNN算法步骤"></a>Mask R-CNN算法步骤</h4><ul><li>首先，输入一幅你想处理的图片，然后进行对应的预处理操作，或者预处理后的图片；</li><li>然后，将其输入到一个预训练好的神经网络中（ResNeXt等）获得对应的feature map；</li><li>接着，对这个feature map中的每一点设定预定个的ROI，从而获得多个候选ROI；</li><li>接着，将这些候选的ROI送入RPN网络进行二值分类（前景或背景）和BB回归，过滤掉一部分候选的ROI；</li><li>接着，对这些剩下的ROI进行ROIAlign操作（即先将原图和feature map的pixel对应起来，然后将feature map和固定的feature对应起来）；</li><li>最后，对这些ROI进行分类（N类别分类）、BB回归和MASK生成（在每一个ROI里面进行FCN操作）。</li></ul><h4 id="Mask-R-CNN架构分解"><a href="#Mask-R-CNN架构分解" class="headerlink" title="Mask R-CNN架构分解"></a>Mask R-CNN架构分解</h4><p><a href="https://imgchr.com/i/NY6Oqx" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NY6Oqx.md.png" alt="NY6Oqx.md.png"></a></p><h5 id="Faster-rcnn"><a href="#Faster-rcnn" class="headerlink" title="Faster-rcnn"></a>Faster-rcnn</h5><h5 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a>FCN</h5><p>FCN算法是一个经典的语义分割算法，可以对图片中的目标进行准确的分割。其总体架构如上图所示，它是一个端到端的网络，主要的模快包括卷积和去卷积，即先对图像进行卷积和池化，使其feature map的大小不断减小；然后进行反卷积操作，即进行插值操作，不断的增大其feature map，最后对每一个像素值进行分类。从而实现对输入图像的准确分割。</p><p><a href="https://imgchr.com/i/NY2Krn" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NY2Krn.md.png" alt="NY2Krn.md.png"></a></p><h5 id="ROIPooling和ROIAlign的分析与比较"><a href="#ROIPooling和ROIAlign的分析与比较" class="headerlink" title="ROIPooling和ROIAlign的分析与比较"></a>ROIPooling和ROIAlign的分析与比较</h5><p><a href="https://imgchr.com/i/NYRUfS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NYRUfS.md.png" alt="NYRUfS.md.png"></a></p><p>ROI Pooling和ROIAlign最大的区别是：前者使用了两次量化操作，而后者并没有采用量化操作，使用了线性插值算法，具体的解释如下所示。</p><p>ROI Pooling技术：<br><a href="https://imgchr.com/i/NYRmFK" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NYRmFK.md.png" alt="NYRmFK.md.png"></a></p><p>如图所示，为了得到固定大小（7X7）的feature map，我们需要做两次量化操作：<br>1）图像坐标 — feature map坐标，<br>2）feature map坐标 — ROI feature坐标。</p><p>第一次量化误差：\<br>如图我们输入的是一张800x800的图像，在图像中有两个目标（猫和狗），狗的BB大小为665x665，经过VGG16网络后，我们可以获得对应的feature map，如果我们对卷积层进行Padding操作，我们的图片经过卷积层后保持原来的大小，但是由于池化层的存在，我们最终获得feature map 会比原图缩小一定的比例，这和Pooling层的个数和大小有关。在该VGG16中，我们使用了5个池化操作，每个池化操作都是2Pooling，因此我们最终获得feature map的大小为800/32 x 800/32 = 25x25（是整数），但是将狗的BB对应到feature map上面，我们得到的结果是665/32 x 665/32 = 20.78 x 20.78，结果是浮点数，含有小数，但是我们的像素值可没有小数，那么作者就对其进行了量化操作（即取整操作），即其结果变为20 x 20，在这里引入了第一次的量化误差</p><p>第二次量化误差：\<br>然而我们的feature map中有不同大小的ROI，但是我们后面的网络却要求我们有固定的输入，因此，我们需要将不同大小的ROI转化为固定的ROI feature，在这里使用的是7x7的ROI feature，那么我们需要将20 x 20的ROI映射成7 x 7的ROI feature，其结果是 20 /7 x 20/7 = 2.86 x 2.86，同样是浮点数，含有小数点，我们采取同样的操作对其进行取整吧，在这里引入了第二次量化误差。其实，这里引入的误差会导致图像中的像素和特征中的像素的偏差，即将feature空间的ROI对应到原图上面会出现很大的偏差。</p><p><a href="https://imgchr.com/i/NYWens" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NYWens.md.png" alt="NYWens.md.png"></a></p><p>如图10所示，为了得到为了得到固定大小（7X7）的feature map，ROIAlign技术并没有使用量化操作，即我们不想引入量化误差，比如665 / 32 = 20.78，我们就用20.78，不用什么20来替代它，比如20.78 / 7 = 2.97，我们就用2.97，而不用2来代替它。这就是ROIAlign的初衷。那么我们如何处理这些浮点数呢，我们的解决思路是使用“双线性插值”算法。双线性插值是一种比较好的图像缩放算法，它充分的利用了原图中虚拟点（比如20.56这个浮点数，像素位置都是整数值，没有浮点值）四周的四个真实存在的像素值来共同决定目标图中的一个像素值，即可以将20.56这个虚拟的位置点对应的像素值估计出来。</p><p><a href="https://imgchr.com/i/NYh1OJ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/22/NYh1OJ.md.png" alt="NYh1OJ.md.png"></a></p><p>蓝色的虚线框表示卷积后获得的feature map，黑色实线框表示ROI feature，最后需要输出的大小是2x2，那么我们就利用双线性插值来估计这些蓝点（虚拟坐标点，又称双线性插值的网格点）处所对应的像素值，最后得到相应的输出。这些蓝点是2x2Cell中的随机采样的普通点，作者指出，这些采样点的个数和位置不会对性能产生很大的影响，你也可以用其它的方法获得。然后在每一个橘红色的区域里面进行max pooling或者average pooling操作，获得最终2x2的输出结果。我们的整个过程中没有用到量化操作，没有引入误差，即原图中的像素和feature map中的像素是完全对齐的，没有偏差，这不仅会提高检测的精度，同时也会有利于实例分割。</p><h3 id="Loss-计算"><a href="#Loss-计算" class="headerlink" title="Loss 计算"></a>Loss 计算</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L&#x3D;L_&#123;cls&#125;+L_&#123;box&#125;+L_&#123;mask&#125;</span><br></pre></td></tr></table></figure><p>其中<code>$L_{cls},L_{box$</code>和在Faster r-cnn中定义的相同。</p><p>对于每一个ROI，mask分支有Km*m维度的输出，其对K个大小为m*m的mask进行编码，每一个mask有K个类别。我们使用了per-pixel sigmoid，并且将Lmask定义为the average binary cross-entropy loss。对应一个属于GT中的第k类的ROI，Lmask仅仅在第k个mask上面有定义（其它的k-1个mask输出对整个Loss没有贡献）。我们定义的Lmask允许网络为每一类生成一个mask，而不用和其它类进行竞争；我们依赖于分类分支所预测的类别标签来选择输出的mask。这样将分类和mask生成分解开来。这与利用FCN进行语义分割的有所不同，它通常使用一个per-pixel sigmoid和一个multinomial cross-entropy loss，在这种情况下mask之间存在竞争关系；而由于我们使用了一个per-pixel sigmoid 和一个binary loss，不同的mask之间不存在竞争关系。经验表明，这可以提高实例分割的效果。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><ul><li>分析了ROI Pool的不足，提升了ROIAlign，提升了检测和实例分割的效果；</li><li>将实例分割分解为分类和mask生成两个分支，依赖于分类分支所预测的类别标签来选择输出对应的mask。同时利用Binary Loss代替Multinomial Loss，消除了不同类别的mask之间的竞争，生成了准确的二值mask；</li><li>并行进行分类和mask生成任务，对模型进行了加速。</li></ul><h2 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h2><p>reference：<a href="https://blog.csdn.net/Dlyldxwl/article/details/81148810" target="_blank" rel="noopener">https://blog.csdn.net/Dlyldxwl/article/details/81148810</a></p><p>在传统的语义分割问题上，存在的三个挑战：</p><ul><li>传统分类CNN中连续的池化何降采样导致空间分辨率下降。（解决：去掉最后几层的降采样和最大池化，使用上采样滤波器，得到采样率更高的特征）</li><li>对象对尺度检测问题，使用重新调节尺度并聚合特征图，但是计算量较大。（解决：对特征层重采样，得到多尺度的图像文本信息，使用多个并行ACNN进行多尺度采样，成为ASPP）</li><li>以物体为中心的分类，需要保证空间转换不变性。（解决：跳跃层结构，从多个网络层中抽取高层次特征进行预测；使用全连接条件随机场进行边界预测优化）</li></ul><p>Deeplab系列针对的是语义分割任务。对于语义分割任务要求：</p><ul><li>语义分割是对图像做密集的分割任务，分割每个像素到指定的类别上；</li><li>将图像分割成几个有意义的目标；</li><li>给对象分配指定的类别标签。</li></ul><h3 id="Deeplab-v1"><a href="#Deeplab-v1" class="headerlink" title="Deeplab v1"></a>Deeplab v1</h3><p>由于语义分割是像素级别的分类，高度抽象的空间特征对low-level并不适用，因此必须要考虑feature map 的尺寸和空间不变性。</p><p>feature map变小是因为stride的存在，stride&gt;1是为了增加感受野的，如果stride=1，要保证相同的感受野，则必须是卷积核大小变大，因此，论文使用hole算法来增加核大小进而达到相同的感受野，也就是空洞卷积。</p><p>图像输入CNN后是一个倍逐步抽象的过程，原来的位置信息会随着深度而减少甚至消失。条件随机场在传统图像处理上做一个平滑，也就是说在决定一个位置的像素值时，能够考虑周围邻居的像素值，抹杀一些噪音。</p><p>具体的操作为：移除原网络最后两个池化层，使用rate=2的空洞卷积采样。标准的卷积只能获取原图1/4的内容，而新的带孔的卷积能够在全图上获取信息。</p><h4 id="Astrous-conv"><a href="#Astrous-conv" class="headerlink" title="Astrous conv"></a>Astrous conv</h4><p>对使用了s=2后的lower resolution feature map再进行标准的卷积的效果和在原来的feature map上使用rate=2的空洞卷积的效果是一样的。</p><p>空洞卷积：<br><a href="https://imgchr.com/i/NaFKbD" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaFKbD.md.png" alt="NaFKbD.md.png"></a></p><h4 id="ASPP结构"><a href="#ASPP结构" class="headerlink" title="ASPP结构"></a>ASPP结构</h4><p>使用多尺度进行空洞卷积，在经过1*1的卷积之后连接起来。多尺度特征提取，得到全局和局部特征</p><p><a href="https://imgchr.com/i/NaFrPs" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaFrPs.md.png" alt="NaFrPs.md.png"></a></p><p>DeeplabV1是在VGG16的基础上做了修改：</p><ul><li>VGG16的全连接层转为卷积；</li><li>最后两个池化层去掉，后续使用空洞卷积。</li></ul><h3 id="Deeplab-v2"><a href="#Deeplab-v2" class="headerlink" title="Deeplab v2"></a>Deeplab v2</h3><p>Deeplabv2是在v1上进行改进的：</p><ul><li>使用多尺度获得更好的分割效果（使用ASPP）</li><li>基础层由VGG16转为ResNet</li><li>使用不同的学习策略</li><li>Deeplab V1和V2的优点：</li><li>速度上：使用空洞卷积的Dense DCNN速度比全连接层快；</li><li>准确度高</li></ul><h3 id="Deeplab-v3"><a href="#Deeplab-v3" class="headerlink" title="Deeplab v3"></a>Deeplab v3</h3><p>paper： Rethinking Atrous Convolution for Semantic Image Segmentation</p><p>创新点</p><ol><li>改进了ASPP模块，一个11的卷积和3个33的空洞卷积，每个卷积核有256个且都有BN层，包含图像及特征（全局平均池化）。</li><li>参考了图森组的Understanding Convolution for Semantic Segmentation中HDC的思想。其实就是对应纵横两种结构。</li><li>提出了更通用的框架，适用于任何网络；</li><li>复制了resnet最后的block，并级联起来</li><li>在ASPP中使用BN层</li><li>没有随机向量场</li></ol><p>backbone还是resnet 101.</p><p>全局特征或上下文之间的相互作用有助于做语义特征，现有四种不同类型利用上下文信息做语义分割的全卷积神经网络（几种常见的捕获multi-scale context的方法）：</p><ol><li><strong>图像金字塔：</strong>通常使用共享权重的模型，适用于多尺寸的输入。小尺寸输入响应控制语义，大尺寸的输入响应控制细节。通过拉普拉斯金字塔对输入变化成多尺度，传入DCNN，融合输出。缺点：因为GPU存储器的限制，对于更大更深的模型不方便扩展。（输入图像进行尺度变换得到不同分辨率input，然后将所有尺度的图像放入CNN中得到不同尺度的分割结果，最后将不同分辨率的分割结果融合得到原始分辨率的分割结果，类似的方法为DeepMedic；）</li><li><strong>Encoder-Decoder：</strong>编码器的高层次的特征容易捕获更长的距离信息，在解码器阶段使用编码器阶段的信息帮助恢复目标的细节和空间维度。FCN和UNet等结构。</li><li><strong>上下文模块：</strong>包含了额外的模块用于级联编码长距离的上下文。例如空洞卷积。（串联结构）</li><li><strong>空间金字塔池化：</strong>采用空间金字塔池化可以捕获多个层次的上下文。（本文提出的Deeplab v3结构。）</li></ol><p><a href="https://imgchr.com/i/NaAA6x" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaAA6x.md.png" alt="NaAA6x.md.png"></a></p><h4 id="ASPP的改进"><a href="#ASPP的改进" class="headerlink" title="ASPP的改进"></a>ASPP的改进</h4><p>改进后的aspp长下图那个样子，多了个1*1的conv和global avg pool。</p><p><a href="https://imgchr.com/i/NaARN4" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaARN4.md.png" alt="NaARN4.md.png"></a></p><h4 id="“串联”结构"><a href="#“串联”结构" class="headerlink" title="“串联”结构"></a>“串联”结构</h4><p>如下图所示，复制conv4的结构3次，后面的每个block都有一个基准dilation Rate，在每一个block里面参考HDC的思想，又设置了[1,2,1]的rate，所以每个conv的rate = Rate*rate.在论文4.2的Multi-grid部分详细进行了解释对比。</p><p><a href="https://imgchr.com/i/NaA43R" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaA43R.md.png" alt="NaA43R.md.png"></a></p><p>两种方法的结构合并并不会带来提升，相比较来说，aspp的纵式结构要好一点。所以deeplab v3一般也是指aspp的结构。</p><h1 id="人体行为识别"><a href="#人体行为识别" class="headerlink" title="人体行为识别"></a>人体行为识别</h1><h2 id="3D-CNN"><a href="#3D-CNN" class="headerlink" title="3D CNN"></a>3D CNN</h2><p>reference：<a href="https://zhuanlan.zhihu.com/p/47490523" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47490523</a></p><h3 id="摘要-1"><a href="#摘要-1" class="headerlink" title="摘要"></a>摘要</h3><p>当前很多人体行为识别分类器都是基于从原始图像上手工提取的特征，本文提出的3D CNN能够直接从原始输入中提取特征，通过执行3D卷积在监控视频中从时间和空间维度提取特征，将高级功能模型规范化，并结合各种不同模型的输出，进一步提高3D CNN的性能。在机场的监控视频中，该方法相比于传统的方法，取得了卓越的性能。</p><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><ul><li>现实的环境的监控视频背景杂乱、遮挡等原因，在识别之前会对视频中的某些情况作出某些假设（假设在现实环境中很少存在），然后遵循两步原则：</li></ul><ol><li>计算原始视频帧的特征；</li><li>基于获得的特征学习分类器；</li></ol><ul><li>然而在实际场景中，很少知道哪些特征对手头任务很重要，因为特征选择高度依赖问题。特别是对于人类动作识别，不同的动作类别在其外观和运动模式方面可能显得截然不同。</li><li>深度学习模型是一类可以通过从低级特征构建高级特征来学习特征层次结构的机器。这种学习机可以使用有监督或无监督的方法进行训练。</li><li>CNN主要用于2D图像，本文探讨将CNN用于视频中人体动作的识别，一种容易想到的方法是将视频的每一帧视为静止图像，并用CNN来识别单个帧的级别动作，但这种方法没有考虑多个连续帧的编码运动信息。为了有效的结合视频中的运动信息，文章提出可以在CNN卷积层中执行3D卷积，以便捕获沿空间和时间维度的辨别特征。3D CNN架构可以从相邻的视频帧生成多个信息通道，并在每个通道中分别执行卷积和下采样，通过组合来自视频通道的信息获得最终特征表示。为了进一步提升3D CNN模型的性能，我们建议增加模型，辅助输出计算为高级运动特征，并集成各种不同架构的输出进行预测。</li></ul><h4 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h4><ul><li>本文应用3D卷积运算从视频数据中提取空间和时间特征以进行动作识别。这些3D特征提取器在空间和时间维度上操作，从而捕获视频流中的运动信息；</li><li>开发了基于3D卷积特征提取的3D卷积神经网络架构（CNN），该CNN架构从相邻视频帧生成多个信息通道，并在每个通道中分别执行卷积和下采样。通过组合来自所有通道的信息获得最终的特征表示；</li><li>建议通过增加具有高级运动特征的输出来规范3D CNN模型；</li><li>建议通过组合各种不同3D CNN架构的输出来提高模型的性能。</li></ul><h4 id="3D卷积神经网络"><a href="#3D卷积神经网络" class="headerlink" title="3D卷积神经网络"></a>3D卷积神经网络</h4><p>在二维CNN中，卷积应用于2D特征图，仅从空间维度计算特征。当利用视频数据分析问题的时候，我们期望捕获在多个连续帧编码的运动信息。为此，提出在CNN的卷积进行3D卷积，以计算空间和时间维度特征， 3D卷积是通过堆叠多个连续的帧组成一个立方体，然后在立方体中运用3D卷积核。通过这种结构，<strong>卷积层中的特征图都会与上一层中的多个相邻帧相连</strong>，从而捕获运动信息。如下图所示，一个feature map的某一位置的值是通过卷积上一层的三个连续的帧的同一位置的局部感受野得到的。</p><p><a href="https://imgchr.com/i/NtKOPg" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NtKOPg.md.png" alt="NtKOPg.md.png"></a></p><ul><li>要注意的是，3D卷积核只能从cube中提取一种类型特征，因为在整个卷积的过程中卷积核的权值都是一样的的（共享权值），都是同一种卷积核，上图中同一颜色的连线表示相同的权值。因此我们可以采用多种卷积核来提取多种特征。</li><li>对于CNNs，有一个通用的设计规则就是：在后面的层（离输出层近的）特征map的个数应该增加，这样就可以从低级的feature map组合产生更多类型的特征。</li></ul><h4 id="3D-CNN架构"><a href="#3D-CNN架构" class="headerlink" title="3D CNN架构"></a>3D CNN架构</h4><p>基于上述的3D卷积，可以设计出各种CNN架构。在上下文中，我们描述了为了描述了为TRECVID数据集中的人为动作识别开发的3D CNN架构，如图所示：</p><p><a href="https://imgchr.com/i/NULOhD" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NULOhD.md.png" alt="NULOhD.md.png"></a></p><ul><li>文中的3D CNN架构包含一个硬连线hardwired层、3个卷积层、2个下采样层和一个全连接层。每个3D卷积核卷积的立方体是连续7帧，每帧patch大小是60x40；</li><li>在第一层，我们应用了一个固定的hardwired的核去对原始的帧进行处理，产生多个通道的信息，然后对多个通道分别处理。最后再将所有通道的信息组合起来得到最终的特征描述。这个hardwired层实际上是编码了我们对特征的先验知识，这比随机初始化性能要好。</li></ul><p><a href="https://imgchr.com/i/NUjRtf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NUjRtf.md.png" alt="NUjRtf.md.png"></a></p><ul><li>每帧提取五个通道的信息，分别是：灰度、x和y方向的梯度，x和y方向的光流。其中，前面三个都可以每帧都计算。然后水平和垂直方向的光流场需要两个连续帧才确定。所以是7x3 + (7-1)x2=33个特征maps。</li><li>然后我们用一个7x7x3的3D卷积核（<strong>7x7在空间，3是时间维</strong>）在五个通道的每一个通道分别进行卷积。为了增加feature map个数（实际上就是提取不同的特征），我们在每一个位置都采用两个不同的卷积核，这样在C2层的两个特征maps组中，每组都包含23个特征maps。23=(7-3+1)x3+(6-3+1)x2，前面那个是：七个连续帧，其灰度、x和y方向的梯度这三个通道都分别有7帧，然后水平和垂直方向的光流场都只有6帧。54x34是(60-7+1)x(40-7+1)。</li><li>在紧接着的下采样层S3层max pooling，我们在C2层的特征maps中用2x2窗口进行下采样，这样就会得到相同数目但是空间分辨率降低的特征maps。下采样后，就是27x17=(54/2)*(34/2)。</li><li>C4是在5个通道中分别采用7x6x3的3D卷积核。为了增加特征maps个数，我们在每个位置都采用3个不同的卷积核，这样就可以得到6组不同的特征maps，每组有13个特征maps。13=((7-3+1)-3+1)x3+((6-3+1)-3+1)x2，前面那个是：七个连续帧，其灰度、x和y方向的梯度这三个通道都分别有7帧，然后水平和垂直方向的光流场都只有6帧。21x12是(27-7+1)x(17-6+1)。</li><li>S5层用的是3x3的下采样窗口，所以得到7x4。所以本文中，空间维度上卷积后的尺寸变化可以通过下图很直观的表现出来:</li></ul><p><a href="https://imgchr.com/i/NaSoGV" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/NaSoGV.md.png" alt="NaSoGV.md.png"></a></p><ul><li>到这个阶段，时间维上帧的个数已经很小了，在这一层，我们只在空间维度上面卷积，这时候我们使用的核是7x4，然后输出的特征maps就被减小到1x1的大小。而C6层就包含有128个feature map，每个特征map与S5层中所有78（13x6）个特征maps全连接，这样每个特征map就是1x1，也就是一个值了，<strong>而这个就是最终的特征向量了，共128维</strong>。</li><li>经过多层的卷积和下采样后，每连续7帧的输入图像都被转化为一个128维的特征向量，这个特征向量捕捉了输入帧的运动信息。输出层的节点数与行为的类型数目一致，而且每个节点与C6中这128个节点是全连接的。如下图：</li></ul><p><a href="https://imgchr.com/i/Nap6F1" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/Nap6F1.md.png" alt="Nap6F1.md.png"></a></p><ul><li>在这里，我们采用一个线性分类器来对这128维的特征向量进行分类，实现行为识别。</li><li>模型中所有可训练的参数都是随机初始化的，然后通过在线BP算法进行训练。</li></ul><h4 id="Model-Regularization（模型规范化）"><a href="#Model-Regularization（模型规范化）" class="headerlink" title="Model Regularization（模型规范化）"></a>Model Regularization（模型规范化）</h4><ul><li>3D CNN模型的输入被限制为一个少的连续视频帧（论文中取的是7帧），因为随着输入窗口大小的增加，模型需要训练的参数也会增加。但是呢，很多人的行为是跨越很多帧的。</li><li>因此，在3D CNN模型中，有必要捕捉这种高层的运动信息。为了达到这个目的，我们用大量的帧来计算运动特征，然后把这些运动特征作为辅助输出去规则化3D CNN模型。</li><li>对于每一个需要训练的行为，我们提取其长时间的行为信息，作为其高级行为特征。这个运动信息因为时间够长，所以要比CNN的输入帧的立方体包含的信息要丰富很多。然后我们就迫使CNN学习一个非常接近这个特征的特征向量。这可以通过在CNN的最后一个隐层再连接一系列的辅助输出节点，然后训练过程中，使提取的特征更好的逼近这个计算好的高层的行为运动特征向量。如下图所示：</li></ul><p><a href="https://imgchr.com/i/Na99kn" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/Na99kn.md.png" alt="Na99kn.md.png"></a></p><p>高级行为辅助特征的提取过程是先在原始的灰度图像上计算稠密sift (Scale Invariant Feature Transform)描述子，然后通过这些sift描述子和运动边缘历史图像（MEHI）组合构造bag-of-words特征作为高级行为辅助特征。如下图：</p><p><a href="https://imgchr.com/i/Na911K" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/23/Na911K.md.png" alt="Na911K.md.png"></a></p><ul><li>因为灰度图保留了外观信息，运动边缘历史图像（MEHI）只关心形状和运动模式，所以可以提取这两个互补的信息作为两个连续帧的局部特征bag。MEHI 的计算见上图右，先简单的计算两帧间的差分，这样就可以保留运动信息，然后对其执行一次Canny边缘检测，这样可以使得观测图像更加清楚简洁。最终的运动边缘图像就是将历史的这些图像乘以一个遗忘因子再累加起来得到。</li></ul><h4 id="Model-Combination-模型组合"><a href="#Model-Combination-模型组合" class="headerlink" title="Model Combination (模型组合)"></a>Model Combination (模型组合)</h4><ul><li>不同的3D CNN模型在不同的应用环境下性能不一样，一种自适应的方法就是构造多个不同模型，然后对一个特定的输入，每个模型都做出预测，然后组合这些模型的预测得到最后的决策。</li><li>本文中，我们构造多个不同的3D CNN模型，因此它可以从输入捕捉潜在的互补信息，然后在预测阶段，每个模型都针对一个输入得到对应的输出，然后再组合这些输出得到最终的结果。</li></ul><h2 id="双流法-Two-Stream"><a href="#双流法-Two-Stream" class="headerlink" title="双流法 Two-Stream"></a>双流法 Two-Stream</h2><p>《Two-Stream Convolutional Networks for Action Recognition in Videos》</p><p>双流法，顾名思义就好像是两条小溪流各自流动最后汇聚到了一块；其中一条小溪流的名称为“RGB”图信息，可以是3通道的信息，也可以是 RGB-D 的灰度图信息； 而另一条小溪流的名称是“光流”图的信息，一般的光流图为2通道的信息，分别为在X轴上的信息变化与Y轴上的信息变化。【光流是通过对两张图进行梯度计算得到，抽象层面可以理解成是其关键点的像素点信息移动的信息】</p><p><a href="https://imgchr.com/i/NddaD0" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/24/NddaD0.md.png" alt="NddaD0.md.png"></a></p><p>如图所示，其实做法非常的简单，相当于训练两个CNN的分类器。一个是专门对于 RGB 图的， 一个专门对于光流图的， 然后将两者的结果进行一个 fushion 的过程。</p><p>RGB图的选择，是对于所给的一段视频随机挑选出视频中的任意一帧；而光流图是选择视频中的任意一帧的时间然后及其后面的N帧叠合成一个光流栈进入训练。</p><p>[这种光流的训练方式是论文作者认为，这样子的光流叠加可以获得它的运动信息流，但是实际上光流图并不是以motion的信息来得到结果]</p><p>Spatial stream ConvNet 网络对视频的的单个帧进行操作，从静止的图片中进行特征的提取。</p><p>Optical ﬂow ConvNets 的输入是几个连续帧之间堆叠光流位移场，该输入描述了视频帧之间的运动信息。</p><p>作者在文章中也介绍了基于光流输入的几种变种，如下图，(a),(b)表示一对连续的视频帧，在移动的手周围用青色矩形勾勒出区域。(c).表示在轮廓区域密集的光流。(d).位移矢量场的水平分量dx。(e).表示位移矢量场的垂直分量dy。</p><p><a href="https://imgchr.com/i/Nd0RAK" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/24/Nd0RAK.md.png" alt="Nd0RAK.md.png"></a></p><p>现在介绍一下<strong>光流堆叠(Optical ﬂow stacking)</strong>，密集光学流可以看作成对连续帧t和t + 1之间的一组位移矢量场dt。用dt(u,v)表示帧t中点(u，v)的位移矢量，表示它将点移动到下一帧t+1中的相应点。如下图左边图所示，矢量场的水平和垂直分量dt(x)和dt(y)可以看作图像通道。为了表示一系列帧之间的运动，将L个连续帧的流通道dt(xy )叠加在一起，形成总共2L个输入通道。图4为通过光流堆叠卷积网络的输入。</p><p><strong>轨迹堆叠(Trajectory stacking)</strong>，沿着运动轨迹采样的光流，而光流堆叠在几个帧的相同位置采样的光学流动。</p><p>文中提到了双向光流(Bi-directional optical ﬂow),光流堆叠和轨迹堆叠都是处理前向光流，即帧t的位移场dt定义为其在下一帧t + 1中的像素的位置，而双向光流指的是通过在帧τ-π/ L和τ之间堆叠L / 2前向流并且在帧τ-L / 2和τ之间堆叠L / 2后向流来构造输入。</p><p>最后是<strong>Mean ﬂow subtraction</strong>，对网络输入进行零中心化可以使模型更好地纠正非线性。对于一对帧，它们之间的光流动可以由特定位移支配，比如相机的移动，在本论文中作者从每个位移场中减去其平均向量。在这部分中，作者也阐述了Temporal ConvNet架构与先前表示的关系，表明了emporal network特征可以概括了手工设计特征。</p><p><a href="https://imgchr.com/i/NdrVX9" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/24/NdrVX9.md.png" alt="NdrVX9.md.png"></a></p><p>第四部分为多任务学习(Multi-tasklearning)，这主要针对与temporal ConvNet，由于现有的视频行为数据集相对是少的。训练在UCF-101和HMDB-51数据集上。为了防止过拟合，考虑将多个数据集进行合并成一个，由于不同数据集类别上由交叉，所以一种做法是增加不在原始图像类别中的图片，然而这需要手动进行。而组合多个数据集的更有原则的方法是基于多任务学习，其目的是学习(视频)的表示，它不仅适用于所关心的任务，还适用于其他任务。额外的任务充当一个regulariser，并允许利用额外的训练数据。对于多任务学习，具体实现，论文中也给出了做法，修改ConvNet架构，使其在最后一个全连接层的顶部有两个softmax分类层：一个softmax层计算HMDB-51分类分数，另一个是UCF-101分数。每个层都由有自己的损失函数，该操作仅对来自相应数据集的视频进行操作。整体训练损失计算为各个任务的损失之和，并且可以通过反向传播更新网络参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对计算机视觉的基础知识，重要工作，以及相关任务进行了梳理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="survey" scheme="http://yoursite.com/categories/survey/"/>
    
    
      <category term="Computer Vision" scheme="http://yoursite.com/tags/Computer-Vision/"/>
    
      <category term="CNN" scheme="http://yoursite.com/tags/CNN/"/>
    
      <category term="Semantic Segmentation" scheme="http://yoursite.com/tags/Semantic-Segmentation/"/>
    
      <category term="Object Detection" scheme="http://yoursite.com/tags/Object-Detection/"/>
    
  </entry>
  
  <entry>
    <title>A Survey on Few-shot Learning</title>
    <link href="http://yoursite.com/2020/06/12/Overview-of-Few-shot-Learning/"/>
    <id>http://yoursite.com/2020/06/12/Overview-of-Few-shot-Learning/</id>
    <published>2020-06-12T11:44:35.000Z</published>
    <updated>2020-06-12T12:19:38.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近开始研究利用少量样本进行机器学习。<a href="https://arxiv.org/abs/1904.05046v2" target="_blank" rel="noopener">Wang et al.</a> 系统性地对小样本学习的工作做了一个总结，本篇对该论文以及相关的工作进行了一个梳理。</p><a id="more"></a><h1 id="INTRODUCTION"><a href="#INTRODUCTION" class="headerlink" title="INTRODUCTION"></a>INTRODUCTION</h1><p><strong>Main idea:</strong> Use <strong>prior knowledge</strong> to alleviate the problem of having an unreliable empirical risk minimizer in FSL supervised learning.</p><p><a href="https://imgchr.com/i/tOlmqS" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tOlmqS.md.png" alt="tOlmqS.md.png"></a></p><h1 id="METHODS"><a href="#METHODS" class="headerlink" title="METHODS"></a>METHODS</h1><p>小样本学习的方法主要可以被归为三个方面：数据，模型，以及算法。其核心都是如何更好地利用先验知识。</p><p>从数据入手，主要是利用先验知识产生更大数量的数据；从模型入手，主要思想是利用先验知识来限制假设空间的大小，从而更快的找到最优点；从算法入手，主要思想是利用先验知识来改变搜索策略。</p><h2 id="Data"><a href="#Data" class="headerlink" title="Data"></a>Data</h2><p><a href="https://imgchr.com/i/tO1uy6" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1uy6.md.png" alt="tO1uy6.md.png"></a></p><p>通过数据增强小样本的方法不改变搜索空间的大小，而是通过产生数据来帮助找到最优参数。它可以被归类为以下三种方法：<br><a href="https://imgchr.com/i/tO1ZWR" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1ZWR.md.png" alt="tO1ZWR.md.png"></a></p><ol><li>Transforming Samples from $D_{train}$ \<br>该类方法通过对原训练数据的操作（如图像领域中的翻转等）进行数据增强，从而达到扩充数据的效果。</li><li>Transforming Samples from a Weakly Labeled or Unlabeled Data Set \<br>该类方法利用从训练数据中学习到的predictor对无监督或者弱监督的数据集进行标注，从而获得更大规模的数据集。</li><li>Transforming Samples from Similar Data Sets \<br>该类方法从一个相似且更大规模的数据集上迁移input-output pairs，aggregation weight通常基于样本间的相似性。</li></ol><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>Main idea: Use prior knowledge to constrain the complexity of ℋ, which results in a much smaller hypothesis space $\widetilde{H}$.</p><p><a href="https://imgchr.com/i/tO1VY9" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1VY9.md.png" alt="tO1VY9.md.png"></a></p><h3 id="Multitask-Learning"><a href="#Multitask-Learning" class="headerlink" title="Multitask Learning"></a>Multitask Learning</h3><p><strong>Multitask learning</strong> learns multiple related tasks simultaneously by exploiting both task-generic and task-specific information.</p><p>Given $C$ related tasks $T_1,…,T_C$, each $T_c$ has a dataset$D_c=\{D_{train}^c, D_{test}^c\}$.</p><p>The few-shot tasks are regarded as target tasks, and the rest as source tasks.<br>Multitask learning learns from $D_{train}^c$ to obtain $\theta_c$ for train each $T_c$.</p><h4 id="Parameter-Sharing"><a href="#Parameter-Sharing" class="headerlink" title="Parameter Sharing"></a>Parameter Sharing</h4><p><strong>Parameter Sharing</strong> directly shares some parameters among tasks.</p><p><a href="https://imgchr.com/i/tO1nQx" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1nQx.md.png" alt="tO1nQx.md.png"></a></p><h4 id="Parameter-Tying"><a href="#Parameter-Tying" class="headerlink" title="Parameter Tying"></a>Parameter Tying</h4><p><strong>Parameter Tying</strong> encourages parameters of different tasks to be similar.<br>A popular approach is by regularizing the $\theta_c$.</p><p><a href="https://imgchr.com/i/tO1mS1" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1mS1.md.png" alt="tO1mS1.md.png"></a></p><h3 id="Embedding-Learning"><a href="#Embedding-Learning" class="headerlink" title="Embedding Learning"></a>Embedding Learning</h3><p><strong>Embedding learning</strong> embeds each sample $x_i \in \mathcal{X} \subseteq R^d$ to a lower-dimensional $z_i \in \mathcal{Z} \subseteq R^m$.</p><p>It have three key components:</p><ul><li>A function $f$ which embeds test sample $x_{test} \in D_test$ to $\mathcal{Z}$</li><li>A function $g$ which embeds training sample $x_{train} \in  D_{train}$ to $\mathcal{Z}$</li><li>A similarity function $s(·,·)$ which measures the similarity between $f(x_{test})$ and $g(x_I)$ in $\mathcal{Z}$</li></ul><p><a href="https://imgchr.com/i/tO1QeO" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1QeO.md.png" alt="tO1QeO.md.png"></a></p><h4 id="Task-specific-embedding-model"><a href="#Task-specific-embedding-model" class="headerlink" title="Task-specific embedding model"></a>Task-specific embedding model</h4><p>Learn an embedding function tailored for each task, by using only information from that task.</p><h4 id="Task-invariant-i-e-general-embedding-model"><a href="#Task-invariant-i-e-general-embedding-model" class="headerlink" title="Task-invariant (i.e., general) embedding model"></a>Task-invariant (i.e., general) embedding model</h4><p>Learn a general embedding function from a large-scale data set containing sufficient samples with various outputs, and then directly use this on the new few-shot $D_{train}$  without retraining.</p><p>E.g. Meta-learning (Matching Nets, Prototypical Networks, etc.), Siamese Net, etc.</p><p><a href="https://imgchr.com/i/tO1KOK" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1KOK.md.png" alt="tO1KOK.md.png"></a></p><h4 id="Hybrid-embedding-model-encodes-both-task-specific-and-task-invariant-information"><a href="#Hybrid-embedding-model-encodes-both-task-specific-and-task-invariant-information" class="headerlink" title="Hybrid embedding model (encodes both task-specific and task-invariant information)"></a>Hybrid embedding model (encodes both task-specific and task-invariant information)</h4><p>Learn a function which takes information extracted from $D_{train}$  as input and returns an embedding which acts as the parameter for $f(·)$ .</p><p><a href="https://imgchr.com/i/tO11Te" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO11Te.md.png" alt="tO11Te.md.png"></a></p><h3 id="Learning-with-External-Memory"><a href="#Learning-with-External-Memory" class="headerlink" title="Learning with External Memory"></a>Learning with External Memory</h3><p><strong>Learning with external memory</strong> extracts knowledge from $D_{train}$, and stores it in an external memory. Each new sample $D_{test}$ is then represented by a weighted average of contents extracted from the memory. </p><p>A <strong>key-value memory</strong> is usually used in FSL. \<br>Let the memory be $M \in R^{(b \times m)}$, with each of its $b$ memory slots $M(i) \in R^m$ consisting of a key-value pair $M(i)=(M_{key}(i),M_{value}(i))$. \<br>A test sample $x_{test}$ is first embedded by an embedding function $f$, and used to query for the similar memory slots.</p><p>According to the functionality of the memory, it can be subdivided into two types.</p><ol><li>Refining Representations \<br>Put $x_{train}$  into the memory, such that the stored key-value pairs can represent $x_{test}$  more accurately.</li><li>Refining Parameters \<br>Use a memory to parameterize the embedding function $g(·)$ for a new $x_{test}$ or classification model.</li></ol><p><a href="https://imgchr.com/i/tO1lwD" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1lwD.md.png" alt="tO1lwD.md.png"></a></p><h3 id="Generative-Modeling"><a href="#Generative-Modeling" class="headerlink" title="Generative Modeling"></a>Generative Modeling</h3><p><strong>Generative modeling methods</strong> estimate the probability distribution $p(x)$ from the observed $x_i$ with the help of prior knowledge.</p><p>The observed $x$ is assumed to be drawn from some distribution $p(x;\theta)$ parameterized by $\theta$. \<br>Usually, there exists a latent variable $z \backsim p(z;\gamma)$, so that $x \backsim \int p(x|z;\theta)p(z;\gamma)dz$. \<br>The prior distribution $p(z;\gamma)$ brings in prior knowledge.</p><p>According to what the latent variable 𝑧 represents, it can be grouped into three types.</p><ol><li>Decomposable Components \<br>Samples may share some smaller decomposable components with samples from the other tasks. One then only needs to find the correct combination of these decomposable components, and decides which target class this combination belongs to.</li><li>Groupwise Shared Prior \<br>Similar tasks have similar prior probabilities, and this can be utilized.</li><li>Parameters of Inference Networks \<br>To find the best $\theta$, one has to maximize the posterior </li></ol><script type="math/tex; mode=display">p(z|x;\theta,\gamma)=\frac{p(x,z;\theta ,\gamma)}{p(x;\gamma)}=\frac{p(x|z;\theta)p(z;\gamma)}{\int p(x|z;\theta)p(z;\gamma)dz}</script><p><a href="https://imgchr.com/i/tO1tSI" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1tSI.md.png" alt="tO1tSI.md.png"></a></p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ol><li><p>Multitask learning \<br><strong>Scenarios:</strong> Existing similar tasks or auxiliary tasks.\<br><strong>Limitations:</strong> Joint training of all the tasks together is required. Thus, when a new few-shot task arrives, the whole multitask model has to be trained again.</p></li><li><p>Embedding learning \<br><strong>Scenarios:</strong> A large-scale data set containing sufficient samples of various classes is available. \<br><strong>Limitations:</strong> May not work well when the few-shot task is not closely related to the other tasks. </p></li><li><p>Learning with External Memory \<br><strong>Scenarios:</strong> A memory network is available.\<br><strong>Limitations:</strong> Incurs additional space and computational costs, which increase with memory size.</p></li><li><p>Generative modeling \<br><strong>Scenarios:</strong> Performing tasks such as generation and reconstruction. \<br><strong>Limitations:</strong> High inference cost, and more difficult to derive than deterministic models. </p></li></ol><h2 id="ALGORITHM"><a href="#ALGORITHM" class="headerlink" title="ALGORITHM"></a>ALGORITHM</h2><p>The algorithm is the strategy to search in the hypothesis space $H$ for the parameter $\theta$ of the best hypothesis $h^*$.</p><p>Methods in this section use prior knowledge to influence how $\theta$ is obtained, either by:</p><ol><li>providing a good initialized parameter $\theta_0$</li><li>directly learning an optimizer to output search steps</li></ol><p>In terms of how the search strategy is affected by prior knowledge, the methods can be classified into three groups.</p><p><a href="https://imgchr.com/i/tO5Z4S" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO5Z4S.md.png" alt="tO5Z4S.md.png"></a></p><h3 id="Refining-Existing-Parameters"><a href="#Refining-Existing-Parameters" class="headerlink" title="Refining Existing Parameters"></a>Refining Existing Parameters</h3><p><strong>Refining existing parameters:</strong> An initial $\theta_0$ learned from other tasks, and is then refined using $D_{train}$ . \<br>The assumption is that $\theta_0$ captures some general structures of the large-scale data. Therefore, it can be adapted to $D$ with a few iterations.</p><p>Given the few-shot $D_{train}$ , simply fine-tuning $\theta_0$ by gradient descent may lead to overfitting. Hence, methods fine-tune $\theta_0$ by regularization to prevent overfitting. They can be grouped as follows:</p><ol><li>Early-stopping . \<br>It requires separating a validation set from D train to monitor the training procedure. Learning is stopped when there is no performance improvement on the validation set.</li><li>Selectively updating $\theta_0$ . \<br>Only a portion of $\theta_0$ is updated in order to avoid overfitting.</li><li>Updating related parts of $\theta_0$ together.\<br>One can group elements of $\theta_0$ (such as the neurons in a deep neural network), and update each group jointly with the same update information.</li><li>Using a model regression network.\<br>A model regression network captures the task-agnostic transformation which maps the parameter values obtained by training on a few examples to the parameter values that will be obtained by training on a lot of samples.</li></ol><h4 id="Aggregating-a-Set-of-Parameters"><a href="#Aggregating-a-Set-of-Parameters" class="headerlink" title="Aggregating a Set of Parameters"></a>Aggregating a Set of Parameters</h4><p>Sometimes, we do not have a suitable $\theta_0$ to start with. Instead, we have many models that are learned from related tasks.</p><p><a href="https://imgchr.com/i/tO100S" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO100S.md.png" alt="tO100S.md.png"></a></p><p>Instead of using the augmented data directly, the following methods use models (with parameters $\theta_0$’s) pre-trained from these data sets. The problem is then how to adapt them efficiently to the new task using $D_{train}$ .</p><ol><li>Unlabeled data set.\<br>One can pre-train functions from the unlabeled data to cluster and separate samples well. A neural network is then used to adapt them to the new task with the few-shot $D_{train}$.</li><li>Similar data sets. \<br>few-shot object classification can be performed by leveraging samples and classifiers from similar classes. First, it replaces the features of samples from these similar classes by features from the new class. The learned classifier is then reused, and only the classification threshold is adjusted for the new class.</li></ol><h4 id="Fine-Tuning-Existing-Parameter-with-New-Parameters"><a href="#Fine-Tuning-Existing-Parameter-with-New-Parameters" class="headerlink" title="Fine-Tuning Existing Parameter with New Parameters"></a>Fine-Tuning Existing Parameter with New Parameters</h4><p>The pre-trained $\theta_0$ may not be enough to encode the new FSL task completely. Hence, an additional parameter(s) $\delta$ is used to take the specialty of D train into account. Specifically, this strategy expands the model parameter to become $\theta = \{\theta_0,\delta\}$, and fine-tunes $\theta_0$ while learning $\delta$.</p><p><a href="https://imgchr.com/i/tO1Nlt" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1Nlt.md.png" alt="tO1Nlt.md.png"></a></p><h3 id="Refining-meta-learned-parameters"><a href="#Refining-meta-learned-parameters" class="headerlink" title="Refining meta-learned parameters"></a>Refining meta-learned parameters</h3><p>Methods in this section use meta-learning to refine the meta-learned parameter $\theta_0$.The $\theta_0$ is <strong>continuously optimized</strong> by the meta-learner according to performance of the learner.</p><p><a href="https://imgchr.com/i/tO1aOf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1aOf.md.png" alt="tO1aOf.md.png"></a></p><p>The meta-learned $\theta_0$ is often refined by gradient descent. A representative method is the <a href="https://arxiv.org/abs/1703.03400" target="_blank" rel="noopener">ModelAgnostic Meta-Learning (MAML)</a>.</p><p><a href="https://imgchr.com/i/tX3dSA" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tX3dSA.md.png" alt="tX3dSA.md.png"></a></p><p>Recently, many improvements have been proposed for MAML, mainly along the following three aspects:</p><ol><li>Incorporating task-specific information. \<br>MAML provides the same initialization for all tasks. However, this neglects task-specific information, and is appropriate only when the set of tasks are all very similar.</li><li>Modeling the uncertainty of using a meta-learned $\theta_0$.\<br>The ability to measure this uncertainty provides hints for active learning and further data collection . There are works that consider uncertainty for the meta-learned $\theta_0$, uncertainty for the task-specific $\phi_s$, and uncertainty for class n’s class-specific parameter$\phi_{s,n}$.</li><li>Improving the refining procedure.\<br>Refinement by a few gradient descent steps may not be reliable. Regularization can be used to correct the descent direction.</li></ol><h3 id="Learning-the-optimizer"><a href="#Learning-the-optimizer" class="headerlink" title="Learning the optimizer"></a>Learning the optimizer</h3><p>Instead of using gradient descent, methods in this section learns an optimizer which can directly output the update ($\sum_{i=1}^t\Delta\theta^{i-1}$). There is then no need to tune the stepsize $\alpha$ or find the search direction, as the learning algorithm does that automatically.</p><p><a href="https://imgchr.com/i/tO1wm8" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/06/12/tO1wm8.md.png" alt="tO1wm8.md.png"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近开始研究利用少量样本进行机器学习。&lt;a href=&quot;https://arxiv.org/abs/1904.05046v2&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Wang et al.&lt;/a&gt; 系统性地对小样本学习的工作做了一个总结，本篇对该论文以及相关的工作进行了一个梳理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="survey" scheme="http://yoursite.com/categories/survey/"/>
    
    
      <category term="Few-shot Learning" scheme="http://yoursite.com/tags/Few-shot-Learning/"/>
    
      <category term="Transfer Learning" scheme="http://yoursite.com/tags/Transfer-Learning/"/>
    
      <category term="Meta Learning" scheme="http://yoursite.com/tags/Meta-Learning/"/>
    
  </entry>
  
  <entry>
    <title>Multi-Task Identiﬁcation of Entities, Relations, and Coreference for Scientiﬁc Knowledge Graph Construction</title>
    <link href="http://yoursite.com/2019/09/24/Multi-Task-Identi%EF%AC%81cation-of-Entities-Relations-and-Coreference-for-Scienti%EF%AC%81c-Knowledge-Graph-Construction/"/>
    <id>http://yoursite.com/2019/09/24/Multi-Task-Identi%EF%AC%81cation-of-Entities-Relations-and-Coreference-for-Scienti%EF%AC%81c-Knowledge-Graph-Construction/</id>
    <published>2019-09-24T09:43:37.000Z</published>
    <updated>2020-06-05T02:39:52.000Z</updated>
    
    <content type="html"><![CDATA[<p>本文提出了一种基于共享span表示进行多任务分类的框架（实体分类、关系分类、共指消解），将科学文献摘要抽取成知识图。</p><p>Accepted by: EMNLP 2018<br>Paper link：<a href="http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf" target="_blank" rel="noopener">http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf</a></p><a id="more"></a><h1 id="Challenge"><a href="#Challenge" class="headerlink" title="Challenge"></a>Challenge</h1><ul><li>尽管搜索引擎取得了进步，但仍然很难确定新技术及其与之前技术存在的关系</li><li>科学文本的注释需要领域专业知识，这使得注释成本高昂并限制了资源</li><li>大多数关系提取系统都是针对句内关系而设计的，但是从科学文章中提取信息需要提取句子之间的关系</li></ul><h1 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h1><ul><li>开发了一个统一的学习模型（科学信息提取器框架， SCIIE），用于提取科学实体、关系和共指消解</li><li>创建了SCIERC数据库，包含科学名词、关系类别以及共指链接的标注（500个标注的科学摘要）<ul><li>6种实体</li><li>7种关系</li><li>共指链接在实体间的标注</li></ul></li></ul><h1 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h1><p>该论文提出了SCIERC数据集，包括了500个科学摘要，标记了其中的实体类型、实体间的关系以及共指关系。</p><p>下载链接：<a href="http://nlp.cs.washington.edu/sciIE/" target="_blank" rel="noopener">http://nlp.cs.washington.edu/sciIE/</a></p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdmRKQS5wbmc?x-oss-process=image/format,png#pic_center" alt="annotation"></p><center>Fig 1.标注实例.</center><h1 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h1><h2 id="主要思想"><a href="#主要思想" class="headerlink" title="主要思想"></a>主要思想</h2><p>在低级别任务间共享参数，将三个任务看成共享span表示的多项分类问题</p><h2 id="问题定义"><a href="#问题定义" class="headerlink" title="问题定义"></a>问题定义</h2><p>输入：单词序列 $D = {w_1, …,w_n}$;</p><p>所有可能的句内词序列span $S = {s_1, … , s_N}$</p><p>输出：所有Span(即S)的实体类型E; </p><p>$S \times S$的关系R; </p><p>S中所有span的共指关系C</p><h2 id="模型定义"><a href="#模型定义" class="headerlink" title="模型定义"></a>模型定义</h2><p>将多任务学习定义为条件概率分布: $P(E,R,C|D)$</p><p>为了高效地训练和推理，将该分部拆分成：<br>$P(E,R,C|D) = P(E,R,C,S|D) = \prod^N_{i=1} P(e_i |D) P(c_i | D)\prod^N_{j=1}P(r_{ij}|D)$</p><p>其中每个随机变量的条件概率是独立标准化的：</p><script type="math/tex; mode=display">P(e_i= e|D) = \frac{exp(\Phi_E (e,s_i))} {\sum_{e' \in L_E} exp(\Phi_E(e',s_i))}</script><script type="math/tex; mode=display">P(r_{ij}= r|D) = \frac{exp(\Phi_R (r,s_i,s_j))} {\sum_{r' \in L_R} exp(\Phi_R(r',s_i,s_j))}</script><script type="math/tex; mode=display">P(c_i= j|D) = \frac{exp(\Phi_C (s_i,s_j))} {\sum_{j' \in \{1,...,i-1,\epsilon \}} exp(\Phi_E(e',s_i))}</script><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdmFpZC5wbmc?x-oss-process=image/format,png#pic_center" alt="Overview"></p><center>Fig 2. 多任务设置，三个任务被看做是顶层共享Span表示的分类问题.</center><h2 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h2><p>给定一组所有文档D，模型损失函数被定义为所有三个任务的负对数似然丢失的加权和：</p><script type="math/tex; mode=display">-\sum_{(D,R^*,E^*,C^*) \in D} \{\lambda_E logP(E^* |D) + \lambda_R logP(R^*|D) + \lambda_C log P(C^*|D)\}</script><p>$R^<em>, E^</em>, C^<em>$ 为goal。<br>令$C_i^</em>$ 为span i里所有正确的祖先。即：</p><script type="math/tex; mode=display">log P(C^*|D = \sum_{i=1...N}log\sum_{c \in C^*_i} P(c|D))</script><h2 id="打分结构"><a href="#打分结构" class="headerlink" title="打分结构"></a>打分结构</h2><ul><li><p>在共享跨度表示g上使用前馈神经网络（FFNN）来计算一组跨度和成对跨度的分数。</p><ul><li>$\phi_e(s_i)$:一个跨度$s_i$有一个实体类型e的可能性；        </li><li>$\phi_{mr}(s_i)$跨度$s_i$在一个关系r中被提到的可能性；       </li><li>$\phi_{mc}(s_i)$跨度$s_i$在一条共指链接中被提到的可能性</li><li>$\phi_r(s_i,s_j)$两个跨度与一个关系相结合的可能性；</li><li>$\phi_c(s_i,s_j)$两个跨度与一条共指链接相结合的可能性</li><li>$g_i$：$s_i$的向量表示 (ELMo)：连接来自BiLSTM的输出的$s_i$的左端点和右端点，基于注意力的软词条，嵌入span的宽度特征</li><li>span打分以及成对的span打分的计算方式：<script type="math/tex; mode=display">\phi_x(s_i) = w_x \dot FFNN_x(g_i)\phi_y(s_i,s_j)=w_y \dot FFNN_y([g_i,g_j,g_i \odot g_j])</script></li></ul></li><li>这些分数被用于计算最终打分:<script type="math/tex; mode=display">\Phi_E (e,s_i) = \phi_e(s_i)</script><script type="math/tex; mode=display">\Phi_R (r,s_i,s_j) = \phi_{mr}(s_i) + \phi_{mr}(s_j) + \phi_r(s_i,s_j)</script><script type="math/tex; mode=display">\Phi_C (s_i,s_j) = \phi_{mc}(s_i) + \phi_{mc}(s_j) + \phi_c(s_i,s_j)</script></li></ul><h2 id="推理和剪枝"><a href="#推理和剪枝" class="headerlink" title="推理和剪枝"></a>推理和剪枝</h2><p>使用波束搜索，根据打分排序减少训练和测试中成对的span的数量以将计算复杂度降低到$O(n)$.</p><p>使用$B_C$修剪共指消解任务中的span，使用$B_R$修剪关系抽取任务中的span。</p><p>使用span score $\phi_{mc}$和 $\phi_{mr}$对波束中的span进行排序，波束的大小用$\lambda_Cn$和$\lambda_Rn$进行约束。span的最大宽度为W。</p><h1 id="KG-Construction"><a href="#KG-Construction" class="headerlink" title="KG Construction"></a>KG Construction</h1><p>为了构建整个语料库中的知识图，先将SCIIE用于单个文档（摘要），再将多个文档中的实体和关系集成。</p><ul><li><p>结点（实体）抽取</p><ul><li><p>句子被启发式地标准化</p><ul><li>利用共指链接，将不通用词汇替换为通用词汇</li><li>采用字符长度最长的实体名称（使用全名替代首字母缩略）</li><li>使用单数标准化所有复数</li></ul></li><li><p>计算整个语料库中的实体出现频率</p><ul><li>出现频率&gt;k的实体为它分配结点</li><li>将频繁出现的、为子字符串的剩余实体进行合并</li></ul></li></ul></li><li><p>边（关系）分配</p><ul><li>在整个语料库中计算一对实体间的关系出现频率，选择频率最大的关系</li></ul></li></ul><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdnRkZS5wbmc?x-oss-process=image/format,png#pic_center" alt="知识图谱构建过程"></p><center>Fig 3. 知识图谱的构建过程.</center><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdndSSS5wbmc?x-oss-process=image/format,png#pic_center" alt="自动构建的知识图"></p><center>Fig 4. 自动构建的知识图.</center><h1 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h1><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3Vrdk5JSC5wbmc?x-oss-process=image/format,png#pic_center" alt="RESULT"></p><center>Table 1. 三个任务上与其他系统的性能对比.</center><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdkRRUC5wbmc?x-oss-process=image/format,png#pic_center" alt="ablation"></p><center>Table 2. 多任务学习的消融研究.</center><h1 id="KG-Analysis"><a href="#KG-Analysis" class="headerlink" title="KG Analysis"></a>KG Analysis</h1><h2 id="科学趋势分析"><a href="#科学趋势分析" class="headerlink" title="科学趋势分析"></a>科学趋势分析</h2><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9zMi5heDF4LmNvbS8yMDE5LzA5LzI0L3VrdjB6dC5wbmc?x-oss-process=image/format,png#pic_center" alt="科学趋势分析"></p><center>Fig 5. 关键词 神经网络 在NLP\speech\CV领域的历史研究趋势.Y轴：在该任务中使用神经网络的论文与使用其他论文的比例.</center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文提出了一种基于共享span表示进行多任务分类的框架（实体分类、关系分类、共指消解），将科学文献摘要抽取成知识图。&lt;/p&gt;
&lt;p&gt;Accepted by: EMNLP 2018&lt;br&gt;Paper link：&lt;a href=&quot;http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://ssli.ee.washington.edu/~luanyi/YiLuan_files/EMNLP2018_YL_sciIE.pdf&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="paper-reading" scheme="http://yoursite.com/categories/paper-reading/"/>
    
    
      <category term="knowledge graph" scheme="http://yoursite.com/tags/knowledge-graph/"/>
    
      <category term="multi-task learning" scheme="http://yoursite.com/tags/multi-task-learning/"/>
    
      <category term="paper-reading" scheme="http://yoursite.com/tags/paper-reading/"/>
    
  </entry>
  
  <entry>
    <title>Overview of Crawler Technology</title>
    <link href="http://yoursite.com/2019/03/22/Overview-of-Crawler-Technology/"/>
    <id>http://yoursite.com/2019/03/22/Overview-of-Crawler-Technology/</id>
    <published>2019-03-22T11:44:35.000Z</published>
    <updated>2019-03-22T12:17:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>大致记录了一下爬虫的整体思想和一些常用的库方便日后项目中进行查阅。本文的主要内容整理自崔庆才的爬虫教程。<br><a id="more"></a></p><h2 id="爬虫基本流程"><a href="#爬虫基本流程" class="headerlink" title="爬虫基本流程"></a>爬虫基本流程</h2><ol><li>发起请求<br>通过HTTP库向目标站点发起请求，即发送一个request，请求可以包含额外的header等信息，等待服务器响应</li><li>获取响应内容<br>如果服务器能正常响应，会得到一个response，response的内容便是所要获取的页面内容，类型可能有HTML,Json字符串，二进制数据（如图片视频）等类型。</li><li>解析内容<br>得到的内容可能是HTML，可以用正则表达式、网页解析库进行解析。可能是Json，可以直接转为Json对象解析，可能是二进制数据，可以做保存或者进一步的处理</li><li>保存数据<br>保存形式多样，可以存为文本，也可以保存至数据库，或者保存特定格式的文件</li></ol><h2 id="Request-和-Response"><a href="#Request-和-Response" class="headerlink" title="Request 和 Response"></a>Request 和 Response</h2><h3 id="Request"><a href="#Request" class="headerlink" title="Request"></a>Request</h3><ol><li>请求方式<br>主要有<strong>GET、POST</strong>两种类型，另外还有HEAD、PUT、DELETE、OPTIONS等<br>GET和POST的区别：<br>get：直接输入URL回车访问<br>post：需要构建表单，点击表单提交，请求参数不会包含在URL后</li><li>请求URL<br>URL全称统一资源定位符，如一个网页文档、一张图片、一个视频都可以用URL唯一来确定。<blockquote><p>在渲染过程中，浏览器会根据图片的URL重新发送请求，渲染出图片</p></blockquote></li><li>请求头<br>包含请求时的头部信息，如User-Agent、Host、Cookies等信息\<br>用于服务器判断配置信息</li><li>请求体<br>请求时额外携带的数据，如表单提交时的表单数据</li></ol><h3 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h3><ol><li>响应状态<br>判断网页响应状态\<br>e.g.状态码：\<br>200 成功\<br>301 跳转 \<br>404 找不到服务器\<br>505 服务器错误</li><li>响应头<br>如服务类型、内容长度、服务器信息、设置Cookie等等。</li><li>响应体<br>最主要的部分，包含了请求资源的内容，如网页HTML、图片二进制数据等。</li></ol><h2 id="能抓取的数据"><a href="#能抓取的数据" class="headerlink" title="能抓取的数据"></a>能抓取的数据</h2><ol><li>网页文本<br>如HTML文档、Json格式文本等。</li><li>图片<br>获取到的是二进制文件，保存为图片格式</li><li>视频<br>同为二进制文件，保存为视频格式即可。</li><li>其他<br>只要是能获取到的都能抓取</li></ol><h2 id="解析方式"><a href="#解析方式" class="headerlink" title="解析方式"></a>解析方式</h2><ol><li>直接处理</li><li>Json解析</li><li>正则表达式</li><li>BeautifulSoup</li><li>PyQuery</li><li>XPath</li></ol><h2 id="怎样保存数据"><a href="#怎样保存数据" class="headerlink" title="怎样保存数据"></a>怎样保存数据</h2><ol><li>文本<br>纯文本、Json、Xml等</li><li>关系型数据库<br>如MySQL、Oracle、SQL Server等具有结构化表结构形式存储。</li><li>非关系型数据库<br>如MongoDB、Redis等Key-Value形式存储。</li><li>二进制文件<br>如图片、视频、音频等等直接保存成特定形式即可。</li></ol><h1 id="Urllib库基本使用"><a href="#Urllib库基本使用" class="headerlink" title="Urllib库基本使用"></a>Urllib库基本使用</h1><h2 id="什么是Urllib"><a href="#什么是Urllib" class="headerlink" title="什么是Urllib"></a>什么是Urllib</h2><p>Python内置的HTTP请求库\<br>urllib.request 请求模块\<br>urllib.error 异常处理模块\<br>urllib.parse url解析模块(工具模块)\<br>urllib.robotparser robots.txt解析模块</p><h2 id="用法讲解"><a href="#用法讲解" class="headerlink" title="用法讲解"></a>用法讲解</h2><h3 id="Request-1"><a href="#Request-1" class="headerlink" title="Request"></a>Request</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.request.urlopen(url, data=<span class="literal">None</span>, [timeout, ]*, cafile=<span class="literal">None</span>, capath=<span class="literal">None</span>, cadefault=<span class="literal">False</span>, context=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://python.org'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将hello以post的形式传递，完成一个post的请求；若不加data则以get的形式发送</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> urllib.parse</span><br><span class="line"></span><br><span class="line">data = bytes(urllib.parse.urlencode(&#123;<span class="string">'word'</span>:<span class="string">'hello'</span>&#125;).encoding=<span class="string">'utf8'</span>)</span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/post'</span>,data=data)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在设置时间内没有得到响应的话会抛出异常；http://httpbin.org/get会返回请求时的一些参数，以json形式</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">1</span>)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将异常时间设为0.1秒，对异常进行捕获</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> urllib.error</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = urllib.request.urlopen(<span class="string">'http://httpbin.org/get'</span>,timeout=<span class="number">0.1</span>)</span><br><span class="line"><span class="keyword">except</span> urllib.error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):\\将错误的原因进行判断</span><br><span class="line">        print(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></table></figure><h3 id="Response-1"><a href="#Response-1" class="headerlink" title="Response"></a>Response</h3><h4 id="响应类型"><a href="#响应类型" class="headerlink" title="响应类型"></a>响应类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(type(response))</span><br></pre></td></tr></table></figure><h4 id="状态码、响应头"><a href="#状态码、响应头" class="headerlink" title="状态码、响应头"></a>状态码、响应头</h4><p>是判断响应是否成功的重要标志<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(response.status)</span><br><span class="line">print(response.getheaders())</span><br><span class="line">print(response.getheaders(<span class="string">'Server'</span>))    <span class="comment">#获取一个特定的响应头(Server)</span></span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">response = urllib.request.urlopen(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))    <span class="comment">#read是获得一个响应体的内容</span></span><br></pre></td></tr></table></figure><br>若要发送更为复杂的request<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#加入新的headers</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">request = urllib.request.Request(<span class="string">'http://www.python.org'</span>)</span><br><span class="line">response = urllib.request.urlopen(request)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br></pre></td></tr></table></figure></p><h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><p>相当于辅助工具，帮助我们进行其他的操作</p><h4 id="设置代理"><a href="#设置代理" class="headerlink" title="设置代理"></a>设置代理</h4><p>设置代理可以切换本地的ip地址使不被封<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line">proxy_handler = urllib.request.ProxyHandler(&#123;</span><br><span class="line">    <span class="string">'http'</span>:<span class="string">'http://127.0.0.1:9743'</span>,</span><br><span class="line">    <span class="string">'https'</span>:<span class="string">'https://127.0.0.1:9743'</span>,</span><br><span class="line">&#125;)</span><br><span class="line">opener = urllib.request.build_opener(proxy_handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(response.read())</span><br></pre></td></tr></table></figure></p><h4 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h4><p>用来维持登录状态<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.CookieJar() <span class="comment">#cookie创建为对象</span></span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> cookie: <span class="comment">#对cookie遍历</span></span><br><span class="line">    print(item.name+<span class="string">"="</span>+item.value)</span><br></pre></td></tr></table></figure><br>可将Cookie保存成文本文件，若cookie没有失效的话可以从文件中读出cookie，请求时附加cookie信息来保持登录状态。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将cookie保存为txt文件</span></span><br><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">filename = <span class="string">"cookie.txt"</span></span><br><span class="line">cookie = http.cookiejar.MozillaCookieJar(filename)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">cookie.save(ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br>还有一种保存方式<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用文本文件的形式把cookie存储，然后读取出来，然后把cookie再次放到request里面，请求出了这个网页，这样请求的结果就是登陆后才能看到的网页内容</span></span><br><span class="line"><span class="keyword">import</span> http.cookiejar,urllib.request</span><br><span class="line"></span><br><span class="line">cookie = http.cookiejar.LWPCookieJar()</span><br><span class="line">cookie.load(<span class="string">'cookie.txt'</span>,ignore_discard=<span class="literal">True</span>,ignore_expires=<span class="literal">True</span>)</span><br><span class="line">handler = urllib.request.HTTPCookieProcessor(cookie)</span><br><span class="line">opener = urllib.request.build_opener(handler)</span><br><span class="line">response = opener.open(<span class="string">'http://www.baidu.com'</span>)</span><br><span class="line">print(response.read().decode(<span class="string">'utf-8'</span>))</span><br><span class="line">filename = <span class="string">"cookie.txt"</span></span><br></pre></td></tr></table></figure></p><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#请求一个不存在的网页</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason) <span class="comment">#捕捉的是URL的异常</span></span><br></pre></td></tr></table></figure><p>具体可以捕捉哪些异常，see:<a href="https://docs.python.org/3/library/urllib.html" target="_blank" rel="noopener">https://docs.python.org/3/library/urllib.html</a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#请求一个不存在的网页</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>)</span><br><span class="line"><span class="keyword">except</span> error.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason,e.code,e.headers,sep=<span class="string">'\n'</span>) </span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(e.reason) </span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    print(<span class="string">'Request Successfully'</span>)</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request,error</span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = request.urlopen(<span class="string">'http://cuiqingcai.com/index.htm'</span>,timeout = <span class="number">0.01</span>)</span><br><span class="line"><span class="keyword">except</span> error.URLError <span class="keyword">as</span> e:</span><br><span class="line">    print(type(e.reason))</span><br><span class="line">    <span class="keyword">if</span> isinstance(e.reason,socket.timeout):</span><br><span class="line">        print(<span class="string">'TIME OUT'</span>)</span><br></pre></td></tr></table></figure></p><h3 id="URL解析"><a href="#URL解析" class="headerlink" title="URL解析"></a>URL解析</h3><h4 id="urlparse"><a href="#urlparse" class="headerlink" title="urlparse"></a>urlparse</h4><p>传入一个URL，然后将URL进行分割，分割成几个部分，然后将各个部分依次进行复制\<br>所有URL都可以按标准的结构划分<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">urllib.parse.urlparse(urlstring, scheme=<span class="string">''</span>, allow_fragments=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">result = urlparse(<span class="string">'http://www.baidu.com/index.html'</span>)</span><br><span class="line">print(type(result),result)</span><br></pre></td></tr></table></figure><br>若没有协议类型，则默认为https类型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlparse</span><br><span class="line"></span><br><span class="line">result = urlparse(www.baidu.com/index.html<span class="string">',scheme="https")</span></span><br><span class="line"><span class="string">print(result)</span></span><br></pre></td></tr></table></figure><br>若allow_fragments=False，则其内容将拼接到前面的内容中（成为path或query或params）</p><h4 id="urlunparse"><a href="#urlunparse" class="headerlink" title="urlunparse"></a>urlunparse</h4><p>urlparse的反函数，将url进行拼接<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlunparse</span><br><span class="line"></span><br><span class="line">data = [<span class="string">'http'</span>,<span class="string">'www.baidu.com'</span>,<span class="string">'index.html'</span>,<span class="string">'user'</span>,<span class="string">'a=6'</span>,<span class="string">'comment'</span>]</span><br><span class="line">print(urlunparse(data))</span><br></pre></td></tr></table></figure></p><h4 id="urljoin"><a href="#urljoin" class="headerlink" title="urljoin"></a>urljoin</h4><p>用于拼接url，若前面的url和后面的url不同，后面的字段会覆盖前面的字段</p><h4 id="urlencode"><a href="#urlencode" class="headerlink" title="urlencode"></a>urlencode</h4><p>将字典对象转变为url请求参数<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'name'</span>:<span class="string">'germey'</span>,</span><br><span class="line">    <span class="string">'age'</span>:<span class="number">22</span></span><br><span class="line">&#125;</span><br><span class="line">base_url = <span class="string">'http://www.baidu.com?'</span></span><br><span class="line">url = base_url + urlencode(params)</span><br><span class="line">print(url)</span><br></pre></td></tr></table></figure></p><h3 id="robotparser"><a href="#robotparser" class="headerlink" title="robotparser"></a>robotparser</h3><p>用来解析robot.txt文件</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大致记录了一下爬虫的整体思想和一些常用的库方便日后项目中进行查阅。本文的主要内容整理自崔庆才的爬虫教程。&lt;br&gt;
    
    </summary>
    
    
      <category term="crawler" scheme="http://yoursite.com/categories/crawler/"/>
    
    
      <category term="Crawler" scheme="http://yoursite.com/tags/Crawler/"/>
    
  </entry>
  
  <entry>
    <title>Overview of Knowledge Graph</title>
    <link href="http://yoursite.com/2019/03/22/Knowledge-Graph-Overview/"/>
    <id>http://yoursite.com/2019/03/22/Knowledge-Graph-Overview/</id>
    <published>2019-03-22T11:26:34.000Z</published>
    <updated>2019-03-22T12:17:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>在计算机世界中，节点和边的符号通过“符号具化（symbol grounding）”表征物理世界和认知世界中的对象，并作为不同个体对认知世界中信息和知识进行描述和交换的桥梁。这种使用统一形式描述的知识描述框架便于知识的分享与利用。</p><a id="more"></a><h2 id="知识图谱的类型"><a href="#知识图谱的类型" class="headerlink" title="知识图谱的类型"></a>知识图谱的类型</h2><ul><li>语言知识图谱<br>主要是存储人类语言方面的知识，其中比较典型是英文词 汇知识图谱WordNet，它由同义词集和描述同义词集之间的关系构成。</li><li>常识知识图谱<br>主要有 Cyc和 ConceptNet等。其中 Cyc 由大量实体和 关系以及支持推理的常识规则构成；ConceptNet 由大量概念以及描述 它们之间关系的常识构成。</li><li>语言认知知识图谱<br>中文知网词库HowNet是一种典型的语言认知知识图谱（语言认知知识与常识知识区别不大，因为语言是人类表达和交换信息的主要载体），HowNet致力于描述认知世界中人们对词语概念的理解，基于词语义原，揭示词语的更小语义单元的含义。</li><li>领域知识图谱<br>针对特定领域构建的知识图谱，专门为特定的领域服务， 例如：医学知识图谱 SIDER(Side Effect Resource) ，电影知识图谱 IMDB (Internet Movie Database)，音乐知识图谱MusicBrainz等，这些知识图谱在各自的领域都有着广泛的应用。</li><li>百科知识图谱<br>主要以 Linked Open Data (LOD)项目支持的开放知识 图谱为核心，主要有 Freebase、DBpedia、YAGO和Wikidata等，它们在信息检索、问答系统等任务中有着重要应用。</li></ul><h2 id="知识图谱的生命周期"><a href="#知识图谱的生命周期" class="headerlink" title="知识图谱的生命周期"></a>知识图谱的生命周期</h2><h3 id="知识体系构建"><a href="#知识体系构建" class="headerlink" title="知识体系构建"></a>知识体系构建</h3><p>指采用什么样的方式表达知识，其核心是构建一个本体对目 标知识进行描述。   </p><p><strong>输入</strong>：领域（医疗、金融…）、应用场景<br><strong>输出</strong>：领域知识本体<br><strong>关键技术</strong>：Ontology Engineering</p><p>作为语义网的应用，知识图谱的知识建模采用语义网的知 识建模方式，分为概念、关系、概念关系三元组三个层次，并利用<strong>资源描述框架(RDF</strong>)进行描述。</p><p>RDF 的基本数据模型包括了三个对象类型：  </p><ul><li>资源<br>能够使用RDF表示的对象称之为资源，包括互联网上的实体、事件和 概念等。</li><li>谓词 (Predicate)<br>主要描述资源本身的特征和资源之间的关系。每一个谓词可以定义元知识，例如，谓词的头尾部数据值的类型（如定义域和值域）、谓词与其他谓词的关系（如逆关系）。</li><li>陈述 (Statements)<br>一条陈述包含三个部分，通常称之为RDF三元组&lt;主体(subject)，谓词(predicate)，宾语(object)&gt;。其中主体是被描述的资源，谓词可以表示主体的属性，也可以表示主体和宾语之间关系。当表示属性时，宾语就是属性值；当表示关系时，宾语也是一个资源。</li></ul><h3 id="知识获取"><a href="#知识获取" class="headerlink" title="知识获取"></a>知识获取</h3><p>知识获取目标是从海量的文本数据中通过信息抽取的方式获 取知识，其方法根据所处理数据源的不同而不同。</p><p>知识图谱中数据的主要来源有：</p><ul><li>结构化数据<br>置信度高，规模小，缺乏个性化的属性信息</li><li>半结构化数据<br>置信度高，规模较大，个性化信息，形式多样，含有噪声</li><li>非结构化文本数据  <ul><li>纯文本<br>置信度低，复杂多样，规模大</li></ul></li></ul><p><strong>输入</strong>：领域知识本体；海量数据：文本、垂直站点、百科<br><strong>输出</strong>：领域知识（实体集合，实体关系/属性）<br><strong>主要技术</strong>：信息抽取；文本挖掘</p><h4 id="实体识别"><a href="#实体识别" class="headerlink" title="实体识别"></a>实体识别</h4><p>实体识别任务的目标是从文本中识别实体信息。早期有关实体识别的研究主要是针对命名实体的识别。在知识图谱领域，从文本中识别实体不仅仅局限于命名实体 ，还包括其他类别的实体，特别是领域实体。与实体识别相关的任务是实体抽取。</p><h4 id="实体消歧"><a href="#实体消歧" class="headerlink" title="实体消歧"></a>实体消歧</h4><p>目标是消除指定实体的歧义。实体消歧对于知识图谱构建和应用有着重要的作用，也是建立语言表达和知识图谱联系的关键环节。从技术路线上划分，实体消歧任务可以分为<em>实体链接</em>和<em>实体聚类</em>两种类型。</p><h4 id="关系抽取"><a href="#关系抽取" class="headerlink" title="关系抽取"></a>关系抽取</h4><p>目标是获取两个实体之间的语义关系。</p><p>语义关系可以是一元关系（例如实体的类型），也可以是二元关系（例如实体的属性）甚至是更高阶的关系。在现有知识图谱中，所处理的语义关系通常指的是一元关系和二元关系。</p><p>根据抽取目标的不同，关系抽取任务可以分为：</p><ul><li>关系分类任务：判别一句话中两个指定实体之间的语义关系。</li><li>属性抽取任务：在给定一个实体以及一个预定义关系的条件下，抽取另外一个实体。</li><li>关系实例抽取任务：给定关系类型，抽取满足该关系的实例数据。</li></ul><h4 id="事件抽取"><a href="#事件抽取" class="headerlink" title="事件抽取"></a>事件抽取</h4><p>目标是从描述事件信息的文本中抽取出用户感兴趣的事件信息并以结构化的形式呈现出来。</p><p>事件是发生在某个特定的时间点或时间段、某个特定的地域范围内，由一个或者多个角色参与的，一个或者多个动作组 成的事情或者状态的改变。</p><p>现有知识图谱大多以实体和实体之间的关系为核心，缺乏事件知识。事件知识能弥补现有以实体和实体关系为核心的知识图谱知识表达能力不足的问题，是构建知识图谱不可或缺的技术。事件结构本身的复杂性以及自然语言表达的歧义性和灵活性 ，对事件抽取提出了很大的挑战。</p><p>根据抽取方法的不同，已有的事件抽取方法可以分为</p><ul><li>基于模式匹配的事件抽取</li><li>基于机器学习的事件抽取</li></ul><h3 id="知识融合"><a href="#知识融合" class="headerlink" title="知识融合"></a>知识融合</h3><p>对不同来源、不同语言或不同结构的知识进行融合， 从而对于已有知识图谱进行补充、更新和去重。</p><p><strong>输入</strong>：抽取出来的知识；现有知识库；知识本体<br><strong>输出</strong>：统一知识库；知识置信度<br><strong>关键技术</strong>：Ontology Matching；Entity Linking</p><p>从融合的对象看：</p><ul><li>知识体系的融合：两个或多个异构知识体系进行融合，即对相同的 类别、属性、关系进行映射。</li><li>实例的融合：对于两个不同知识图谱中的实例（实体实例、关系实例）进行融合，包括不同知识体系下的实例、不同语言的实例。</li></ul><p>从融合的知识图谱类型看：</p><ul><li>竖直方向的融合：融合（较）高层通用本体与（较）底层领域本体 或实例数据</li><li>水平方向的融合：融合同层次的知识图谱，实现实例数据的互补。</li></ul><h3 id="知识存储和查询"><a href="#知识存储和查询" class="headerlink" title="知识存储和查询"></a>知识存储和查询</h3><p>因为目前知识图谱大多是基于图的数据结构，它的存储方式 主要有两种形式：</p><ul><li>RDF 格式存储：以三元组的形式存储数据</li><li>图数据库 (Graph Database)</li></ul><p><strong>输入</strong>：大规模知识库知识<br><strong>输出</strong>：知识库存储和查询服务<br><strong>主要技术</strong>：知识表示；知识查询语言；存储/检索引擎</p><h3 id="知识推理"><a href="#知识推理" class="headerlink" title="知识推理"></a>知识推理</h3><p>由于处理数据的不完备性，知识图谱中肯定存在知识缺失现象（包括实体缺失、关系缺失）。我们也很难利用抽取或者融合的方法对于缺失的知识进行补齐。因此，需要采用推理的手段发现已有知识中隐含的知识。</p><p>目前知识推理的研究主要集中在针对知识图谱中缺失关系的补足，即挖掘两个实体之间隐含的语义关系。所采用的方法可以分为两种：</p><ul><li>基于传统逻辑规则的方法进行推理：研究热点在于如何自动学习推理规则，以及如何解决推理过程中的规则冲突问题。</li><li>基于表示学习的推理：即采用学习的方式，将传统推理过程转化为基于分布式表示的语义向量相似度计算任务。这类方法优点是容错率高、可学习，缺点也显而易见，即不可解释，缺乏语义约束。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在计算机世界中，节点和边的符号通过“符号具化（symbol grounding）”表征物理世界和认知世界中的对象，并作为不同个体对认知世界中信息和知识进行描述和交换的桥梁。这种使用统一形式描述的知识描述框架便于知识的分享与利用。&lt;/p&gt;
    
    </summary>
    
    
      <category term="knowledge graph" scheme="http://yoursite.com/categories/knowledge-graph/"/>
    
    
      <category term="Knowledge Graph" scheme="http://yoursite.com/tags/Knowledge-Graph/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Dynamic programming</title>
    <link href="http://yoursite.com/2018/10/18/Algorithm-Design-and-Analysis-Dynamic-programming/"/>
    <id>http://yoursite.com/2018/10/18/Algorithm-Design-and-Analysis-Dynamic-programming/</id>
    <published>2018-10-18T13:52:10.000Z</published>
    <updated>2019-03-22T12:17:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>Main message:</p><ol><li>把子问题的求解想象成多步求解过程</li><li>子问题的最优解可以组合成原问题的最优解</li><li>Programming：tabular可以被用于避免子问题的重复计算</li></ol><a id="more"></a><p>联动： <a  href ="http://imjiawen.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/#more">Dynamic Programming 动态规划算法</a></p><h1 id="Dynamic-programming-VS-Divide-and-conquer"><a href="#Dynamic-programming-VS-Divide-and-conquer" class="headerlink" title="Dynamic programming VS. Divide-and-conquer"></a>Dynamic programming VS. Divide-and-conquer</h1><p>动态规划算法一般被用于解决优化问题。需满足以下几个特点：</p><ol><li>原问题可以被分解成更小的子问题</li><li>具有最优子结构性质，即最优解可以通过结合子问题的最优解得到。</li></ol><p>与通用的分治法框架不同，动态规划算法通常<strong>枚举</strong>所有可能的分解策略。子问题的重复计算可以通过“programming”避免。</p><h1 id="Matrix-Chain-Multiplication-problem-矩阵的链式乘法"><a href="#Matrix-Chain-Multiplication-problem-矩阵的链式乘法" class="headerlink" title="Matrix Chain Multiplication problem 矩阵的链式乘法"></a>Matrix Chain Multiplication problem 矩阵的链式乘法</h1><hr><p>INPUT:A sequence of n matrices $A_1, A_2 , …, A_n$; matrix A i has dimension $p_{i-1} \times p_i$</p><p>OUTPUT:Fully parenthesizing the product $A_1, A_2 , …, A_n$ in a way to minimize the number of scalar multiplications.</p><hr><script type="math/tex; mode=display">A_1 = \left[\begin{matrix} 1 & 2 \end{matrix}\right] A_2 = \left[ \begin{matrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{matrix} \right] A_3 =\left[\begin{matrix} 1 & 2 & 3 & 4\\ 4 & 5 & 6 & 7\\7 & 8 & 9 & 10\end{matrix} \right]</script><p>Solutions: </p><p>$((A_1)(A_2))(A_3) : (1 \times 2 \times 3) + (1 \times 3 \times 4)$ </p><p>$(A_1)((A_2)(A_3)) : (2 \times 3 \times 4) + (1 \times 2 \times 4)$</p><p>我们要如何选取矩阵相乘的顺序来使乘的次数最小呢？</p><p>若枚举所有可能的解法，时间复杂度是指数级的。我们可以将其想象成一个多步决策，将加括号看成子问题。我们使用OPT(i,j)来表示子问题，原问题可以通过计算OPT(1,n)解决。由于<strong>最优子结构</strong>性质，我们可以通过计算子问题的最优解计算出原问题的最优解。</p><script type="math/tex; mode=display">OPT(1,n) = OPT(1,k) + OPT(k+1,n) + p_1p_{k+1}p_{n+1}</script><p>我们可以通过<strong>枚举</strong>所有可能的解来获得第一步决策。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesfnsyvnj20e405a0t4.jpg" alt="recursive slt"></p><h2 id="Trials"><a href="#Trials" class="headerlink" title="Trials"></a>Trials</h2><h3 id="Trial-1"><a href="#Trial-1" class="headerlink" title="Trial 1"></a>Trial 1</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">RECURSIVE MATRIX CHAIN(i, j)</span><br><span class="line">    if i &#x3D;&#x3D; j then </span><br><span class="line">        return 0; </span><br><span class="line">    end if </span><br><span class="line">    OPT(i, j) &#x3D; +∞; </span><br><span class="line">    for k &#x3D; i to j − 1 do </span><br><span class="line">        q &#x3D; RECURSIVE MATRIX CHAIN(i, k) </span><br><span class="line">            + RECURSIVE MATRIX CHAIN(k + 1, j) + p_(i−1) p_k p_j ; </span><br><span class="line">        if q &lt; OPT(i, j) then </span><br><span class="line">            OPT(i, j) &#x3D; q; </span><br><span class="line">        end if </span><br><span class="line">    end for </span><br><span class="line">    return OPT(i, j);</span><br></pre></td></tr></table></figure><p>最优解：RECURSIVE MATRIX CHAIN(1, n)</p><p>然而，这种方式需要花费指数时间$O(n^2)$，且有大量的重复计算。我们可以开一个二维数组来存储subsolution，之后查表即可。</p><h3 id="Trial-2"><a href="#Trial-2" class="headerlink" title="Trial 2"></a>Trial 2</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">MEMORIZE_MATRIX_CHAIN(i, j) </span><br><span class="line">    if OPT[i, j] !&#x3D; NULL then </span><br><span class="line">        return OPT(i, j); </span><br><span class="line">    end if </span><br><span class="line">    if i &#x3D;&#x3D; j then </span><br><span class="line">        OPT[i, j] &#x3D; 0; </span><br><span class="line">        else </span><br><span class="line">        for k &#x3D; i to j − 1 do </span><br><span class="line">            q &#x3D; MEMORIZE MATRIX CHAIN(i, k) </span><br><span class="line">                +MEMORIZE MATRIX CHAIN(k + 1, j) </span><br><span class="line">                    +p i−1 p k p j ; </span><br><span class="line">            if q &lt; OPT[i, j] then </span><br><span class="line">                OPT[i, j] &#x3D; q; </span><br><span class="line">            end if </span><br><span class="line">        end for </span><br><span class="line">    end if </span><br><span class="line">    return OPT[i, j];</span><br></pre></td></tr></table></figure><p>原问题可以通过调用MEMORIZE_MATRIX_CHAIN(1, n)并 将所有OPT[i,j]设为NULL来解决。时间复杂度为$O(n^3)$</p><h3 id="Trial-3"><a href="#Trial-3" class="headerlink" title="Trial 3"></a>Trial 3</h3><p>更快的一种解决方式：自底向上迭代<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MATRIX CHAIN MULTIPLICATION(p 0 , p 1 , ..., p n )</span><br><span class="line">    for i &#x3D; 1 to n do </span><br><span class="line">        OPT(i, i) &#x3D; 0; </span><br><span class="line">    end for </span><br><span class="line">    for l &#x3D; 2 to n do </span><br><span class="line">        for i &#x3D; 1 to n − l + 1 do </span><br><span class="line">            j &#x3D; i + l − 1; </span><br><span class="line">            OPT(i, j) &#x3D; +∞; </span><br><span class="line">            for k &#x3D; i to j − 1 do</span><br><span class="line">                q &#x3D; OPT(i, k) + OPT(k + 1, j) + p i−1 p k p j ; </span><br><span class="line">                if q &lt; OPT(i, j) then </span><br><span class="line">                    OPT(i, j) &#x3D; q; </span><br><span class="line">                    S(i, j) &#x3D; k; </span><br><span class="line">                end if </span><br><span class="line">            end for </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return OPT(1, n);</span><br></pre></td></tr></table></figure><br><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfntaifj20nb089dgw.jpg" alt=""></p><p>解题顺序：红 $\Rightarrow$ 绿 $\Rightarrow$ 橙 $\Rightarrow$ 蓝，自底而上，先列出所有子问题</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fwesfnswo9j20f207rdge.jpg" alt=""></p><p><strong>step 1：</strong></p><p>OPT[1,2],OPT[2,3],OPT[3,4]</p><p><strong>step 2：</strong></p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[1,2] + OPT[3,3] + p_0 \times p_2 \times p_3 \\ OPT[1,1] + OPT[2,3] + p_0 \times p_1 \times p_3  \end{aligned} \right.</script><p>Thus, SPLITTER[1,2] = 2.</p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[2,2] + OPT[3,4] + p_1 \times p_2 \times p_4 \\ OPT[2,3] + OPT[4,4] + p_1 \times p_3 \times p_4  \end{aligned} \right.</script><p>Thus, SPLITTER[2,4] = 3.</p><p><strong>step 3：</strong></p><script type="math/tex; mode=display">OPT[1,3] = min \left\{ \begin{aligned} OPT[1,1] + OPT[2,4] + p_0 \times p_1 \times p_4 \\ OPT[1,2] + OPT[3,4] + p_0 \times p_2 \times p_4 \\ OPT[1,3] + OPT[4,4] + p_0 \times p_3 \times p_4  \end{aligned} \right.</script><p>Thus, SPLITTER[1,4] = 3.</p><p>在此方法中，只有子问题的最优解被计算，因此没有经过遍历，不是指数级的复杂度。</p><h2 id="Backtracking"><a href="#Backtracking" class="headerlink" title="Backtracking"></a>Backtracking</h2><p>从OPT[1,n]开始回溯每一个决策阶段。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesfnst9hj20eo07fmxk.jpg" alt=""></p><p>Step 1: $(A_1A_2A_3)(A_4)$</p><p>Step 2: $((A_1A_2)(A_3))(A_4)$</p><p>Step 3: $(((A_1)(A_2)(A_3))(A_4)$</p><h1 id="0-1-KNAPSACK-problem-0-1背包问题"><a href="#0-1-KNAPSACK-problem-0-1背包问题" class="headerlink" title="0/1 KNAPSACK problem 0/1背包问题"></a>0/1 KNAPSACK problem 0/1背包问题</h1><hr><p>INPUT: A set of items $S = \{1, 2, …, n\}$. Item i has weight $w_i$ and value $v_i$ . A total weight limit W;<br>OUTPUT: A subset of items to maximize the total value with total weight below W.</p><hr><p>这里的0和1表示我们可以选择一个物品(1)或者放弃它(0)，我们不能选择物品的一部分。</p><p>我们可以将将最优解表示为：$OPT({1,2,…,i},w)$</p><p>最优子结构：</p><script type="math/tex; mode=display">OPT({1,2,...,n},W) = max \left\{\begin{array}{lr}OPT({1,2,...,n-1},W) \\OPT({1,2,...,n-1},W-w_n) + v_n\end{array}\right.</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Knapsack(n, W)</span><br><span class="line">    for w &#x3D; 1 to W do </span><br><span class="line">        OPT[0, w] &#x3D; 0; </span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to n do </span><br><span class="line">        for w &#x3D; 1 to W do </span><br><span class="line">            OPT[i, w] &#x3D; max&#123;OPT[i−1, w], vi +OPT[i−1, w−wi]&#125;; </span><br><span class="line">        end for </span><br><span class="line">    end for</span><br></pre></td></tr></table></figure><p>我们使用OPT[I,w]来表示OPT({1,2,…,i},w).</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesfnsy67j20bq05h74v.jpg" alt=""></p><p><strong>step 1：</strong></p><p>Initially all OPT[0, w] = 0.</p><p><strong>step 2：</strong></p><script type="math/tex; mode=display">OPT[1, 2] = max\{ OPT[0, 2], OPT[0, 0] + V_1 \} =2</script><p><strong>step 3：</strong></p><script type="math/tex; mode=display">OPT[2, 4] = max\{ OPT[1, 4], OPT[1, 2] + V_2\} =4</script><p><strong>step 4：</strong></p><script type="math/tex; mode=display">OPT[3, 3] = max\{OPT[2, 3], OPT[2, 0] + V_3\} =3</script><p><strong>backtracking</strong></p><script type="math/tex; mode=display">OPT[3, 6] = max{ OPT[2, 6](= 4), OPT[2, 3] + V_3 (= 2 + 3)} =5</script><p>Decision: Select item 3</p><script type="math/tex; mode=display">OPT[2, 3] = max{ OPT[1, 3](= 2), OPT[1, 1] + V_2 (= 0 + 2)} =2</script><p>Decision: Select item 2</p><p>时间复杂度：$O(nW)$</p><p>若将items看做是集合（recursion over sets），将花费指数倍的时间；但是若将items先进行排序（recursion over sequences），花费的时间为$O(nW)$。</p><h1 id="Sequence-Alignment-problem"><a href="#Sequence-Alignment-problem" class="headerlink" title="Sequence Alignment problem"></a>Sequence Alignment problem</h1><p><strong>Alignment</strong> is introduced to describe the generating process of an erroneous word from the correct word using a series of INS/DEL/MUTATION operations.</p><p>要比较两个序列，我们首先在合适的地方引入空格-。使得两个序列的长度相同，即$|S’ = T’|$</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesfnrx4nj206s02rglr.jpg" alt=""></p><p>对齐的字符可能有三种情况：</p><ol><li>S’[i] = “-“ : S’[i] is simply a DELETION of T’[i].</li><li>T’[i] = “-“ : S’[i] is simply an INSERTION.</li><li>Otherwise, S’[i] is a copy of T’[i] (with possible MUTATION).</li></ol><p>我们可以用以下方式来给s(a,b)打分：</p><ol><li>Match: +1 , e.g. s(‘C’ ,’C’ ) = 1.</li><li>Mismatch: -1, e.g. s(‘E’ , ‘A’ ) = −1.</li><li>Insertion/Deletion: -3, e.g. s(‘C’ , ‘-‘ ) = −3.</li></ol><p>使用对齐，我们可以找到最相似的来源，并且同样两个序列，通过不同的插入空格的方式我们可以得到不同的值。</p><hr><p>INPUT:Two sequences S and T, |S| = m, and |T| = n;<br>OUTPUT:To identify an alignment of S and T that maximizes a pre-deﬁned scoring function.</p><hr><p>这里也有三种需要考虑的情况：</p><ol><li>$S_m$ comes from $T_n$:S从T产生</li><li>$S_m$ is an INSERTION：若S的最后一个字母多敲了</li><li>$S_m$ comes from T[1..n − 1]：若S少敲了</li></ol><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfnutixj20lg05hdgb.jpg" alt=""></p><p>note:蓝色框表示子问题</p><p>因此，我们可以将子问题的一般式设计为S的前缀(S[1..i])和T的的前缀(T[1..j])。最优解可以被表示为OPT(i,j).</p><script type="math/tex; mode=display">OPT(i,j) = max \left\{\begin{array}{lr}s(S_i,T_j) + OPT(i-1, j-1) \\s('-',T_j) + OPT(i, j-1) \\s(S_i,'-') + OPT(i-1, j)\end{array}\right.</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Needleman-Wunsch(S, T)</span><br><span class="line">    for i &#x3D; 0 to m; do   \\简单的初始化，为了方便计算</span><br><span class="line">        OPT[i, 0] &#x3D; −3 ∗ i; </span><br><span class="line">    end for </span><br><span class="line">    for j &#x3D; 0 to n; do </span><br><span class="line">        OPT[0, j] &#x3D; −3 ∗ j; </span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to m do </span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            \\从三个单元里各自取了一些分，取最大</span><br><span class="line">            OPT[i,j]&#x3D;max&#123;OPT[i−1,j−1]+s(Si,Tj),OPT[i-1,j]−3,OPT[i,j−1]−3&#125;;  </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return OPT[m, n] ;</span><br></pre></td></tr></table></figure><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fwesfnwzbzj20dt0dgabl.jpg" alt=""></p><p>之后通过<strong>回溯</strong>找到最优对齐方式（开一个表格方便回溯）：</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesfnxbxaj20dm0dlgng.jpg" alt=""></p><p>在实践中，有许多中对齐方式可以达到与最优比对相似的效果，被称作次优比对。次优比对可以分为两类：1)类似的次优比对，2)不同的次优比对。</p><p>为了找到类似的次优对齐，我们使用采样技术追溯动态编程矩阵，即，不是在每个步骤采用最高得分选项，而是基于三个选项的值进行概率选择。e.g.将4以一定的概率回到之前的三个点，找一百回，用聚类的算法找到聚类中心。（最robust）</p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>若输入的数据很大（e.g.输入了两篇文章）这个算法面临了三个问题：</p><ol><li>占用空间太大</li><li>用时太长</li><li>Local</li></ol><h3 id="Space-eﬃcient-algorithm"><a href="#Space-eﬃcient-algorithm" class="headerlink" title="Space eﬃcient algorithm:"></a>Space eﬃcient algorithm:</h3><p>Reducing the space requirement from O(mn) to O(m + n) (D. S. Hirschberg, 1975).</p><p>若只计算分数而不记录对齐信息，占用的空间很小。因为我们仅需占用2个数组。绿色数组：已填，蓝色数组：待填，一旦把蓝色的数组填完，绿色的数组就没用了。白色的部分都不需要存。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4xtq3j20d50data5.jpg" alt=""></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Prefix Space Efficient Alignment(S, T, score)</span><br><span class="line">    for i &#x3D; 0 to m do </span><br><span class="line">        score[i] &#x3D; −3 ∗ i;   \\绿色数组</span><br><span class="line">    end for </span><br><span class="line">    for i &#x3D; 1 to m do </span><br><span class="line">        newscore[0] &#x3D; 0;      \\蓝色数组</span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            newscore[j] &#x3D; max&#123;score[j − 1] + s(S i , T j ), score[j] 3, newscore[j − 1] − 3&#125;; </span><br><span class="line">        end for </span><br><span class="line">        for j &#x3D; 1 to n do </span><br><span class="line">            score[j] &#x3D; newscore[j]; </span><br><span class="line">        end for </span><br><span class="line">    end for </span><br><span class="line">    return score[n];</span><br></pre></td></tr></table></figure><p>相应地，我们也可以使用S和T的后缀获得分数和对齐方式。</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4mo4ej20dc0dkjsx.jpg" alt=""></p><p>但是这种方式无法回溯对齐信息。因此，一种更聪明的方式是我们可以将S分为两半(where $S_{\frac{m}{2}}$is aligned to,denoted as q)，分别计算对齐信息。</p><script type="math/tex; mode=display">OPT(S,T) = OPT(S[1...\frac{m}{2}],T[1..q])+OPT(S[\frac{m}{2}+1..m],T[q+1..n])</script><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Linear Space Alignment( S, T )</span><br><span class="line">    Allocate two arrays f and b; each array has a size of m Prefix Space Efficient Alignment(S[1.. m ], T, f); </span><br><span class="line">    Suffix Space Efficient Alignment(S[ m + 1..m], T, b); </span><br><span class="line">    Let q &#x3D; argmaxi (f[i] + b[i]); </span><br><span class="line">    Free arrays f and b; </span><br><span class="line">    Record aligned-position &lt; m&#x2F;2 , q &gt; in an array A; </span><br><span class="line">    Linear Space Alignment(S[1.. m ], T[1..q]); </span><br><span class="line">    Linear Space Alignment(S[ m + 1..m], T[q + 1..n]); </span><br><span class="line">    return A;</span><br></pre></td></tr></table></figure><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fwesg4o38wj20jp0f1mz5.jpg" alt=""><br><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fwesg4nrcej20jq0f5gnj.jpg" alt=""></p><p>先把S分为恰好左一半（前缀，forward）和右一半（后缀，backward），拿’OCUR’与T的总体作比较.从图中可以看出，分数一定是由S前一半的上半部分和后一半的下半部分产生。</p><p>由此，所需的空间仅为$O(m+n)$.</p><h3 id="Time-complexity"><a href="#Time-complexity" class="headerlink" title="Time complexity"></a>Time complexity</h3><p>我们可以发现，足够相似的是对角线，因此我们可以只关心条带内。<br>Banded DP仅需花费$O(\alpha n)$的时间复杂度。它为线性的算法，比原来快得多，条带外的部分我们可以不用考虑。</p><h3 id="Local"><a href="#Local" class="headerlink" title="Local"></a>Local</h3><p>全局比对：识别两个完整序列之间的相似性。</p><p>局部对齐：我们通常希望找到相似的段（子序列）。<br>局部对齐的目的是识别两个序列的相似区段。 其他区域可以被视为独立的，因此形成“随机匹配”。</p><p>通过增加额外的概率来改变递归：</p><script type="math/tex; mode=display">OPT(i,j) = max \left\{\begin{array}{lr}0 \\s(S_i,T_j) + OPT(i-1, j-1) \\s('-',T_j) + OPT(i, j-1) \\s(S_i,'-') + OPT(i-1, j)\end{array}\right.</script><p>其中0对应一个新的对齐。它与旧的对齐无关。</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fwesg4n05xj20aa0b9q4v.jpg" alt=""></p><p>与从右下角回溯不同，这里从最大的项开始回溯，13为相似的终点，右下角的7为相似+不同。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Main message:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把子问题的求解想象成多步求解过程&lt;/li&gt;
&lt;li&gt;子问题的最优解可以组合成原问题的最优解&lt;/li&gt;
&lt;li&gt;Programming：tabular可以被用于避免子问题的重复计算&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Basic algorithm design technique" scheme="http://yoursite.com/tags/Basic-algorithm-design-technique/"/>
    
      <category term="Dynamic programming" scheme="http://yoursite.com/tags/Dynamic-programming/"/>
    
      <category term="Optimization" scheme="http://yoursite.com/tags/Optimization/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Divide-and-Conquer</title>
    <link href="http://yoursite.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/"/>
    <id>http://yoursite.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/</id>
    <published>2018-09-24T06:44:42.000Z</published>
    <updated>2019-03-22T12:16:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>Main message:</p><ol><li>从最简单的case入手</li><li>看能否分，能否combine</li><li>不求最优，只要次优</li></ol><a id="more"></a><h1 id="一、Remarks"><a href="#一、Remarks" class="headerlink" title="一、Remarks"></a>一、Remarks</h1><p>1.对于ClosestPair问题，若暴力破解法将花费多项式时间，分治法通常可被用于节省运行时间：$O(n^2)$ $\implies$ $O(nlogn)$<br>2.这个技巧若与随机技巧结合将非常有威力</p><p>在使用分治法之前，需要先检验输入（i.e.问题是否可以被分为结构相似，规模更小的子问题）以及输出（i.e.原问题的解是否能够用子问题的解组合而成）</p><h1 id="二、Sort-Problem"><a href="#二、Sort-Problem" class="headerlink" title="二、Sort Problem"></a>二、Sort Problem</h1><p>将长度为n的数组排序</p><pre><code>INPUT: An array of n integers, say A[0..n-1];OUTPUT: The items of A in increasing order.</code></pre><p><strong><em>方法1.将其分为n-1长度的数列和一个元素</em></strong></p><p>第一种方法可以从最简单的case入手，从n=2，n=3，到逐步解决原问题</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fvl1co5hjuj20cw0atgmq.jpg" alt="分离出一个元素"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">InsertionSort( A, n )</span><br><span class="line">for j &#x3D; 0 to n - 1 do</span><br><span class="line">key &#x3D; A[j];</span><br><span class="line">i &#x3D; j - 1;</span><br><span class="line">while i &gt;&#x3D; 0 and A[i] &gt; key do</span><br><span class="line">A[i + 1] &#x3D; A[i];</span><br><span class="line">i --;</span><br><span class="line">end while</span><br><span class="line">A[i + 1] &#x3D; key;</span><br><span class="line">end for</span><br></pre></td></tr></table></figure><p>最差的情况：A数组里的元素为逆序</p><p>时间复杂度： $T(n)=T(n-1)+O(n)=O(n^2)$</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fvl1cnv0q4j206e0a3ab1.jpg" alt="最差情况"></p><p><strong><em>方法2.将其分为两个独立的子问题(MERGE SORT)</em></strong></p><p>将数组$A[0..n-1]$分为两个数组$A[0..\frac{n}{2}-1]$以及$A[\frac{n}{2}-1..n-1]$</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnxlrkj20f30armzr.jpg" alt="分为子问题"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">MergeSort(A; l; r) &#x2F;&#x2F;从l到r之间排序</span><br><span class="line">&#x2F;&#x2F; To sort part of the array A[l::r]</span><br><span class="line">if l &lt; r then</span><br><span class="line">m &#x3D; (l + r)&#x3D;2; &#x2F;&#x2F;m denotes the middle point</span><br><span class="line">MergeSort(A; l; m );</span><br><span class="line">MergeSort(A; m + 1; r);</span><br><span class="line">Merge(A; l; m; r); &#x2F;&#x2F;Combining the sorted arrays</span><br><span class="line">end if</span><br><span class="line">Merge (A; l; m; r) &#x2F;&#x2F;将左端最小与右端最小比较</span><br><span class="line">&#x2F;&#x2F;Merge A[l::m] (denoted as L) and A[m + 1::r](denoted as R).</span><br><span class="line">i &#x3D; 0; j &#x3D; 0;</span><br><span class="line">for k &#x3D; l to r do</span><br><span class="line">if L[i] &lt; R[j] then</span><br><span class="line">A[k] &#x3D; L[i];</span><br><span class="line">i + +;</span><br><span class="line">else</span><br><span class="line">A[k] &#x3D; R[j];</span><br><span class="line">j + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br></pre></td></tr></table></figure><p>时间复杂度：O(n)</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvl1cnuxq5j20ea02v74x.jpg" alt="mergesort"></p><h1 id="三、迭代的时间复杂度的分析方法："><a href="#三、迭代的时间复杂度的分析方法：" class="headerlink" title="三、迭代的时间复杂度的分析方法："></a>三、迭代的时间复杂度的分析方法：</h1><ol><li>Unrolling the recurrence 硬展开</li><li>Guess and substitution 猜然后验证</li><li>Master theorem</li></ol><h3 id="technique-1-Unrolling-the-recurrence"><a href="#technique-1-Unrolling-the-recurrence" class="headerlink" title="technique 1: Unrolling the recurrence"></a>technique 1: Unrolling the recurrence</h3><p>We have $T(n) = 2T(\frac{n}{2}) + O(n) &lt;= 2T(\frac{n}{2}) + cn$ for a constant c. Let unrolling a few levels to find a pattern, and then sum over all levels.</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnvn1mj20c408dt9u.jpg" alt="Unrolling"></p><h3 id="technique-2-Guess-and-substitution"><a href="#technique-2-Guess-and-substitution" class="headerlink" title="technique 2: Guess and substitution"></a>technique 2: Guess and substitution</h3><p>Guess and substitution: guess a solution, substitute it into the recurrence relation, and justify that it works.</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fvl1cnxy0gj20gv08kq4g.jpg" alt="Guess"></p><h3 id="technique-3-Master-theorem-主定理"><a href="#technique-3-Master-theorem-主定理" class="headerlink" title="technique 3:Master theorem  主定理"></a>technique 3:Master theorem  主定理</h3><p>Let T(n) be defined by $T(n)=aT(\frac{n}{b})+O(n^d)$ for a &gt; 1, b &gt; 1 and d &gt; 0, 其中n为问题规模，a为递推的子问题数量,$\frac{n}{b}$为每个子问题的规模（假设每个子问题的规模基本一样），  为递推以外进行的计算工作.<br>then T(n) can be bounded by:</p><ol><li>If d &lt; $\log_b a$, then $T(n)=O(n^{\log_b a})$;</li><li>If d = $\log_b a$, then $T(n)=O(n^{\log_b a} \log n)$;</li><li>If d &gt; $\log_b a$, then $T(n)=O(n^d)$.</li></ol><h1 id="四、Counting-Inversion-Problem-数逆序对"><a href="#四、Counting-Inversion-Problem-数逆序对" class="headerlink" title="四、Counting Inversion Problem  数逆序对"></a>四、Counting Inversion Problem  数逆序对</h1><p>To count inversions in an array of n integers</p><pre><code>INPUT: An array $A[0..n]$ with n distinct numbers; OUTPUT:the number of inversions. A pair of indices i and j constitutes an inversion if i &lt; j butA[i] &gt; A[j].</code></pre><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvl1cnupelj20ak041aa8.jpg" alt="CountingInversion"></p><p>可使用分治法解决数逆序对问题，其中Divide和Conquer部分与之前排序问题相同，即将问题分为两个独立的子问题。Combine部分有两种策略。</p><p><strong>策略1</strong>：若$A[0..\frac{n}{2}-1]$以及$A[\frac{n}{2}..n-1]$没有特殊的结构，则我们需要检查所有可能的配对$(i,j)$去检查逆序。即若左右数都是任意的，就必须写For循环。</p><p>时间复杂度为：$T(n)=2T(\frac{n}{2})+\frac{n^2}{4}=O(n^2)$</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fvl1cnyqh7j20d007h0uj.jpg" alt="strategy1"></p><p><strong>策略2</strong>：若每一部分为升序，则相对容易计算逆序</p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fvl1co2bztj20cv06bjsg.jpg" alt="strategy2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Sort-and-Count(A)</span><br><span class="line">Divide A into two sub-sequences L and R;</span><br><span class="line">(RCL, L) &#x3D; Sort-and-Count(L);</span><br><span class="line">(RCR, R) &#x3D; Sort-and-Count(R);</span><br><span class="line">(C, A) &#x3D; Merge-and-Count(L, R);</span><br><span class="line">return (RC &#x3D; RCL + RCR + C, A);</span><br><span class="line">Merge-and-Count (L; R)</span><br><span class="line">RC &#x3D; 0; i &#x3D; 0; j &#x3D; 0;</span><br><span class="line">for k &#x3D; 0 to ∥L∥ + ∥R∥ - 1 do</span><br><span class="line">if L[i] &gt; R[j] then</span><br><span class="line">A[k] &#x3D; R[j];</span><br><span class="line">j + +;</span><br><span class="line">RC+ &#x3D; (n&#x2F;2 - i);</span><br><span class="line">else</span><br><span class="line">A[k] &#x3D; L[i];</span><br><span class="line">i + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">return (RC, A);</span><br></pre></td></tr></table></figure><p>时间复杂度为：$T(n)=2T(\frac{n}{2})+O(n)=O(n\log n)$</p><h1 id="五、The-general-Divide-and-Conquer-paradigm"><a href="#五、The-general-Divide-and-Conquer-paradigm" class="headerlink" title="五、The general Divide and Conquer paradigm"></a>五、The general Divide and Conquer paradigm</h1><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>Many problems are recursive in structure, i.e., to solve a given problem, they call themselves several times to deal with closely related sub-problems. These sub-problems have the same form to the original problem but a smaller size.</p><h2 id="Three-Steps"><a href="#Three-Steps" class="headerlink" title="Three Steps"></a>Three Steps</h2><ol><li><strong><em>Divide</em></strong> a problem into a number of independent <strong><em>sub-problems</em></strong>;</li><li><strong><em>Conquer</em></strong> the subproblems by solving them recursively;</li><li><strong><em>Combine</em></strong> the solutions to the subproblems into the solution to the original problem.</li></ol><h2 id="Quick-Sort-algorithm"><a href="#Quick-Sort-algorithm" class="headerlink" title="Quick Sort algorithm"></a>Quick Sort algorithm</h2><p>Divide according to a randomly-selected pivot.根据随机选取的轴进行分割。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">QuickSort(A)</span><br><span class="line">S_ &#x3D; &#123;&#125;; S+ &#x3D; &#123;&#125;;</span><br><span class="line">Choose a pivot A[j] uniformly at random;</span><br><span class="line">for i &#x3D; 0 to n - 1 do  &#x2F;&#x2F;将比A[j]小的放在左边，大的放在右边</span><br><span class="line">Put A[i] in S_ if A[i] &lt; A[j];</span><br><span class="line">Put A[i] in S+ if A[i] &gt;&#x3D; A[j];</span><br><span class="line">end for</span><br><span class="line">QuickSort(S+);</span><br><span class="line">QuickSort(S_);</span><br><span class="line">Output S_, then A[j], then S+;</span><br></pre></td></tr></table></figure><ul><li>随机的操作使得这个算法变得简单而高效</li><li>然而，随机增加了分析的难度，我们不能保证取到每个问题的第$\frac{n}{2}$个元素</li></ul><p><strong>最差的情况</strong>：选取到了每个迭代中最大/最小的元素</p><script type="math/tex; mode=display">T(n) = T(n - 1) + O(n) = O(n^2)</script><p><strong>最好的情况</strong>：选取到了每个迭代中最中间的元素</p><script type="math/tex; mode=display">T(n) = 2T(\frac{n}{2}) + O(n) = O(n\log n)</script><p><strong>大多数情况</strong>：选取到了一个接近中心的轴。这种情况我们认为期望的运行时间仍为：</p><script type="math/tex; mode=display">T(n) = O(n\log n)</script><h2 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h2><p><strong>Observation 1:</strong> 对于任意i,j而言，$A[i]$和$A[j]$之间最多被比较一次。</p><p><strong>Observation 2:</strong> 当处理包含$A[i..j]$的元素时，当且仅当$A[i]$或$A[j]$被选为枢轴时比较$A[i]$和$A[j]$。</p><h2 id="Modified-Quick-Sort"><a href="#Modified-Quick-Sort" class="headerlink" title="Modified Quick Sort"></a>Modified Quick Sort</h2><p>在原算法上寻找一个好的分点（大于$/frac{n}{4}$小于$/frac{3n}{4}$的点）。它在所有项目都不同时有用，然而耗内存，且在比原算法更慢，因为当它偏离中心点时不运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ModifiedQuickSort(A)</span><br><span class="line">while TRUE do</span><br><span class="line">Choose a pivot A[j] uniformly at random;</span><br><span class="line">S_ &#x3D; &#123;&#125;; S+ &#x3D; &#123;&#125;;</span><br><span class="line">for i &#x3D; 0 to n - 1 do</span><br><span class="line">Put A[i] in S_ if A[i] &lt; A[j];</span><br><span class="line">Put A[i] in S+ if A[i] &gt; A[j];</span><br><span class="line">end for</span><br><span class="line">if ∥S+∥ &gt;&#x3D; n&#x2F;4 and ∥S_∥ &gt;&#x3D; n&#x2F;4 then</span><br><span class="line">break;</span><br><span class="line">end if</span><br><span class="line">end while</span><br><span class="line">ModifiedQuickSort(S+);</span><br><span class="line">ModifiedQuickSort(S_);</span><br><span class="line">Output S_, then A[j], and finally S+;</span><br></pre></td></tr></table></figure><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fvnb5mr9sfj20bt04ojrv.jpg" alt="nearcenter"></p><p>比起中心轴，近中心轴更容易获得。获得一个中心点为轴的概率是$frac{1}{n}$,而获得一个近中心轴的概率是$frac{1}{2}$。因此，找到一个近中心轴的期望时间为2n。此时我们不追求最优的pivot，只选择足够好。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">\\Lomuto’s implementation</span><br><span class="line">\\in-place sort 不花内存。</span><br><span class="line">QuickSort(A; l; h)</span><br><span class="line">if l &lt; h then</span><br><span class="line">p &#x3D;Partition(A; l; h);</span><br><span class="line">QuickSort(A; l; p - 1);</span><br><span class="line">QuickSort(A; p + 1; h);</span><br><span class="line">end if</span><br><span class="line">Partition(A; l; h)</span><br><span class="line">pivot &#x3D; A[h]; i &#x3D; l - 1;</span><br><span class="line">for j &#x3D; l to h - 1 do</span><br><span class="line">if A[j] &lt; pivot then</span><br><span class="line">i + +;</span><br><span class="line">Swap A[i] with A[j];</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if A[h] &lt; A[i + 1] then</span><br><span class="line">Swap A[i + 1] with A[h];</span><br><span class="line">end if</span><br><span class="line">return i + 1;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">\\Hoare’s implementation</span><br><span class="line">QuickSort(A; l; h)</span><br><span class="line">if l &lt; h then</span><br><span class="line">p &#x3D;Partition(A; l; h);</span><br><span class="line">QuickSort(A; l; p); &#x2F;&#x2F;Reason: A[p] might not be at its correct position</span><br><span class="line">QuickSort(A; p + 1; h);</span><br><span class="line">end if</span><br><span class="line">Partition(A; l; h)</span><br><span class="line">i &#x3D; l - 1; j &#x3D; h + 1; pivot &#x3D; A[l];</span><br><span class="line">while TRUE do</span><br><span class="line">repeat</span><br><span class="line">j &#x3D; j - 1;</span><br><span class="line">until A[j] &lt;&#x3D; pivot or j &#x3D;&#x3D; l;</span><br><span class="line">repeat</span><br><span class="line">i &#x3D; i + 1;</span><br><span class="line">until A[i] &gt;&#x3D; pivot or i &#x3D;&#x3D; h;</span><br><span class="line">if i &gt;&#x3D; j then</span><br><span class="line">return j;</span><br><span class="line">end if</span><br><span class="line">Swap A[i] with A[j];</span><br><span class="line">end while</span><br></pre></td></tr></table></figure><blockquote><blockquote><p>快速排序只在无重复元素时性能好，若有重复的元素，可用PARTITION算法来解决这个问题，即将数列分为三部分：比pivot大，与pivot相等，比pivot小。仅需对不等于pivot的partitions进行迭代排序。</p></blockquote></blockquote><h2 id="Selection-problem"><a href="#Selection-problem" class="headerlink" title="Selection problem"></a>Selection problem</h2><p>找到数组中第K小的item</p><pre><code>INPUT:An array A = [A0, A1,.., An_1], and a number k &lt; n;OUTPUT:The k-th smallest item in general case (or the median of A as a specical case).</code></pre><p>若先将A排序再寻找第k个值，时间复杂度为$O(nlog n)$。相反地，若使用分治法，则有可能开发出更快的算法（e.g.deterministic linear algorithm by Blum et al.）。时间复杂度为$O(n)$。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Select(A; k)</span><br><span class="line">Choose an element Ai from A as a pivot;</span><br><span class="line">S+ &#x3D; &#123;&#125;;</span><br><span class="line">S_ &#x3D; &#123;&#125;;</span><br><span class="line">for j &#x3D; 1 to n do</span><br><span class="line">if Aj &gt; Ai then</span><br><span class="line">S+ &#x3D; S+ U &#123;Aj&#125;;</span><br><span class="line">else</span><br><span class="line">S_ &#x3D; S_ U &#123;Aj&#125;;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if |S_| &#x3D; k - 1 then</span><br><span class="line">return Ai;</span><br><span class="line">else if |S_| &gt; k - 1 then</span><br><span class="line">return Select(S_; k);  \\S的size越小越好</span><br><span class="line">else</span><br><span class="line">return Select(S+; k - |S_| + 1);</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><h3 id="How-to-choose-a-pivot"><a href="#How-to-choose-a-pivot" class="headerlink" title="How to choose a pivot?"></a>How to choose a pivot?</h3><p>对于pivot（中心元），我们有三种选择方式：</p><p><strong>最差的选择</strong>：选取到了每个迭代中最小的元素(线性下降)</p><script type="math/tex; mode=display">T(n) = T(n - 1) + O(n) = O(n^2)</script><p><strong>最好的选择</strong>：选取到了每个迭代中最中间的元素（指数级下降）</p><script type="math/tex; mode=display">T(n) = T(\frac{n}{2}) + O(n) = O(n)</script><p><strong>好的选择</strong>：选取到了一个接近中心的pivot。（子问题最坏的情况也是指数级下降）</p><script type="math/tex; mode=display">T(n) ≤ T((1 − ϵ)n) + O(n) ≤ cn + c(1 − ϵ)n + c(1 − ϵ)^2 + ....=  O(n)</script><h3 id="How-to-select-a-nearly-central-pivot"><a href="#How-to-select-a-nearly-central-pivot" class="headerlink" title="How to select a nearly-central pivot?"></a>How to select a nearly-central pivot?</h3><p>我们可以通过以下几种方式尝试获得一个完整集合的中间值：</p><ul><li>Selecting a central pivot via <strong>examining medians of groups</strong></li><li>Selecting a central pivot via <strong>randomly selecting an element</strong></li><li>Selecting a central pivot via <strong>examining a random sample</strong></li></ul><h4 id="Strategy-1-BFPRT-algorithm-uses-median-of-medians-as-pivot"><a href="#Strategy-1-BFPRT-algorithm-uses-median-of-medians-as-pivot" class="headerlink" title="Strategy 1:BFPRT algorithm uses median of medians as pivot"></a>Strategy 1:BFPRT algorithm uses median of medians as pivot</h4><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fw46ro5745j20g803wgnc.jpg" alt="BFPRT"></p><p>SelectMedian(A)<br>    Line up elements in groups of 5 elements;</p><ol><li>Find the median of each group; //cost $\frac{6n}{5}$ time</li><li>Find the median of medians (denoted as M)through recursively running Select over the group medians; // $T(\frac{n}{5})$ time</li><li>Use M as pivot to partition A into S_ and S+; //$O(n)$ time</li><li>if |S_| = k - 1 then</li><li>return M;</li><li>else if |S_| &gt; k - 1 then</li><li>return Select(S_; k); //at most $T(\frac{7n}{10})$ time</li><li>else</li><li>return Select(S+; k - |S_| - 1); //at most $T(\frac{7n}{10})$ time</li><li>end if</li></ol><p>这种方法较耗内存，我们也可以使用原位替换的算法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">Select(A; l; r; k)</span><br><span class="line">while TRUE do</span><br><span class="line">if l &#x3D;&#x3D; r then</span><br><span class="line">return l;</span><br><span class="line">end if</span><br><span class="line">p &#x3D;Pivot(A; l; r); &#x2F;&#x2F;Use median of medians A[p] as pivot ;</span><br><span class="line">pos &#x3D;Partition(A; l; r; p); &#x2F;&#x2F;pos represents the final position of the pivot, A[l..pos - 1] deposit S_ and A[pos + 1..r] deposit S+;</span><br><span class="line">if (k - 1) &#x3D;&#x3D; pos then</span><br><span class="line">return k - 1;</span><br><span class="line">else if (k - 1) &lt; pos then</span><br><span class="line">r &#x3D; pos - 1;</span><br><span class="line">else</span><br><span class="line">l &#x3D; pos + 1;</span><br><span class="line">end if</span><br><span class="line">end while</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">Pivot(A, l, r)</span><br><span class="line">if (r - l) &lt; 5 then</span><br><span class="line">return Partition5(A, l, r); &#x2F;&#x2F;Get median for 5 or less elements;</span><br><span class="line">end if</span><br><span class="line">for i &#x3D; l to r by 5 do</span><br><span class="line">right &#x3D; i + 4;</span><br><span class="line">if right &gt; r then</span><br><span class="line">right &#x3D; r;</span><br><span class="line">end if</span><br><span class="line">m &#x3D;Partition5(A, i, right); &#x2F;&#x2F;Get median of a group;</span><br><span class="line">Swap A[m] and A[l + [(i-1)&#x2F;5]];</span><br><span class="line">end for</span><br><span class="line">return Select(A, l, l + [(r-l)&#x2F;5],(r-l)&#x2F;10 + 1);</span><br><span class="line">&#x2F;&#x2F;</span><br><span class="line">Partition(A, l, r, p)</span><br><span class="line">pivot &#x3D; A[p];</span><br><span class="line">Swap A[p] and A[r]; &#x2F;&#x2F;Move pivot to the right end;</span><br><span class="line">i &#x3D; l;</span><br><span class="line">for j &#x3D; l to r - 1 do</span><br><span class="line">if A[j] &lt; pivot then</span><br><span class="line">Swap A[i] and A[j];</span><br><span class="line">i + +;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">Swap A[r] and A[i];</span><br><span class="line">return i;</span><br></pre></td></tr></table></figure><p>图解：</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5k3wj20i50cw422.jpg" alt="part1"></p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5sauj20ga0czado.jpg" alt="part2"></p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fw46ro5n6bj20gr0dc42f.jpg" alt="part3"></p><h4 id="Strategy-2-QuickSelect-algorithm-randomly-select-an-element-as-pivot"><a href="#Strategy-2-QuickSelect-algorithm-randomly-select-an-element-as-pivot" class="headerlink" title="Strategy 2: QuickSelect algorithm randomly select an element as pivot"></a>Strategy 2: QuickSelect algorithm randomly select an element as pivot</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">QuickSelect(A, k)</span><br><span class="line">Choose an element Ai from A uniformly at random;</span><br><span class="line">S+ &#x3D; &#123;&#125;;</span><br><span class="line">S_ &#x3D; &#123;&#125;;</span><br><span class="line">for all element Aj in A do</span><br><span class="line">if Aj &gt; Ai then</span><br><span class="line">S+ &#x3D; S+ U &#123;Aj&#125;;</span><br><span class="line">else</span><br><span class="line">S_ &#x3D; S_ U &#123;Aj&#125;;</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">if |S_| &#x3D; k - 1 then</span><br><span class="line">return Ai;</span><br><span class="line">else if |S_| &gt; k - 1 then</span><br><span class="line">return QuickSelect(S_; k);</span><br><span class="line">else</span><br><span class="line">return QuickSelect(S+; k - |S_| - 1);</span><br><span class="line">end if</span><br></pre></td></tr></table></figure><p><strong>Basic idea:</strong> when selecting an element uniformly at random, it is highly likely to get a good pivot since a fairly large fraction of the elements are nearly-central.</p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fw46ro56shj20fi07wwg5.jpg" alt="atRandom"></p><p>The expected running time of QuickSelect: T(n) = O(n);</p><h4 id="Strategy-3-Floyd-Rivest-algorithm-selects-a-pivot-based-on-random-samples"><a href="#Strategy-3-Floyd-Rivest-algorithm-selects-a-pivot-based-on-random-samples" class="headerlink" title="Strategy 3: Floyd-Rivest algorithm selects a pivot based on random samples"></a>Strategy 3: Floyd-Rivest algorithm selects a pivot based on random samples</h4><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fw46t80bu9j208605l0sw.jpg" alt="Floyd-Rivest"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Floyd-Rivest-Select(A; k)</span><br><span class="line">Select a small random sample S (with replacement) from A.</span><br><span class="line">Select two pivots, denoted as u and v, from S through recursively calling Floyd-Rivest-Select. The interval [u, v], although small, is expected to cover the k-th smallest element of A.</span><br><span class="line">Divide A into three dis-joint subsets: L contains the elements less than u, M contains elements in [u; v], and H contains the elements greater than v.</span><br><span class="line">Partition A into these three sets through comparing each element Ai with u and v: if k &lt;&#x3D; n2, Ai is compared with v first and then to u only if Ai &lt;&#x3D; v. The order is reversed if k &gt; n2.</span><br><span class="line">The k-th smallest element of A is selected through recursively running over an appropriate subset.</span><br></pre></td></tr></table></figure><h1 id="六、例题"><a href="#六、例题" class="headerlink" title="六、例题"></a>六、例题</h1><p>note:一般来说，对于1维问题而言，我们可以将其分为两部分来解决问题。对于二维问题而言，我们可以将其分为横纵四个子问题来解决。但这并不是对所有情况都适用。</p><h2 id="1-ClosestPair-problem"><a href="#1-ClosestPair-problem" class="headerlink" title="1. ClosestPair problem"></a>1. ClosestPair problem</h2><p>Given a set of points in a plane, to find the closest pair.</p><pre><code>INPUT: n points in a plane;OUTPUT: The pair with the least Euclidean distance.</code></pre><p>暴力做法的时间复杂度为<script type="math/tex">T(n^2)</script>,存在很多的冗余。<br>由于将平面分为四个部分会使点的分布不均，我们将平面分割为内含均匀数量的点的两个平面，分别计算两个平面内的最小对点距离，再计算跨越两个平面的最小距离。<br>我们可以观察到，我们仅需检查中线周围以两个平面中较小的最小距离为宽度的区域就足够。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro22y6j20df07vgm1.jpg" alt="ClosestPair1"></p><p>并且，我们不需要检查条形区域内的所有点。检查它周围的11个点已足够。<br>我们将两倍宽度的长条分解成格子，每个格子中最多包含一个点，否则表明之前计算出的最小距离有误。 我们对y轴进行排序，然后仅需将每个点与其周围11个点进行比对。</p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro2bidj209b06qjrz.jpg" alt="ClosestPair2"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">ClosestPair(pl; :::; pr)</span><br><span class="line">&#x2F;&#x2F;To find the closest points within (pl; :::; pr). Here we assume that pl,...,pr have already been sorted according to x-coordinate;</span><br><span class="line">if r - l &#x3D;&#x3D; 1 then</span><br><span class="line">return d(pl; pr);</span><br><span class="line">end if</span><br><span class="line">Use the x-coordinate of p((l+r)&#x2F;2) to divide pl,...,pr into two halves;</span><br><span class="line">d1 &#x3D; ClosestPair(LeftHalf); &#x2F;&#x2F;T(n2)</span><br><span class="line">d2 &#x3D; ClosestPair(RightHalf); &#x2F;&#x2F;T(n2)</span><br><span class="line">d &#x3D; min(d1; d2);</span><br><span class="line">Sort points within the 2d wide strip by y-coordinate; &#x2F;&#x2F;O(n log n)</span><br><span class="line">Scan points in y-order and calculate distance between each point with its next 11 neighbors. Update d if finding a distance less than d;  &#x2F;&#x2F;O(n)</span><br></pre></td></tr></table></figure><p>Time-complexity: <script type="math/tex">T(n) = 2T(\frac{n}{2}) + O(n log n) = O(n log^2 n)</script>.</p><p>为了是复杂度降到O(n),我们可以引入structure，使用merge将每一个子问题先排序。</p><p><strong>实例：</strong></p><p><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fw46ro5d4aj20d909r40m.jpg" alt="ClosestPair3"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Main message:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从最简单的case入手&lt;/li&gt;
&lt;li&gt;看能否分，能否combine&lt;/li&gt;
&lt;li&gt;不求最优，只要次优&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Basic algorithm design technique" scheme="http://yoursite.com/tags/Basic-algorithm-design-technique/"/>
    
      <category term="Divide-and-Conquer" scheme="http://yoursite.com/tags/Divide-and-Conquer/"/>
    
      <category term="Sort Algorithm" scheme="http://yoursite.com/tags/Sort-Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Algorithm Design and Analysis - Overview</title>
    <link href="http://yoursite.com/2018/09/14/Algorithm-Design-and-Analysis-Overview/"/>
    <id>http://yoursite.com/2018/09/14/Algorithm-Design-and-Analysis-Overview/</id>
    <published>2018-09-14T12:51:42.000Z</published>
    <updated>2018-10-20T10:50:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天上了卜东波老师的第一次算法课，对算法的概况有了一个大体的了解，在这里对今天的内容做一些总结。【Three solutions：Induction, Improvemrnt and Enumeration】</p><a id="more"></a><h2 id="一、Mind-Map"><a href="#一、Mind-Map" class="headerlink" title="一、Mind Map"></a>一、Mind Map</h2><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9hdwxga9j20j60j0gmj.jpg" alt="MindMap"></p><h2 id="二、三种基本的算法策略"><a href="#二、三种基本的算法策略" class="headerlink" title="二、三种基本的算法策略"></a>二、三种基本的算法策略</h2><p>基本上，所有的算法题都可以用三种策略解决。</p><ul><li><strong>Divide-and-conquer</strong>: Let’s start from the “smallest”<br>problem first, and investigate whether a large problem can<br><strong><em>reduce to smaller subproblems</em></strong>.</li></ul><p>分治法，将问题分解为小的问题，从最小问题出发解决问题。</p><p>See: <a  href ="http://imjiawen.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/">Algorithm_Design_and Analysis-Divide-and-Conquer</a></p><ul><li><strong>“Intelligent” Enumeration</strong>: Consider an optimization<br>problem. If the solution can be constructed step by step, we might enumerate <strong><em>all possible complete solutions</em></strong> by constructing a <strong><em>partial solution tree</em></strong>. Due to the huge size of the search tree, some techniques should be employed to prune it.</li></ul><p>动态规划就是一种枚举所有可能性的算法，see：<a  href ="http://imjiawen.com/2018/09/24/Algorithm-Design-and-Analysis-Divide-and-Conquer/">Algorithm Design and Analysis - Dynamic programming</a></p><p>枚举法，枚举所有的解。可使用trick(如设定下界)来加快。</p><ul><li><strong>Improvement</strong>: Let’s start from <strong><em>an initial complete<br>solution</em></strong>, and try to improve it step by step.</li></ul><p>若无法将问题分解，就从质量不太好的完整解出发，逐步优化</p><h2 id="三、例题"><a href="#三、例题" class="headerlink" title="三、例题"></a>三、例题</h2><p><strong>EX1.Calculating the greatest common divisor (gcd)</strong><br>求最小公约数</p><p>The greatest common divisor of two integers a and b, when at least one of them is not zero, is the largest positive integer that divides the numbers without a remainder.</p><pre><code>INPUT: two n-bits numbers a, and b (a &gt;= b)OUTPUT: gcd(a; b)</code></pre><p>已知gcd(1; 0) = 1;如何求解gcd(1949; 101)?</p><p>可将复杂问题分解成小的问题(辗转相除法)：gcd(1949; 101) = gcd(101; 1949 mod 101) = gcd(101; 30)= gcd(30; 101 mod 30) = gcd(30; 11)= gcd(11; 30 mod 11) = gcd(11; 8)= gcd(8; 3) = gcd(3; 2) =<br>gcd(2; 1) = gcd(1; 0) = 1</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">function Euclid(a; b)</span><br><span class="line">if b &#x3D; 0 then</span><br><span class="line">return a;</span><br><span class="line">end if</span><br><span class="line">return Euclid(b; a mod b);</span><br></pre></td></tr></table></figure><p><strong>EX2.traveling salesman problem (TSP)</strong><br>周游城市的最短距离</p><pre><code>INPUT: n cities V = {1; 2;...; n}, and a distance matrix D, where dij (1 &lt;= i; j &lt;= n) denotes the distance between city i and j.OUTPUT: the shortest tour that visits each city exactly once and returns to the origin city.</code></pre><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9he4eu4dj204b04mmx9.jpg" alt="map1"></p><p><strong><em>Trial 1: Divide and conquer</em></strong></p><p>我们可通过计算 M(S,e) 来计算最小距离。S为要拜访的节点的集合，e为结束节点。</p><p>如，最短的距离我们可通过以下式子来计算：</p><p>min{ d2;1 +M({3; 4}; 2); d3;1 +M({2; 4}; 3); d4;1 +M({2; 3}; 4)}</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;算是一种动态规划算法</span><br><span class="line">function TSP(V;D)</span><br><span class="line">return min&#123; M(V - &#123;e&#125;; e) + de1&#125;;  &#x2F;&#x2F;e属于V且e不为1</span><br><span class="line"></span><br><span class="line">function M(S; e)</span><br><span class="line">if S &#x3D; &#123;v&#125; then</span><br><span class="line">M(S; e) &#x3D; d1v + dve;</span><br><span class="line">return M(S; e);</span><br><span class="line">end if</span><br><span class="line">return min&#123; M(S - &#123;i&#125;; i) + dei&#125;;  &#x2F;&#x2F;i属于S，i不为e</span><br></pre></td></tr></table></figure><p><strong><em>Trial 2: Improvement strategy</em></strong></p><p>从一个完整的解中开始，一步一步去完善它。Newton法，随机梯度下降和MC都用到了这个策略。但这种方法不一定能够获得最优解。可得到最优解的情况：线性规划，二次规划，网络流等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function GenericImprovement(G;D)  &#x2F;&#x2F;通用，逐步迭代完整解</span><br><span class="line">Let s be an initial tour;   &#x2F;&#x2F;初始解的选择很重要</span><br><span class="line">while TRUE do</span><br><span class="line">Select a new tour s′ from the neighbourhood of s; &#x2F;&#x2F;扰动越小越好</span><br><span class="line">if s′ is shorter than s then</span><br><span class="line">s &#x3D; s′;</span><br><span class="line">end if</span><br><span class="line">if stopping(s) then  &#x2F;&#x2F;s满足退出条件</span><br><span class="line">return s;</span><br><span class="line">end if</span><br><span class="line">end while</span><br></pre></td></tr></table></figure><p><strong><em>Trial 3: Intelligent” enumeration strategy</em></strong></p><p>完整的解可以表示为n条边的排列。将边缘按照一定顺序排列，一个完整的解可以被表示为：X = [x1, x2,…, xm]。 例如：a -&gt; b -&gt; c -&gt; d -&gt; e -&gt; a 可以被表示为 X = [1, 0, 0, 1, 1, 0, 0, 1, 0, 1]。<br>所有的环游都可以写成这种形式，我们就能枚举出所有的解。</p><p><img src="https://wx3.sinaimg.cn/mw690/83fd5bdely1fv9he4hzsgj208a06ewf0.jpg" alt="map2"></p><p><img src="https://wx4.sinaimg.cn/mw690/83fd5bdely1fv9heynqcqj20i2072gn3.jpg" alt="tree"></p><p>子节点：表示一个完整的解</p><p>内部解：表示一个部分解，是一个已知item的子集</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">function GenericBacktrack(P0)  &#x2F;&#x2F;枚举所有的解</span><br><span class="line">Let A &#x3D; fP0g. &#x2F;&#x2F;Start with the original problem P0. Here, A</span><br><span class="line">denotes the active subproblems that are unexplored.</span><br><span class="line">best_so_far &#x3D; 1;   &#x2F;&#x2F;当前知道的最短路程</span><br><span class="line">while A ̸&#x3D; NULL do  &#x2F;&#x2F;当还有节点要扩展时</span><br><span class="line">Choose and remove a subproblem P from A;</span><br><span class="line">Expand P into smaller subproblems P1, P2,..., Pk;</span><br><span class="line">for i &#x3D; 1 to k do</span><br><span class="line">if Pi corresponds to a complete solution then</span><br><span class="line">Update best_so_far if the corresponding objective function value is better;  &#x2F;&#x2F;对应一个完整解</span><br><span class="line">else</span><br><span class="line">Insert Pi into A;   &#x2F;&#x2F;对应一个部分解</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">end while</span><br><span class="line">return best_so_far;</span><br></pre></td></tr></table></figure><p>然而，这种方式计算量巨大，需要花费指数倍的时间，且我们无需在内存中存储整个树。因此，我们可以从中剔除一些低质量的或者不符合条件的部分解（贪心算法）。我们可以使用heuristic functions 和下界(lower bound functions)来评估部分解的质量。【这是EM算法的核心】</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">function IntelligentBacktrack(P0)</span><br><span class="line">Let A &#x3D; fP0g. &#x2F;&#x2F; Start with the original problem P0. Here A denotes the active subproblems that are unexplored.</span><br><span class="line">best_so_far &#x3D; infinite;</span><br><span class="line">while A ̸&#x3D; NULL do</span><br><span class="line">Choose a subproblem P in A with lower bound less than best_so_far;</span><br><span class="line">Remove P from A;</span><br><span class="line">Expand P into smaller subproblems P1, P2, ..., Pk,</span><br><span class="line">for i &#x3D; 1 to k do</span><br><span class="line">if Pi corresponds to a complete solution then</span><br><span class="line">Update best so far;</span><br><span class="line">else</span><br><span class="line">if lowerbound(Pi) &lt;&#x3D; best so far then Insert Pi into A;</span><br><span class="line">end if</span><br><span class="line">end if</span><br><span class="line">end for</span><br><span class="line">end while</span><br><span class="line">return best_so_far;</span><br></pre></td></tr></table></figure><h2 id="四、小结"><a href="#四、小结" class="headerlink" title="四、小结"></a>四、小结</h2><ol><li>先观察问题的结构，解的形式，再设计算法</li><li>能分解成子问题是一个非常有效的信号</li><li>在优化问题中，下界信息非常重要</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天上了卜东波老师的第一次算法课，对算法的概况有了一个大体的了解，在这里对今天的内容做一些总结。【Three solutions：Induction, Improvemrnt and Enumeration】&lt;/p&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Algorithm Design and Analysis" scheme="http://yoursite.com/tags/Algorithm-Design-and-Analysis/"/>
    
      <category term="Course summary" scheme="http://yoursite.com/tags/Course-summary/"/>
    
      <category term="Overview" scheme="http://yoursite.com/tags/Overview/"/>
    
  </entry>
  
  <entry>
    <title>Dynamic programming 动态规划算法</title>
    <link href="http://yoursite.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2018/08/14/Dynamic-programming-%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%AE%97%E6%B3%95/</id>
    <published>2018-08-14T15:08:47.000Z</published>
    <updated>2018-09-08T14:20:34.000Z</updated>
    
    <content type="html"><![CDATA[<p>动态规划算法在编程题中运用场景很广(我觉得也有点难:( )，这篇博文主要总结了动态规划算法的基本思想以及一些例题。</p><a id="more"></a><h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><p>动态规划过程是：每次决策依赖于当前状态，又随即引起状态的转移。一个决策序列就是在变化的状态中产生出来的，所以，这种<strong>多阶段最优化决策解决问题的过程</strong>就称为动态规划。</p><h2 id="二、基本思想与策略"><a href="#二、基本思想与策略" class="headerlink" title="二、基本思想与策略"></a>二、基本思想与策略</h2><p>动态规划算法与分治法的区别：<strong>适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）</strong>。</p><p>动态规划算法将待求解的问题分解为若干个子阶段，按顺序求解子阶段，前一子问题的解决为后一子问题的求解提供了有用信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。</p><p>由于动态规划解决的问题多数有重叠子问题这个特点，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。</p><h2 id="三、适用情况"><a href="#三、适用情况" class="headerlink" title="三、适用情况"></a>三、适用情况</h2><p>一般动态规划问题具有三个性质：</p><ol><li>最优化原理：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。</li><li>无后效性：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。</li><li>有重叠子问题：即子问题之间是不独立的，一个子问题在下一阶段决策中可能被多次使用到。（该性质<strong>并不是动态规划适用的必要条件</strong>，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）有些子问题会被重复计算多次。动态规划算法正是利用了这种子问题的重叠性质，对每一个子问题只计算一次，然后将其计算结果保存在一个<strong>表格</strong>中，当再次需要计算已经计算过的子问题时，只是在表格中简单地查看一下结果，从而获得较高的效率。</li></ol><p>note:先创建一个哈希表，将每次不同参数的计算结果存入哈希表，当遇到相同参数时，再从哈希表里取出，就避免了重复计算<strong>【备忘录算法】</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;上台阶问题中运用备忘录算法</span><br><span class="line">int getClimbingWays(int n, HashMap&lt;Integer, Integer&gt; map)&#123;</span><br><span class="line">    if(n&lt;1)&#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;1)&#123;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">     if(n&#x3D;&#x3D;2)&#123;</span><br><span class="line">        return 2;</span><br><span class="line">    &#125;</span><br><span class="line">     if(map.contains(n))&#123;</span><br><span class="line">        return map.get(n);</span><br><span class="line">    &#125;else&#123;</span><br><span class="line">        int value &#x3D; getClimbingWays(n-1) + getClimbingWays(n-2);</span><br><span class="line">        map.put(n,value);</span><br><span class="line">        return value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="四、求解的基本步骤"><a href="#四、求解的基本步骤" class="headerlink" title="四、求解的基本步骤"></a>四、求解的基本步骤</h2><p>动态规划所处理的问题是一个<strong>多阶段决策问题</strong>，一般由初始状态开始，通过对中间阶段决策的选择，达到结束状态。这些决策形成了一个决策序列，同时确定了完成整个过程的一条活动路线(通常是求最优的活动路线)。如下所示。动态规划的设计都有着一定的模式，一般要经历以下几个步骤。</p><p><strong>初始状态 -&gt; |决策1| -&gt; |决策2| -&gt; … |决策n| -&gt; 结束状态</strong></p><ol><li><strong>划分阶段</strong>：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意<strong>划分后的阶段一定要是有序的或者是可排序的</strong>，否则问题就无法求解。</li><li><strong>确定状态和状态变量</strong>：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足<strong>无后效性</strong>。</li><li><strong>确定决策并写出状态转移方程</strong>：因为决策和状态转移有着天然的联系，<strong>状态转移就是根据上一阶段的状态和决策来导出本阶段的状态</strong> 。所以如果确定了决策，状态转移方程也就可写出。但事实上常常是反过来做，<strong>根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程</strong>。</li><li><strong>寻找边界条件</strong>：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。</li></ol><p>一般，只要解决问题的<strong>阶段</strong>、<strong>状态</strong>和<strong>状态转移决策</strong>确定了，就可以写出状态转移方程（包括边界条件）。<br>实际应用中可以按以下几个简化的步骤进行设计：</p><ol><li>描述最优解的结构</li><li>递归定义最优解的值</li><li>按自底向上的方式计算最优解的值  //此三步构成动态规划解的基础</li><li>由计算出的结果构造一个最优解  //若只要求计算最优解的值可省略</li></ol><h2 id="五、算法实现的说明"><a href="#五、算法实现的说明" class="headerlink" title="五、算法实现的说明"></a>五、算法实现的说明</h2><p>动态规划的主要难点在于理论上的设计，也就是上面4个步骤的确定，一旦设计完成，实现部分就会非常简单。</p><pre><code> 使用动态规划求解问题，最重要的就是确定动态规划三要素：（1）问题的阶段 （2）每个阶段的状态（3）从前一个阶段转化到后一个阶段之间的递推关系。</code></pre><p>递推关系必须是从次小的问题开始到较大的问题之间的转化，从这个角度来说，动态规划往往可以用递归程序来实现，不过因为<strong>递推可以充分利用前面保存的子问题的解来减少重复计算，所以对于大规模问题来说，递归有不可比拟的优势</strong>，这也是动态规划算法的核心之处。</p><p>确定了动态规划的这三要素，<strong>整个求解过程就可以用一个最优决策表来描述，最优决策表是一个二维表，其中行表示决策的阶段，列表示问题状态</strong>，表格需要<strong>填写的数据一般对应此问题的在某个阶段某个状态下的最优值</strong>（如最短路径，最长公共子序列，最大价值等），填表的过程就是根据递推关系，从1行1列开始，以行或者列优先的顺序，依次填写表格，最后根据整个表格的数据通过简单的取舍或者运算求得问题的最优解。</p><p><em>f(n,m)=max{f(n-1,m), f(n-1,m-w[n])+P(n,m)}</em></p><h2 id="六、经典动态算法题"><a href="#六、经典动态算法题" class="headerlink" title="六、经典动态算法题"></a>六、经典动态算法题</h2><p><strong>例题一：上台阶问题</strong></p><p>有n级台阶，一个人每次上一级或者两级，问有多少种走完n级台阶的方法。</p><p>分析：动态规划的实现的关键在于能不能准确合理的用动态规划表来抽象出 实际问题。在这个问题上，我们让f(n)表示走上n级台阶的方法数。</p><p>那么当n为1时，f(n) = 1,n为2时，f(n) =2,就是说当台阶只有一级的时候，方法数是一种，台阶有两级的时候，方法数为2。那么当我们要走上n级台阶，必然是从n-1级台阶迈一步或者是从n-2级台阶迈两步，所以到达n级台阶的方法数必然是到达n-1级台阶的方法数加上到达n-2级台阶的方法数之和。即f(n) = f(n-1)+f(n-2)，我们用dp[n]来表示动态规划表，dp[i],i&gt;0,i&lt;=n,表示到达i级台阶的方法数。</p><p><strong><em>迭代法（自顶向下）</em></strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;*dp是全局数组，大小为n,全部初始化为0，是题目中的动态规划表*&#x2F;</span><br><span class="line">int fun(int n)&#123;</span><br><span class="line">if (n&#x3D;&#x3D;1||n&#x3D;&#x3D;2)</span><br><span class="line">return n;</span><br><span class="line">&#x2F;*判断n-1的状态有没有被计算过*&#x2F;</span><br><span class="line">if (!dp[n-1])</span><br><span class="line">dp[n-1] &#x3D; fun(n-1);</span><br><span class="line">if(!dp[n-2])</span><br><span class="line">dp[n-2]&#x3D;fun(n-2);</span><br><span class="line">return dp[n-1]+dp[n-2];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>LeetCode相关问题：<br><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fv2hkwxy7kj20ez0c4q32.jpg" alt="leetcode问题"><br><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fv2hkwpb75j20dv06kdfs.jpg" alt="解法"></p><p><strong><em>动态规划求解（自底向上）</em></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">int getClimbingWays(int n, HashMap&lt;Integer, Integer&gt; map)&#123;</span><br><span class="line">    if(n&lt;1)&#123;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;1)&#123;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    if(n&#x3D;&#x3D;2)&#123;</span><br><span class="line">        return 2;</span><br><span class="line">    &#125;</span><br><span class="line">    int a &#x3D; 1;</span><br><span class="line">    int b &#x3D; 2;</span><br><span class="line">    int tmp &#x3D; 0;</span><br><span class="line">    </span><br><span class="line">    for (int i &#x3D; 3; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        tmp &#x3D; a + b;</span><br><span class="line">        a &#x3D; b;</span><br><span class="line">        b &#x3D; tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    return tmp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>例题二：国王与金矿（与01背包问题类似）</strong></p><p>有一个国家发现了5座金矿，每座金矿的黄金储量不同，需要参与挖掘的工人数也不同。参与挖矿工人的总数是10人。每座金矿要么全挖，要么不挖，不能派出一半人挖取一半金矿。要求用程序求解出，要想得到尽可能多的黄金，应该选择挖取哪几座金矿？</p><p>500金/5人；200金/3人；300金/4人；350金/3人；400金/5人</p><p>问题的状态转移方程式：</p><p>F(n,w) = 0 (n&lt;=1, w&lt;p[0]);  //若给定的工人数量不够挖取第一座金矿</p><p>F(n,w) = g[0] (n==1, w&gt;=p[0]);</p><p>F(n,w) = F(n-1,w) (n&gt;1, w&lt;p[n-1])</p><p>F(n,w) = max(F(n-1,w), F(n-1,w-p[n-1])+g[n-1]) (n&gt;1, w&gt;=p[n-1]) //最后一个矿有选择不挖和挖两个选择，在其中选最优的选择</p><p><strong><em>排列组合</em></strong></p><p>每一座金矿都有挖与不挖两种选择，如果有N座金矿，排列组合起来就有2^N种选择。对所有可能性做遍历，排除那些使用工人数超过10的选择，在剩下的选择里找出获得金币数最多的选择。（O(2^N)）</p><p><strong><em>简单递归</em></strong></p><p>把状态转移方程式翻译成递归程序，递归的结束的条件就是方程式当中的边界。因为每个状态有两个最优子结构，所以递归的执行流程类似于一颗高度为N的二叉树。方法的时间复杂度是O(2^N)。</p><p><strong><em>备忘录算法</em></strong></p><p>在简单递归的基础上增加一个HashMap备忘录，用来存储中间结果。HashMap的Key是一个包含金矿数N和工人数W的对象，Value是最优选择获得的黄金数。方法的时间复杂度和空间复杂度相同，都等同于备忘录中不同Key的数量。</p><p><strong><em>动态规划</em></strong></p><p><img src="https://wx2.sinaimg.cn/mw690/83fd5bdely1fv28bf1ocoj20hz04djti.jpg" alt="计算过程，除了第一行以外，每个格子都是由前一行的一个或者两个格子推导而来"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">int getMostGold(int n, int w, int[] g, int[] p)&#123;</span><br><span class="line">    int[] preResults &#x3D; new int[p.length];</span><br><span class="line">    int[] results &#x3D; new int[p.length];</span><br><span class="line">    &#x2F;&#x2F;填充边界格子的值</span><br><span class="line">    for(int i&#x3D;0; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        if(i &lt; p[0])&#123;</span><br><span class="line">            preResults[i] &#x3D; 0;</span><br><span class="line">        &#125;else&#123;</span><br><span class="line">            preResults[i] &#x3D; g[0];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;填充其余格子的值，外层循环是金矿数量，内层循环是工人数</span><br><span class="line">    for(int i&#x3D;0; i&lt;&#x3D;n; i++)&#123;</span><br><span class="line">        for(int j&#x3D;0;j&lt;&#x3D;w;j++)&#123;</span><br><span class="line">            if(j &lt; p[i])&#123;</span><br><span class="line">                results[j]&#x3D;preResults[j]; &#x2F;&#x2F;这里代码有问题，java中数组不能直接赋值，可改用clone方式赋值</span><br><span class="line">            &#125;else&#123;</span><br><span class="line">                results[j]&#x3D;Math.max(preResults[j],preResults[j-p[i]]+g[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        preResults &#x3D; results;</span><br><span class="line">    &#125;</span><br><span class="line">    return preResults[n];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法的时间复杂度是 O(n * w)，空间复杂度是(w)。需要注意的是，当金矿只有5座的时候，动态规划的性能优势还没有体现出来。当金矿有10座，甚至更多的时候，动态规划就明显具备了优势。由于动态规划方法的时间和空间都和W成正比，而简单递归却和W无关，所以当工人数量很多的时候，动态规划反而不如递归。</p><p><strong>例题三：最长公共子序列</strong></p><p>如果字符串一的所有字符按其在字符串中的顺序出现在另外一个字符串二中，<br>则字符串一称之为字符串二的子串。</p><p>注意，并不要求子串（字符串一）的字符必须连续出现在字符串二中。<br>请编写一个函数，输入两个字符串，求它们的最长公共子串，并打印出最长公共子串。<br>例如：输入两个字符串BDCABA和ABCBDAB，字符串BCBA和BDAB都是是它们的最长公共子串，<br>则输出它们的长度4，并打印任意一个子串。</p><p>LCS问题具有重叠子问题的性质，因此有些子问题可通过“查表”而直接得到。</p><p>用二维数组c[i][j]记录串x1x2⋯xi与y1y2⋯yj的LCS长度，则可得到状态转移方程<br><img src="https://wx1.sinaimg.cn/mw690/83fd5bdely1fv2hb144upj20gf03kwfd.jpg" alt="状态转移方程"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class LCSequence &#123;</span><br><span class="line">    &#x2F;&#x2F;求解str1 和 str2 的最长公共子序列</span><br><span class="line">    public static int LCS(String str1, String str2)&#123;</span><br><span class="line">        int[][] c &#x3D; new int[str1.length() + 1][str2.length() + 1];</span><br><span class="line">&#x2F;&#x2F;初始化</span><br><span class="line">        for(int row &#x3D; 0; row &lt;&#x3D; str1.length(); row++)</span><br><span class="line">            c[row][0] &#x3D; 0;</span><br><span class="line">        for(int column &#x3D; 0; column &lt;&#x3D; str2.length(); column++)</span><br><span class="line">            c[0][column] &#x3D; 0;</span><br><span class="line">        </span><br><span class="line">        for(int i &#x3D; 1; i &lt;&#x3D; str1.length(); i++)</span><br><span class="line">            for(int j &#x3D; 1; j &lt;&#x3D; str2.length(); j++)</span><br><span class="line">            &#123;</span><br><span class="line">                if(str1.charAt(i-1) &#x3D;&#x3D; str2.charAt(j-1))</span><br><span class="line">                    c[i][j] &#x3D; c[i-1][j-1] + 1;</span><br><span class="line">                else if(c[i][j-1] &gt; c[i-1][j])</span><br><span class="line">                    c[i][j] &#x3D; c[i][j-1];</span><br><span class="line">                else</span><br><span class="line">                    c[i][j] &#x3D; c[i-1][j];</span><br><span class="line">            &#125;</span><br><span class="line">        return c[str1.length()][str2.length()];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Reference："><a href="#Reference：" class="headerlink" title="Reference："></a>Reference：</h2><ol><li><a href="http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741374.html" target="_blank" rel="noopener">http://www.cnblogs.com/steven_oyj/archive/2010/05/22/1741374.html</a></li><li><a href="http://www.cnblogs.com/pengyingh/articles/2396427.html" target="_blank" rel="noopener">http://www.cnblogs.com/pengyingh/articles/2396427.html</a></li><li><a href="https://www.sohu.com/a/153858619_466939" target="_blank" rel="noopener">https://www.sohu.com/a/153858619_466939</a></li><li><a href="https://www.cnblogs.com/hapjin/p/5572483.html" target="_blank" rel="noopener">https://www.cnblogs.com/hapjin/p/5572483.html</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;动态规划算法在编程题中运用场景很广(我觉得也有点难:( )，这篇博文主要总结了动态规划算法的基本思想以及一些例题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="algorithm" scheme="http://yoursite.com/categories/algorithm/"/>
    
    
      <category term="Dynamic programming" scheme="http://yoursite.com/tags/Dynamic-programming/"/>
    
      <category term="Algorithm summary" scheme="http://yoursite.com/tags/Algorithm-summary/"/>
    
  </entry>
  
  <entry>
    <title>Hello world</title>
    <link href="http://yoursite.com/2018/05/01/Hello-world/"/>
    <id>http://yoursite.com/2018/05/01/Hello-world/</id>
    <published>2018-05-01T02:11:12.000Z</published>
    <updated>2020-06-05T02:11:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>Hello guys, this is Jiawen.<br>Nice to meeting you :)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Hello guys, this is Jiawen.&lt;br&gt;Nice to meeting you :)&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
      <category term="life" scheme="http://yoursite.com/tags/life/"/>
    
      <category term="TheFirstPost" scheme="http://yoursite.com/tags/TheFirstPost/"/>
    
  </entry>
  
</feed>
